{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import tarfile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class YourDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "   \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.labels = sorted(os.listdir(self.img_dir), key= lambda x: int(x))\n",
    "        \n",
    "        lb = [int(l)-1 for l in self.labels]\n",
    "        self.labels_ohe=lb\n",
    "        #self.labels_ohe = F.one_hot(torch.as_tensor(lb), num_classes=11) # I have changed from 11 to 5 sami\n",
    "        \n",
    "        self.img_lists = []\n",
    "        self.all_class_dirs = [os.path.join(self.img_dir, label) for label in self.labels]\n",
    "        \n",
    "        for class_dir in self.all_class_dirs[:5]:  # For 5 classes\n",
    "            self.img_lists += os.listdir(class_dir)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            #transforms.CenterCrop(64),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "            #                     std=[0.229, 0.224, 0.225] )\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_lists)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        all_img_abs_dir = []\n",
    "        for class_dir in self.all_class_dirs[:5]: # for 5 classes\n",
    "            all_img_abs_dir += [os.path.join(class_dir, img_name) for img_name in os.listdir(class_dir)]\n",
    "            \n",
    "        image_abs_dir = all_img_abs_dir[index]\n",
    "        label = int(image_abs_dir.split(\"/\")[-2])\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(image_abs_dir).convert(\"L\")\n",
    "            img = self.transform(img)\n",
    "            x=img\n",
    "            x.unsqueeze_(0)\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "            x=x.view( -1, 224, 224)\n",
    "            #vis = np.concatenate((img, img, img), axis=1)\n",
    "            return x , self.labels_ohe[label-1]\n",
    "            \n",
    "        except PIL.UnidentifiedImageError as ui:\n",
    "            print(image_abs_dir)\n",
    "            return None, None\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import tarfile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class YourDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "   \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.labels = sorted(os.listdir(self.img_dir), key= lambda x: int(x))\n",
    "        \n",
    "        lb = [int(l)-1 for l in self.labels]\n",
    "        self.labels_ohe=lb\n",
    "        #self.labels_ohe = F.one_hot(torch.as_tensor(lb), num_classes=11) # I have changed from 11 to 5 sami\n",
    "        \n",
    "        self.img_lists = []\n",
    "        self.all_class_dirs = [os.path.join(self.img_dir, label) for label in self.labels]\n",
    "        \n",
    "        for class_dir in self.all_class_dirs[:5]:  # For 5 classes\n",
    "            self.img_lists += os.listdir(class_dir)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((40, 72)),\n",
    "            #transforms.CenterCrop(64),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "            #                     std=[0.229, 0.224, 0.225] )\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_lists)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        all_img_abs_dir = []\n",
    "        for class_dir in self.all_class_dirs[:5]: # for 5 classes\n",
    "            all_img_abs_dir += [os.path.join(class_dir, img_name) for img_name in os.listdir(class_dir)]\n",
    "            \n",
    "        image_abs_dir = all_img_abs_dir[index]\n",
    "        label = int(image_abs_dir.split(\"/\")[-2])\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(image_abs_dir).convert(\"L\")\n",
    "            img = self.transform(img)\n",
    "            x=img\n",
    "            x.unsqueeze_(0)\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "            x=x.view( -1, 40, 72)\n",
    "            #vis = np.concatenate((img, img, img), axis=1)\n",
    "            return x, self.labels_ohe[label-1]\n",
    "            \n",
    "        except PIL.UnidentifiedImageError as ui:\n",
    "            print(image_abs_dir)\n",
    "            return None, None\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/shoaibmerajsami/Desktop/UCHE/PycharmProjects/abc/\"\n",
    "train_data = YourDataset(root_dir)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=200, shuffle=True,  num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/shoaibmerajsami/Desktop/roi_test/\"\n",
    "testa = YourDataset(root_dir)\n",
    "testloader = torch.utils.data.DataLoader(testa, batch_size=200, shuffle=True,  num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([200, 3, 224, 224])\n",
      "torch.Size([89, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for x in testloader:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "#model2 = model2.cuda()\n",
    "#if torch.cuda.is_available():\n",
    "   # model1= nn.DataParallel(model1, device_ids=[0,1])\n",
    "    #model2= nn.DataParallel(model2, device_ids=[0,1])\n",
    "     \n",
    "     \n",
    "            #model.to(device)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model= nn.DataParallel(model, device_ids=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0\n",
      "tensor(0.2918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "1\n",
      "tensor(0.1913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "2\n",
      "tensor(0.1499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "3\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "4\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "5\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "6\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "7\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "8\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "9\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "10\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "11\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "12\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "13\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "14\n",
      "tensor(0.0641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "15\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "16\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "17\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "18\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "19\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "20\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "21\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "22\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "23\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "24\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "25\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "26\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "27\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "28\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "29\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "30\n",
      "tensor(0.0222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "31\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "32\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "33\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "34\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "35\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "36\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "37\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "38\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "39\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "40\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "41\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "42\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "43\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "44\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "45\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "46\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "47\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "48\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "49\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "50\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "51\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "52\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "53\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "54\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "55\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "56\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "57\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "58\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "59\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "60\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "61\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "62\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "63\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "64\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "65\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "66\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "67\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "68\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "69\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "70\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "71\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "72\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "73\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "74\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "75\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "76\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "77\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "78\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "79\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "80\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "81\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "82\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "83\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "84\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "85\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "86\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "87\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "88\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "89\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "90\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "91\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "92\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "93\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "94\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "95\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "96\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "97\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "98\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0003,  betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "import tqdm \n",
    "\n",
    "# Train Network\n",
    "for epoch in range(100):\n",
    "    #for batch_idx, (data, targets) in enumerate(tqdm(trainloader)):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        data, targets = data\n",
    "        #data=data.cuda()\n",
    "        #targets=targets.cuda()\n",
    "        data=data.to(device=device)\n",
    "        targets=targets.to(device=device)\n",
    "        #print('a')\n",
    "        # Get data to cuda if possible\n",
    "        #data = data.to(device=device)\n",
    "        #targets = targets.to(device=device)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "        scores = model(data)\n",
    "        #scores2=torch.stack(list(scores), dim=0)\n",
    "        loss = criterion(scores, targets)\n",
    "        #print(targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    print(loss)\n",
    "    print(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "tensor([1, 1, 4, 4, 3, 4, 1, 4, 1, 0, 3, 1, 4, 3, 3, 0, 0, 2, 4, 1, 4, 4, 4, 1,\n",
      "        2, 3, 1, 0, 3, 4, 2, 2, 0, 4, 4, 0, 3, 2, 2, 1, 0, 4, 0, 1, 0, 0, 4, 1,\n",
      "        3, 3, 3, 3, 1, 3, 0, 1, 1, 0, 2, 2, 1, 3, 3, 0, 0, 0, 2, 2, 3, 3, 2, 3,\n",
      "        1, 2, 3, 0, 2, 2, 0, 3, 1, 0, 4, 4, 1, 4, 0, 4, 0, 2, 2, 2, 2, 0, 4, 2,\n",
      "        3, 2, 4, 0, 4, 1, 3, 0, 4, 1, 0, 0, 3, 2, 2, 3, 3, 3, 2, 0, 2, 4, 1, 4,\n",
      "        0, 0, 2, 3, 2, 0, 4, 3, 3, 1, 1, 2, 3, 4, 4, 3, 1, 0, 1, 0, 1, 4, 1, 3,\n",
      "        2, 0, 4, 0, 1, 3, 0, 4, 4, 1, 1, 0, 1, 4, 0, 1, 3, 2, 0, 3, 4, 0, 2, 0,\n",
      "        3, 1, 0, 4, 2, 4, 3, 0, 4, 1, 1, 2, 2, 4, 4, 4, 4, 2, 4, 4, 0, 3, 2, 4,\n",
      "        2, 2, 2, 3, 3, 1, 1, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 1, 2, 4, 3, 4, 4, 3, 1, 0, 3, 1, 4, 3, 1, 1, 0, 2, 2, 1, 4, 4, 4, 1,\n",
      "        2, 3, 0, 1, 2, 4, 2, 4, 0, 3, 4, 1, 3, 2, 2, 0, 0, 2, 0, 1, 0, 0, 4, 0,\n",
      "        3, 3, 4, 3, 1, 4, 0, 1, 1, 0, 2, 2, 1, 2, 3, 1, 0, 0, 2, 0, 3, 3, 1, 4,\n",
      "        1, 1, 3, 0, 0, 2, 1, 3, 1, 2, 4, 4, 1, 4, 2, 4, 0, 1, 1, 1, 2, 2, 2, 2,\n",
      "        4, 1, 4, 4, 3, 0, 3, 1, 4, 1, 0, 0, 0, 4, 1, 3, 3, 3, 2, 0, 4, 4, 2, 4,\n",
      "        1, 0, 2, 3, 4, 0, 0, 3, 3, 1, 2, 2, 3, 4, 4, 3, 2, 0, 1, 1, 1, 4, 1, 3,\n",
      "        2, 1, 4, 0, 2, 3, 1, 4, 4, 0, 1, 0, 1, 3, 0, 0, 2, 2, 0, 3, 2, 1, 2, 0,\n",
      "        0, 1, 1, 2, 2, 3, 3, 0, 4, 1, 1, 2, 2, 4, 4, 4, 4, 2, 4, 4, 0, 3, 3, 4,\n",
      "        2, 2, 2, 4, 3, 2, 1, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 2, 2, 0, 2, 2, 3, 3, 2, 1, 2, 2, 2, 3, 1, 1, 2, 0, 4, 2, 1, 1, 1, 4,\n",
      "        0, 2, 2, 4, 0, 0, 2, 0, 1, 3, 2, 4, 0, 4, 2, 3, 4, 0, 1, 0, 2, 0, 3, 1,\n",
      "        0, 3, 1, 2, 3, 3, 1, 4, 1, 3, 2, 0, 3, 0, 4, 1, 3, 3, 4, 4, 4, 1, 2, 1,\n",
      "        0, 2, 1, 0, 0, 2, 1, 3, 0, 3, 2, 0, 0, 0, 1, 4, 1, 3, 3, 2, 3, 2, 1, 1,\n",
      "        3, 0, 2, 1, 2, 2, 2, 4, 2, 1, 1, 3, 3, 1, 2, 1, 4, 1, 1, 0, 2, 3, 2, 4,\n",
      "        4, 3, 4, 3, 3, 2, 2, 0, 1, 3, 2, 3, 1, 1, 0, 1, 3, 0, 1, 3, 4, 2, 0, 3,\n",
      "        2, 2, 2, 4, 2, 4, 1, 2, 1, 3, 0, 2, 0, 2, 4, 2, 0, 0, 0, 4, 2, 0, 3, 3,\n",
      "        0, 3, 3, 3, 1, 3, 2, 0, 4, 4, 0, 0, 1, 2, 1, 0, 4, 2, 0, 2, 4, 0, 0, 3,\n",
      "        4, 4, 3, 2, 1, 2, 1, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 2, 2, 1, 2, 1, 3, 3, 4, 2, 2, 0, 0, 3, 1, 2, 2, 0, 4, 2, 2, 1, 2, 4,\n",
      "        1, 2, 2, 4, 1, 0, 2, 0, 1, 0, 2, 4, 0, 4, 2, 3, 4, 1, 0, 1, 2, 0, 0, 1,\n",
      "        0, 3, 2, 4, 3, 3, 1, 4, 1, 0, 2, 0, 3, 0, 4, 1, 3, 3, 4, 0, 4, 2, 2, 1,\n",
      "        4, 1, 1, 0, 0, 2, 4, 3, 0, 3, 1, 1, 0, 0, 1, 4, 1, 3, 4, 1, 3, 2, 1, 2,\n",
      "        0, 1, 2, 1, 2, 2, 0, 3, 2, 1, 1, 3, 3, 1, 2, 1, 4, 1, 1, 2, 0, 3, 2, 4,\n",
      "        4, 3, 4, 3, 3, 2, 2, 1, 1, 3, 2, 3, 1, 1, 0, 0, 0, 4, 1, 3, 4, 2, 0, 3,\n",
      "        2, 2, 1, 3, 2, 4, 1, 1, 1, 3, 0, 1, 0, 2, 4, 2, 0, 1, 0, 4, 2, 1, 3, 3,\n",
      "        0, 3, 3, 3, 0, 3, 2, 0, 1, 3, 0, 1, 1, 2, 1, 0, 4, 2, 0, 2, 2, 0, 2, 3,\n",
      "        4, 4, 0, 2, 0, 2, 0, 1], device='cuda:0')\n",
      "label\n",
      "tensor([4, 1, 2, 2, 3, 1, 3, 0, 3, 4, 3, 1, 1, 1, 0, 4, 4, 3, 2, 1, 1, 4, 3, 2,\n",
      "        2, 3, 3, 0, 1, 2, 0, 1, 0, 4, 0, 2, 1, 0, 0, 3, 1, 0, 3, 4, 3, 4, 0, 1,\n",
      "        1, 4, 4, 4, 3, 3, 2, 2, 3, 1, 1, 1, 3, 0, 4, 1, 1, 1, 1, 0, 2, 0, 1, 0,\n",
      "        1, 2, 0, 4, 1, 3, 2, 3, 2, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1, 2, 1, 1, 4, 0,\n",
      "        3, 0, 1, 3, 2, 1, 4, 1, 1, 0, 0, 4, 3, 1, 0, 0, 3, 4, 4, 0, 0, 0, 4, 0,\n",
      "        4, 2, 0, 1, 4, 0, 2, 3, 4, 3, 4, 1, 4, 0, 3, 1, 1, 4, 3, 3, 0, 4, 0, 0,\n",
      "        2, 4, 4, 0, 2, 4, 1, 3, 2, 3, 3, 1, 0, 1, 2, 3, 3, 2, 0, 3, 2, 1, 1, 2,\n",
      "        4, 1, 2, 1, 1, 1, 1, 2, 2, 4, 1, 1, 0, 0, 4, 2, 1, 3, 3, 2, 1, 4, 0, 2,\n",
      "        3, 2, 0, 3, 2, 4, 2, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 2, 2, 3, 1, 3, 0, 2, 4, 3, 1, 1, 1, 3, 4, 0, 3, 1, 1, 1, 4, 3, 2,\n",
      "        2, 3, 3, 0, 0, 2, 0, 1, 0, 4, 0, 1, 1, 0, 2, 3, 0, 0, 0, 2, 3, 4, 4, 2,\n",
      "        3, 1, 3, 0, 3, 3, 3, 0, 0, 2, 1, 0, 0, 1, 1, 1, 0, 2, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 4, 1, 3, 2, 3, 2, 0, 1, 1, 2, 1, 2, 1, 0, 1, 3, 2, 0, 0, 4, 0,\n",
      "        3, 1, 1, 3, 0, 1, 4, 1, 2, 2, 0, 2, 4, 0, 0, 1, 4, 4, 4, 1, 0, 2, 3, 0,\n",
      "        2, 2, 1, 1, 4, 0, 4, 3, 4, 3, 2, 1, 4, 0, 3, 1, 1, 4, 2, 2, 0, 2, 0, 0,\n",
      "        3, 4, 0, 0, 4, 4, 1, 3, 2, 3, 3, 0, 0, 4, 2, 3, 3, 1, 1, 1, 2, 1, 1, 2,\n",
      "        0, 1, 2, 2, 0, 2, 1, 2, 2, 4, 1, 1, 0, 1, 4, 2, 1, 3, 1, 2, 1, 1, 1, 1,\n",
      "        2, 1, 0, 3, 2, 4, 1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 3, 2, 4, 4, 4, 2, 4, 2, 2, 0, 1, 0, 3, 0, 4, 0, 3, 2, 0, 4, 2, 3,\n",
      "        0, 3, 0, 3, 2, 0, 4, 2, 0, 2, 0, 0, 1, 1, 2, 0, 1, 0, 1, 2, 0, 1, 1, 2,\n",
      "        1, 4, 0, 1, 0, 1, 0, 2, 2, 4, 4, 0, 4, 1, 4, 0, 1, 3, 4, 0, 4, 4, 0, 2,\n",
      "        2, 4, 1, 0, 4, 0, 4, 0, 0, 4, 0, 2, 1, 1, 1, 0, 2, 4, 1, 1, 3, 2, 2, 0,\n",
      "        0, 2, 2, 2, 1, 1, 3, 2, 2, 0, 0, 3, 0, 2, 1, 4, 0, 0, 2, 1, 3, 2, 1, 1,\n",
      "        4, 1, 0, 4, 3, 2, 0, 1, 2, 0, 2, 1, 2, 0, 2, 2, 4, 4, 1, 3, 4, 4, 2, 0,\n",
      "        3, 3, 3, 3, 1, 1, 4, 2, 0, 1, 0, 0, 0, 1, 3, 4, 0, 2, 4, 4, 3, 3, 0, 2,\n",
      "        4, 4, 2, 0, 1, 3, 3, 1, 0, 0, 3, 1, 4, 1, 0, 0, 2, 3, 3, 0, 0, 1, 3, 2,\n",
      "        0, 4, 2, 0, 0, 2, 2, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 0, 1, 2, 3, 1, 0, 2, 4, 1, 2, 1, 0, 1, 3, 0, 2, 0, 3, 2, 0, 4, 2, 3,\n",
      "        0, 1, 0, 3, 2, 1, 2, 2, 0, 2, 1, 4, 1, 0, 2, 0, 2, 1, 2, 2, 0, 1, 1, 1,\n",
      "        1, 4, 0, 1, 0, 1, 0, 2, 2, 4, 4, 0, 4, 1, 4, 4, 3, 3, 4, 1, 4, 4, 4, 0,\n",
      "        1, 4, 2, 0, 4, 0, 3, 0, 0, 2, 3, 2, 1, 0, 1, 2, 4, 3, 1, 1, 3, 2, 2, 0,\n",
      "        1, 2, 2, 2, 1, 1, 3, 2, 0, 0, 1, 3, 0, 0, 1, 4, 0, 0, 4, 1, 4, 1, 1, 1,\n",
      "        4, 0, 0, 3, 1, 2, 0, 1, 2, 0, 2, 1, 2, 2, 2, 2, 4, 4, 1, 3, 4, 4, 2, 1,\n",
      "        3, 3, 0, 0, 1, 1, 2, 4, 0, 1, 0, 0, 0, 0, 3, 4, 2, 2, 4, 2, 3, 0, 0, 2,\n",
      "        4, 4, 2, 0, 0, 3, 3, 4, 0, 0, 2, 1, 4, 1, 0, 0, 2, 3, 3, 0, 0, 1, 3, 2,\n",
      "        0, 4, 2, 0, 4, 2, 2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([4, 4, 4, 1, 1, 0, 0, 4, 0, 0, 4, 3, 0, 2, 1, 3, 4, 0, 3, 0, 0, 4, 0, 3,\n",
      "        3, 1, 3, 3, 0, 2, 0, 0, 1, 4, 0, 1, 3, 1, 3, 0, 0, 0, 0, 3, 0, 1, 2, 2,\n",
      "        0, 0, 4, 1, 4, 3, 3, 2, 1, 0, 2, 0, 4, 2, 1, 4, 1, 3, 3, 2, 2, 2, 4, 3,\n",
      "        0, 1, 4, 1, 4, 4, 4, 4, 4, 2, 3, 0, 3, 0, 4, 0, 2, 0, 2, 2, 4, 3, 1, 4,\n",
      "        3, 3, 3, 3, 1, 2, 1, 0, 4, 2, 0, 0, 2, 0, 4, 1, 0, 1, 2, 4, 2, 0, 0, 4,\n",
      "        3, 0, 4, 3, 0, 2, 1, 2, 2, 4, 0, 2, 2, 1, 3, 1, 0, 1, 1, 4, 2, 0, 2, 3,\n",
      "        2, 1, 0, 4, 0, 0, 4, 0, 4, 2, 1, 0, 4, 4, 2, 1, 2, 3, 4, 4, 3, 1, 4, 3,\n",
      "        4, 3, 0, 4, 0, 3, 2, 2, 0, 0, 2, 0, 1, 2, 4, 2, 2, 1, 2, 3, 2, 3, 1, 1,\n",
      "        3, 2, 0, 4, 3, 4, 4, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 4, 0, 1, 4, 0, 4, 1, 1, 4, 3, 1, 2, 1, 3, 4, 0, 1, 1, 2, 4, 0, 4,\n",
      "        3, 1, 3, 3, 0, 2, 2, 0, 2, 3, 0, 1, 3, 0, 3, 1, 4, 0, 4, 3, 1, 1, 2, 4,\n",
      "        2, 2, 4, 1, 4, 3, 3, 2, 2, 0, 2, 2, 4, 2, 1, 4, 1, 3, 3, 4, 1, 2, 2, 3,\n",
      "        1, 1, 4, 1, 2, 4, 4, 1, 4, 2, 3, 1, 0, 0, 0, 0, 2, 4, 3, 3, 4, 3, 2, 0,\n",
      "        3, 3, 1, 0, 1, 2, 1, 0, 4, 2, 0, 0, 1, 0, 3, 1, 0, 1, 2, 4, 2, 0, 0, 4,\n",
      "        3, 0, 1, 3, 3, 2, 1, 2, 4, 2, 0, 1, 2, 1, 3, 1, 0, 0, 4, 4, 2, 0, 2, 1,\n",
      "        1, 1, 0, 2, 0, 0, 4, 0, 4, 2, 2, 0, 4, 2, 2, 1, 2, 2, 4, 1, 3, 0, 0, 3,\n",
      "        4, 3, 0, 4, 1, 3, 2, 2, 0, 0, 4, 0, 1, 2, 2, 2, 2, 1, 1, 3, 2, 3, 1, 1,\n",
      "        3, 2, 0, 4, 3, 4, 0, 0], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 4, 3, 3, 3, 2, 3, 1, 3, 0, 1, 2, 1, 0, 4, 1, 0, 3, 2, 2, 3, 3, 2,\n",
      "        2, 1, 1, 1, 4, 2, 2, 4, 4, 0, 1, 3, 3, 3, 1, 1, 2, 0, 0, 3, 2, 3, 0, 3,\n",
      "        2, 0, 3, 4, 2, 2, 4, 3, 1, 3, 3, 4, 0, 3, 1, 0, 3, 3, 4, 1, 4, 1, 3, 2,\n",
      "        4, 0, 0, 0, 3, 0, 3, 1, 3, 4, 1, 3, 4, 0, 1, 1, 2, 4, 4, 2, 3, 4, 2, 1,\n",
      "        1, 1, 4, 1, 1, 3, 2, 2, 1, 3, 3, 0, 0, 4, 4, 4, 0, 1, 4, 0, 1, 0, 2, 4,\n",
      "        1, 0, 3, 2, 0, 2, 0, 2, 2, 4, 4, 2, 2, 0, 3, 4, 1, 2, 1, 2, 0, 4, 3, 3,\n",
      "        1, 2, 1, 4, 4, 0, 4, 3, 2, 4, 4, 1, 4, 3, 1, 2, 4, 2, 0, 4, 1, 0, 0, 1,\n",
      "        2, 3, 0, 0, 0, 1, 1, 1, 1, 2, 2, 0, 1, 2, 1, 2, 2, 0, 2, 4, 0, 1, 4, 3,\n",
      "        4, 3, 2, 1, 1, 1, 2, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 1, 3, 3, 3, 3, 2, 3, 1, 3, 0, 1, 2, 1, 4, 4, 0, 3, 3, 2, 4, 3, 3, 1,\n",
      "        4, 1, 1, 1, 2, 2, 2, 4, 4, 0, 1, 3, 3, 3, 1, 2, 2, 4, 0, 1, 2, 4, 1, 4,\n",
      "        2, 0, 3, 3, 2, 1, 2, 3, 1, 3, 3, 4, 0, 3, 1, 0, 3, 3, 4, 1, 4, 1, 3, 4,\n",
      "        4, 0, 0, 4, 3, 3, 3, 1, 3, 4, 1, 3, 3, 0, 1, 0, 2, 2, 2, 1, 3, 2, 4, 0,\n",
      "        0, 0, 4, 1, 1, 4, 1, 2, 1, 0, 3, 0, 3, 2, 1, 0, 0, 1, 4, 0, 1, 0, 1, 4,\n",
      "        1, 0, 0, 2, 0, 2, 1, 2, 4, 4, 4, 2, 2, 1, 0, 4, 1, 1, 2, 3, 0, 2, 3, 3,\n",
      "        1, 2, 1, 4, 2, 0, 3, 1, 2, 4, 4, 0, 0, 3, 1, 2, 4, 2, 4, 4, 1, 1, 1, 1,\n",
      "        0, 3, 0, 0, 0, 1, 0, 2, 1, 2, 2, 0, 1, 2, 2, 1, 4, 0, 2, 4, 0, 1, 4, 3,\n",
      "        4, 3, 2, 2, 1, 1, 4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([1, 2, 1, 0, 0, 0, 2, 2, 1, 3, 1, 4, 0, 0, 4, 0, 0, 3, 2, 3, 2, 0, 3, 1,\n",
      "        2, 2, 2, 2, 1, 0, 2, 2, 0, 2, 1, 0, 2, 1, 1, 1, 4, 4, 2, 4, 1, 0, 1, 1,\n",
      "        0, 1, 2, 3, 2, 2, 4, 2, 4, 1, 4, 0, 3, 3, 1, 1, 0, 4, 2, 4, 4, 1, 2, 0,\n",
      "        3, 4, 2, 3, 3, 1, 1, 4, 2, 4, 1, 3, 3, 0, 4, 0, 2, 1, 2, 3, 2, 2, 4, 3,\n",
      "        1, 0, 2, 0, 2, 2, 1, 4, 0, 4, 4, 2, 2, 3, 4, 1, 0, 2, 4, 0, 1, 4, 4, 2,\n",
      "        4, 2, 1, 1, 1, 2, 3, 4, 0, 4, 3, 1, 0, 1, 4, 4, 0, 2, 3, 0, 0, 2, 3, 1,\n",
      "        3, 4, 2, 2, 2, 0, 3, 3, 1, 0, 4, 3, 2, 3, 1, 0, 2, 1, 0, 2, 0, 3, 4, 4,\n",
      "        1, 2, 4, 3, 1, 0, 3, 2, 1, 1, 1, 3, 0, 1, 1, 1, 1, 2, 3, 0, 2, 4, 4, 2,\n",
      "        0, 0, 4, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 2, 1, 1, 0, 0, 2, 2, 1, 4, 1, 4, 0, 1, 2, 0, 0, 3, 2, 2, 4, 0, 3, 0,\n",
      "        2, 1, 4, 2, 1, 0, 3, 2, 0, 4, 1, 0, 2, 1, 4, 1, 4, 4, 2, 2, 1, 0, 4, 1,\n",
      "        0, 1, 0, 4, 2, 2, 2, 2, 4, 1, 4, 0, 3, 3, 1, 1, 0, 2, 2, 4, 4, 1, 2, 0,\n",
      "        4, 2, 2, 4, 0, 1, 1, 4, 2, 4, 1, 2, 0, 1, 2, 0, 0, 2, 2, 1, 2, 2, 4, 3,\n",
      "        2, 0, 1, 0, 2, 4, 3, 4, 0, 4, 4, 0, 2, 3, 4, 1, 4, 2, 4, 1, 0, 0, 4, 2,\n",
      "        4, 2, 1, 1, 1, 2, 2, 3, 0, 4, 3, 1, 0, 1, 4, 4, 0, 2, 3, 0, 0, 2, 2, 1,\n",
      "        3, 2, 2, 2, 4, 2, 2, 3, 1, 0, 4, 4, 2, 3, 1, 1, 2, 1, 0, 2, 0, 3, 4, 1,\n",
      "        1, 2, 4, 3, 1, 0, 1, 2, 1, 3, 1, 4, 0, 1, 1, 1, 1, 1, 3, 0, 2, 4, 4, 3,\n",
      "        1, 0, 4, 2, 1, 0, 1, 1], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 2, 4, 1, 0, 2, 0, 4, 2, 2, 0, 1, 0, 3, 4, 1, 0, 0, 0, 0, 3, 0, 0,\n",
      "        4, 4, 1, 1, 4, 4, 4, 3, 3, 4, 4, 4, 1, 1, 3, 4, 3, 2, 2, 0, 3, 0, 4, 2,\n",
      "        4, 2, 1, 0, 2, 2, 3, 1, 1, 2, 2, 0, 2, 0, 1, 4, 2, 4, 2, 0, 4, 1, 4, 3,\n",
      "        4, 0, 0, 2, 0, 3, 2, 2, 2, 4, 2, 2, 0, 0, 4, 4, 3, 2, 3, 3, 4, 3, 2, 0,\n",
      "        0, 0, 3, 3, 4, 3, 3, 4, 3, 2, 0, 2, 0, 2, 1, 2, 2, 0, 3, 2, 2, 1, 2, 3,\n",
      "        0, 1, 1, 0, 1, 0, 1, 2, 4, 0, 2, 0, 2, 0, 0, 4, 1, 4, 2, 3, 4, 3, 1, 3,\n",
      "        3, 2, 3, 0, 4, 4, 2, 4, 2, 3, 1, 4, 2, 3, 2, 4, 2, 4, 0, 0, 0, 1, 0, 0,\n",
      "        1, 2, 4, 2, 0, 0, 0, 2, 2, 1, 2, 2, 1, 0, 0, 3, 1, 1, 2, 4, 4, 4, 3, 3,\n",
      "        2, 0, 0, 0, 1, 2, 3, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 2, 3, 3, 0, 4, 0, 4, 2, 2, 1, 2, 0, 0, 4, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        4, 4, 2, 2, 0, 4, 4, 2, 3, 2, 4, 2, 1, 4, 3, 2, 3, 1, 4, 0, 3, 0, 4, 2,\n",
      "        2, 2, 0, 0, 2, 2, 3, 1, 1, 2, 2, 0, 2, 1, 1, 4, 0, 2, 1, 0, 4, 1, 3, 4,\n",
      "        4, 1, 0, 0, 0, 3, 2, 2, 0, 4, 0, 2, 4, 1, 4, 4, 3, 2, 3, 3, 2, 2, 2, 0,\n",
      "        1, 1, 2, 3, 2, 3, 3, 3, 3, 2, 1, 2, 1, 1, 1, 2, 3, 0, 0, 2, 4, 1, 2, 3,\n",
      "        0, 2, 0, 1, 0, 0, 3, 0, 4, 0, 2, 0, 1, 4, 0, 4, 3, 4, 2, 3, 4, 1, 1, 3,\n",
      "        3, 2, 3, 0, 4, 4, 4, 4, 2, 4, 1, 4, 4, 3, 2, 4, 1, 4, 0, 1, 0, 1, 0, 0,\n",
      "        1, 2, 4, 2, 1, 0, 1, 4, 4, 1, 2, 2, 1, 0, 0, 3, 1, 1, 2, 4, 1, 4, 3, 3,\n",
      "        1, 0, 0, 2, 1, 3, 0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 0, 3, 0, 2, 0, 1, 2, 4, 4, 0, 1, 1, 2, 0, 2, 0, 3, 2, 2, 3, 4, 0,\n",
      "        4, 3, 4, 3, 2, 1, 3, 1, 1, 0, 3, 1, 2, 2, 4, 3, 4, 0, 0, 0, 0, 3, 0, 0,\n",
      "        2, 0, 0, 4, 2, 3, 0, 0, 1, 2, 3, 0, 2, 1, 1, 4, 0, 1, 1, 4, 1, 4, 2, 1,\n",
      "        3, 4, 0, 4, 4, 0, 1, 1, 3, 1, 2, 2, 2, 2, 0, 0, 1, 3, 4, 2, 0, 1, 0, 0,\n",
      "        3, 2, 1, 2, 2, 0, 1, 2, 3, 0, 0, 1, 1, 1, 3, 3, 2, 0, 3, 1, 0, 0, 2, 0,\n",
      "        3, 0, 0, 4, 2, 2, 2, 1, 3, 1, 1, 3, 1, 4, 2, 2, 0, 4, 4, 2, 0, 2, 2, 3,\n",
      "        0, 2, 4, 3, 1, 0, 0, 2, 3, 2, 0, 1, 1, 2, 2, 1, 0, 2, 1, 1, 4, 0, 4, 1,\n",
      "        1, 0, 3, 4, 1, 3, 2, 0, 0, 0, 0, 2, 2, 1, 2, 3, 0, 4, 3, 3, 3, 0, 3, 0,\n",
      "        2, 3, 2, 2, 3, 2, 3, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 0, 0, 3, 0, 2, 0, 1, 2, 4, 4, 0, 1, 1, 2, 4, 2, 1, 3, 2, 2, 2, 4, 0,\n",
      "        1, 3, 1, 2, 2, 1, 3, 2, 0, 0, 3, 4, 2, 0, 4, 3, 2, 0, 1, 4, 0, 4, 0, 0,\n",
      "        2, 0, 0, 4, 2, 3, 0, 0, 1, 2, 3, 0, 2, 2, 2, 4, 0, 1, 0, 4, 0, 4, 3, 1,\n",
      "        3, 4, 0, 4, 4, 0, 2, 1, 3, 4, 2, 2, 4, 2, 0, 0, 2, 3, 0, 2, 0, 1, 0, 1,\n",
      "        3, 2, 1, 2, 2, 0, 1, 2, 3, 0, 4, 2, 1, 0, 3, 4, 2, 0, 3, 2, 0, 0, 2, 0,\n",
      "        3, 0, 0, 0, 2, 2, 2, 4, 3, 2, 3, 3, 1, 4, 0, 1, 1, 4, 4, 0, 0, 1, 2, 3,\n",
      "        0, 2, 4, 3, 1, 1, 0, 4, 3, 2, 0, 0, 1, 2, 2, 1, 0, 2, 1, 1, 2, 0, 4, 1,\n",
      "        1, 0, 0, 4, 2, 0, 2, 0, 1, 0, 0, 2, 2, 1, 1, 3, 0, 3, 2, 3, 3, 0, 3, 4,\n",
      "        2, 3, 2, 2, 3, 4, 0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 3, 1, 1, 3, 0, 2, 4, 0, 0, 1, 0, 4, 4, 1, 4, 2, 0, 0, 3, 4, 0, 3, 2,\n",
      "        1, 3, 2, 3, 2, 2, 1, 0, 4, 2, 1, 2, 2, 3, 4, 4, 2, 2, 1, 2, 4, 2, 0, 3,\n",
      "        1, 3, 4, 4, 3, 4, 3, 3, 4, 1, 2, 1, 1, 0, 1, 1, 1, 2, 1, 2, 3, 1, 2, 0,\n",
      "        0, 1, 0, 2, 4, 0, 0, 1, 2, 3, 0, 2, 4, 2, 4, 0, 2, 0, 4, 0, 1, 4, 0, 4,\n",
      "        3, 2, 3, 0, 0, 4, 3, 0, 2, 0, 4, 1, 3, 0, 0, 4, 1, 0, 4, 0, 2, 2, 2, 4,\n",
      "        1, 0, 4, 1, 4, 4, 3, 2, 2, 1, 2, 2, 0, 2, 3, 3, 0, 4, 0, 4, 2, 3, 4, 1,\n",
      "        3, 0, 0, 4, 1, 1, 4, 1, 1, 3, 1, 2, 0, 0, 1, 0, 1, 3, 0, 0, 3, 0, 2, 4,\n",
      "        4, 1, 1, 3, 4, 4, 1, 0, 1, 1, 4, 4, 1, 1, 0, 0, 2, 3, 1, 3, 4, 4, 2, 4,\n",
      "        0, 3, 4, 2, 1, 0, 2, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 2, 1, 2, 3, 1, 2, 2, 0, 1, 0, 0, 2, 4, 1, 0, 2, 0, 0, 3, 4, 2, 4, 2,\n",
      "        1, 3, 1, 3, 2, 0, 1, 0, 2, 2, 1, 2, 2, 1, 4, 2, 2, 0, 1, 2, 4, 4, 0, 3,\n",
      "        1, 3, 4, 2, 3, 4, 3, 3, 4, 1, 3, 0, 1, 0, 1, 1, 1, 4, 1, 0, 3, 1, 2, 2,\n",
      "        1, 1, 4, 2, 3, 1, 0, 1, 4, 4, 0, 2, 4, 4, 4, 2, 2, 1, 0, 0, 1, 4, 2, 4,\n",
      "        3, 1, 3, 0, 0, 4, 3, 0, 0, 0, 4, 1, 3, 0, 0, 2, 0, 0, 4, 1, 2, 2, 2, 3,\n",
      "        4, 1, 3, 1, 4, 4, 3, 2, 2, 1, 2, 2, 0, 4, 3, 3, 0, 4, 4, 4, 2, 3, 3, 1,\n",
      "        3, 1, 2, 0, 1, 1, 4, 1, 1, 0, 1, 4, 0, 4, 1, 0, 1, 3, 1, 0, 3, 0, 2, 0,\n",
      "        4, 1, 1, 3, 2, 2, 1, 2, 1, 1, 4, 4, 1, 1, 4, 0, 1, 3, 1, 3, 4, 4, 4, 4,\n",
      "        0, 3, 4, 2, 1, 0, 1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 1, 4, 2, 4, 0, 4, 2, 0, 0, 3, 3, 3, 1, 1, 4, 1, 0, 4, 1, 0, 3, 2,\n",
      "        3, 1, 3, 0, 2, 1, 1, 2, 0, 0, 1, 1, 2, 1, 3, 3, 3, 3, 4, 3, 2, 4, 2, 0,\n",
      "        1, 1, 4, 4, 2, 1, 0, 2, 1, 1, 4, 2, 3, 2, 4, 3, 4, 3, 1, 0, 1, 1, 4, 0,\n",
      "        4, 2, 3, 2, 4, 2, 4, 3, 1, 0, 2, 4, 2, 2, 0, 2, 1, 0, 2, 2, 2, 4, 0, 2,\n",
      "        1, 2, 2, 2, 1, 4, 2, 3, 3, 3, 4, 2, 1, 4, 1, 2, 3, 2, 2, 1, 2, 0, 2, 0,\n",
      "        0, 2, 1, 0, 2, 4, 0, 0, 4, 3, 4, 1, 0, 4, 1, 4, 3, 4, 3, 4, 4, 0, 4, 2,\n",
      "        4, 0, 3, 0, 0, 4, 1, 1, 1, 2, 0, 0, 1, 0, 1, 0, 1, 0, 1, 4, 0, 0, 0, 0,\n",
      "        2, 1, 3, 2, 2, 2, 2, 3, 1, 4, 0, 2, 4, 1, 3, 2, 1, 0, 2, 0, 0, 2, 1, 4,\n",
      "        2, 0, 0, 2, 0, 0, 0, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 0, 4, 0, 4, 0, 4, 2, 0, 0, 3, 0, 3, 1, 1, 4, 1, 0, 4, 1, 0, 3, 2,\n",
      "        3, 4, 4, 0, 2, 1, 1, 2, 0, 0, 1, 1, 2, 1, 0, 4, 4, 4, 4, 3, 2, 4, 1, 0,\n",
      "        1, 4, 4, 0, 2, 0, 0, 4, 0, 1, 0, 2, 3, 2, 2, 1, 4, 0, 0, 0, 1, 1, 4, 0,\n",
      "        4, 2, 3, 2, 4, 2, 2, 2, 1, 0, 2, 4, 2, 2, 1, 2, 1, 0, 1, 4, 1, 2, 0, 4,\n",
      "        1, 2, 2, 1, 1, 4, 1, 0, 0, 3, 4, 2, 1, 4, 1, 2, 3, 2, 2, 1, 2, 0, 2, 0,\n",
      "        1, 2, 3, 0, 2, 2, 0, 1, 2, 1, 2, 1, 0, 2, 1, 1, 3, 4, 3, 4, 3, 1, 4, 2,\n",
      "        2, 0, 4, 0, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 1, 0, 1, 0, 4, 4, 0, 2, 0, 4,\n",
      "        2, 1, 3, 2, 2, 2, 2, 3, 2, 4, 4, 2, 1, 0, 3, 2, 2, 0, 4, 0, 0, 2, 3, 4,\n",
      "        2, 1, 2, 1, 4, 4, 0, 3], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 4, 1, 3, 1, 1, 3, 0, 2, 1, 2, 2, 3, 0, 3, 0, 4, 4, 1, 2, 3, 0, 0,\n",
      "        0, 0, 2, 0, 0, 4, 1, 0, 2, 1, 4, 2, 0, 2, 1, 1, 1, 2, 1, 0, 2, 3, 2, 4,\n",
      "        1, 4, 4, 0, 2, 4, 3, 0, 1, 4, 1, 1, 3, 1, 2, 1, 2, 4, 3, 4, 0, 1, 2, 0,\n",
      "        3, 4, 2, 0, 4, 3, 0, 3, 3, 2, 4, 1, 0, 0, 0, 2, 4, 4, 2, 4, 0, 4, 2, 2,\n",
      "        2, 3, 0, 1, 1, 0, 0, 4, 0, 2, 0, 2, 3, 4, 0, 2, 1, 1, 2, 2, 0, 2, 1, 3,\n",
      "        0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 2, 0, 0, 0, 0, 1,\n",
      "        3, 0, 0, 1, 0, 0, 3, 4, 3, 0, 3, 3, 0, 4, 1, 4, 0, 4, 0, 1, 1, 2, 0, 3,\n",
      "        1, 0, 2, 0, 3, 4, 1, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 3, 0, 3, 0, 4, 2, 3,\n",
      "        2, 0, 1, 2, 4, 3, 4, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 0, 4, 1, 3, 1, 1, 2, 2, 2, 1, 2, 4, 2, 1, 2, 0, 4, 2, 1, 2, 4, 1, 1,\n",
      "        1, 0, 2, 1, 4, 0, 1, 0, 1, 1, 4, 2, 1, 2, 1, 1, 1, 0, 1, 4, 2, 3, 2, 4,\n",
      "        2, 2, 2, 0, 2, 4, 2, 4, 1, 4, 0, 2, 3, 3, 2, 1, 2, 4, 3, 4, 0, 1, 2, 1,\n",
      "        3, 2, 2, 2, 4, 0, 0, 3, 0, 4, 4, 1, 0, 0, 0, 2, 4, 4, 2, 4, 0, 3, 3, 4,\n",
      "        2, 3, 0, 4, 0, 1, 1, 4, 0, 2, 0, 4, 3, 4, 1, 2, 2, 0, 4, 2, 0, 2, 1, 3,\n",
      "        0, 0, 0, 0, 1, 0, 2, 1, 4, 1, 0, 1, 0, 1, 1, 2, 4, 4, 2, 1, 2, 0, 0, 2,\n",
      "        3, 0, 1, 0, 0, 1, 3, 1, 0, 4, 3, 3, 0, 3, 1, 1, 0, 2, 0, 2, 2, 2, 0, 4,\n",
      "        1, 2, 4, 1, 3, 4, 2, 1, 1, 0, 1, 3, 1, 1, 2, 0, 0, 0, 0, 3, 0, 4, 2, 4,\n",
      "        2, 0, 1, 2, 3, 2, 1, 3], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 4, 2, 1, 4, 1, 2, 0, 1, 0, 3, 1, 0, 3, 2, 4, 3, 0, 3, 0, 1, 3, 3,\n",
      "        0, 2, 0, 0, 4, 4, 3, 3, 4, 1, 4, 2, 3, 4, 4, 3, 2, 0, 2, 1, 1, 2, 2, 2,\n",
      "        2, 2, 3, 4, 0, 3, 0, 1, 0, 2, 3, 0, 1, 4, 3, 0, 3, 1, 2, 0, 0, 4, 2, 1,\n",
      "        0, 2, 4, 2, 3, 4, 2, 0, 0, 3, 0, 3, 0, 1, 4, 0, 2, 4, 0, 1, 4, 2, 0, 0,\n",
      "        3, 2, 3, 1, 4, 1, 4, 4, 4, 2, 1, 4, 1, 0, 0, 0, 2, 1, 1, 2, 4, 2, 4, 1,\n",
      "        3, 1, 2, 2, 3, 0, 0, 2, 3, 2, 1, 3, 2, 1, 0, 4, 2, 1, 2, 4, 4, 0, 4, 0,\n",
      "        4, 4, 0, 1, 0, 0, 4, 4, 2, 3, 1, 3, 4, 1, 1, 0, 0, 2, 2, 0, 2, 2, 2, 0,\n",
      "        1, 2, 1, 0, 1, 4, 1, 2, 2, 0, 1, 1, 4, 3, 3, 2, 3, 0, 0, 3, 4, 3, 0, 1,\n",
      "        3, 2, 1, 0, 2, 2, 2, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 2, 3, 4, 1, 4, 1, 4, 1, 4, 0, 3, 1, 0, 0, 2, 4, 4, 0, 3, 0, 1, 4, 3,\n",
      "        0, 2, 2, 0, 3, 4, 3, 2, 2, 1, 2, 2, 1, 4, 3, 3, 2, 0, 2, 4, 1, 4, 2, 2,\n",
      "        2, 2, 3, 2, 2, 3, 0, 1, 0, 2, 3, 0, 0, 4, 3, 4, 2, 1, 2, 1, 1, 4, 2, 1,\n",
      "        1, 2, 3, 2, 3, 4, 4, 0, 0, 4, 1, 3, 1, 1, 3, 0, 2, 4, 0, 1, 2, 4, 1, 1,\n",
      "        3, 1, 1, 1, 1, 1, 2, 3, 4, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 3, 4, 2, 2, 1,\n",
      "        3, 1, 2, 1, 3, 0, 0, 2, 2, 2, 0, 1, 4, 1, 2, 2, 2, 0, 4, 2, 4, 0, 4, 0,\n",
      "        4, 4, 0, 1, 0, 0, 4, 4, 2, 4, 1, 0, 4, 0, 1, 0, 1, 2, 2, 0, 2, 2, 2, 2,\n",
      "        1, 2, 1, 0, 1, 4, 4, 2, 2, 0, 1, 1, 3, 4, 3, 2, 2, 0, 0, 3, 4, 3, 2, 1,\n",
      "        3, 2, 1, 4, 2, 2, 2, 0], device='cuda:0')\n",
      "label\n",
      "tensor([3, 2, 3, 0, 1, 4, 3, 2, 1, 4, 0, 3, 3, 0, 3, 0, 0, 0, 0, 2, 0, 0, 4, 0,\n",
      "        4, 0, 1, 0, 3, 2, 1, 0, 3, 2, 1, 4, 2, 2, 2, 0, 1, 1, 2, 4, 4, 4, 0, 2,\n",
      "        0, 4, 3, 0, 2, 4, 0, 2, 3, 1, 0, 0, 0, 0, 1, 2, 2, 1, 4, 1, 0, 2, 2, 2,\n",
      "        3, 2, 3, 2, 2, 0, 4, 3, 4, 3, 0, 1, 3, 2, 3, 2, 1, 4, 2, 2, 2, 4, 2, 1,\n",
      "        1, 2, 1, 4, 4, 0, 3, 1, 2, 2, 1, 4, 0, 4, 0, 0, 3, 0, 0, 2, 1, 4, 1, 1,\n",
      "        0, 2, 1, 2, 2, 3, 1, 0, 3, 1, 2, 4, 1, 4, 3, 2, 3, 3, 1, 1, 2, 2, 2, 1,\n",
      "        4, 2, 1, 3, 2, 4, 0, 1, 1, 1, 0, 3, 2, 4, 2, 0, 0, 0, 1, 3, 4, 1, 3, 1,\n",
      "        2, 1, 3, 0, 0, 3, 1, 0, 0, 0, 3, 3, 4, 3, 1, 0, 0, 3, 4, 3, 0, 4, 1, 4,\n",
      "        0, 2, 0, 1, 3, 4, 1, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 2, 0, 0, 2, 4, 2, 2, 1, 4, 1, 3, 3, 0, 3, 0, 0, 0, 1, 2, 1, 1, 4, 0,\n",
      "        2, 0, 2, 0, 3, 2, 4, 0, 3, 0, 1, 4, 1, 4, 2, 1, 1, 1, 2, 4, 4, 4, 1, 2,\n",
      "        0, 4, 3, 0, 2, 3, 0, 2, 2, 1, 0, 0, 0, 0, 0, 2, 2, 1, 4, 1, 0, 2, 4, 1,\n",
      "        0, 0, 0, 2, 0, 0, 4, 3, 2, 3, 2, 2, 1, 2, 3, 2, 2, 4, 1, 0, 3, 4, 2, 1,\n",
      "        1, 2, 1, 4, 2, 1, 1, 1, 2, 1, 1, 4, 0, 3, 0, 0, 3, 0, 0, 2, 1, 4, 3, 1,\n",
      "        0, 2, 1, 2, 1, 3, 1, 1, 3, 1, 4, 4, 1, 0, 3, 2, 3, 3, 1, 1, 2, 1, 1, 4,\n",
      "        2, 2, 1, 3, 2, 0, 2, 2, 0, 1, 1, 3, 2, 4, 1, 1, 0, 0, 0, 3, 4, 1, 3, 1,\n",
      "        2, 1, 3, 0, 0, 3, 4, 0, 1, 0, 3, 3, 4, 1, 1, 0, 0, 3, 1, 3, 0, 4, 2, 4,\n",
      "        0, 2, 0, 2, 3, 4, 2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 2, 1, 4, 3, 1, 1, 3, 2, 2, 3, 0, 2, 1, 0, 1, 1, 0, 3, 1, 4, 2, 3, 4,\n",
      "        4, 2, 4, 2, 0, 2, 1, 1, 4, 2, 2, 1, 3, 3, 1, 2, 2, 1, 3, 1, 0, 1, 3, 2,\n",
      "        1, 2, 1, 4, 0, 4, 2, 1, 3, 4, 2, 0, 0, 0, 0, 2, 0, 4, 1, 3, 4, 4, 1, 4,\n",
      "        2, 2, 0, 1, 0, 1, 2, 1, 2, 3, 2, 2, 1, 3, 2, 2, 4, 2, 0, 4, 3, 4, 3, 2,\n",
      "        2, 3, 3, 2, 0, 3, 1, 2, 3, 4, 3, 2, 2, 1, 0, 2, 3, 2, 1, 0, 0, 1, 1, 3,\n",
      "        1, 0, 4, 2, 1, 1, 1, 2, 0, 3, 0, 3, 2, 2, 3, 3, 1, 2, 2, 0, 1, 0, 0, 4,\n",
      "        4, 4, 4, 3, 1, 0, 3, 0, 3, 4, 2, 0, 1, 0, 4, 3, 1, 2, 2, 2, 3, 0, 3, 2,\n",
      "        2, 0, 3, 1, 2, 3, 2, 4, 3, 4, 1, 1, 1, 3, 1, 2, 1, 4, 1, 4, 3, 3, 0, 0,\n",
      "        0, 2, 2, 4, 2, 0, 0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 2, 0, 4, 3, 1, 3, 3, 4, 0, 3, 4, 1, 1, 0, 1, 1, 1, 3, 1, 4, 2, 0, 0,\n",
      "        4, 2, 2, 2, 1, 2, 1, 2, 3, 2, 4, 1, 3, 3, 1, 2, 2, 1, 3, 1, 2, 2, 3, 2,\n",
      "        1, 2, 1, 0, 1, 0, 2, 1, 3, 3, 2, 0, 0, 0, 0, 2, 0, 4, 1, 2, 4, 1, 1, 4,\n",
      "        2, 4, 0, 1, 0, 0, 2, 0, 4, 4, 2, 4, 1, 3, 2, 2, 2, 2, 0, 4, 3, 4, 3, 2,\n",
      "        2, 3, 3, 4, 0, 3, 1, 4, 3, 3, 3, 2, 4, 1, 0, 1, 3, 2, 1, 1, 2, 1, 0, 4,\n",
      "        4, 0, 4, 2, 1, 1, 1, 0, 0, 2, 1, 3, 2, 4, 3, 2, 1, 4, 2, 1, 1, 1, 4, 3,\n",
      "        4, 2, 4, 3, 1, 1, 0, 0, 2, 4, 2, 0, 1, 0, 2, 0, 1, 4, 2, 2, 3, 1, 3, 2,\n",
      "        2, 0, 0, 1, 0, 1, 1, 4, 3, 4, 3, 1, 2, 1, 2, 1, 1, 2, 0, 4, 4, 3, 1, 0,\n",
      "        0, 2, 1, 4, 2, 0, 2, 2], device='cuda:0')\n",
      "label\n",
      "tensor([4, 0, 0, 2, 4, 2, 4, 4, 3, 1, 1, 1, 1, 2, 3, 1, 0, 2, 3, 4, 2, 3, 4, 2,\n",
      "        3, 0, 2, 3, 4, 2, 2, 1, 4, 2, 1, 0, 1, 3, 4, 1, 3, 1, 3, 2, 2, 0, 0, 3,\n",
      "        3, 0, 2, 4, 2, 4, 1, 2, 1, 0, 3, 1, 0, 3, 0, 0, 1, 1, 0, 0, 2, 2, 0, 0,\n",
      "        2, 0, 1, 4, 3, 4, 2, 2, 2, 2, 3, 4, 0, 1, 0, 2, 1, 0, 2, 1, 3, 2, 0, 0,\n",
      "        0, 2, 0, 4, 2, 4, 4, 1, 0, 2, 4, 2, 0, 4, 2, 1, 2, 3, 4, 4, 0, 0, 1, 1,\n",
      "        4, 1, 2, 2, 2, 0, 3, 3, 0, 0, 1, 4, 4, 2, 0, 4, 4, 1, 3, 3, 4, 0, 0, 4,\n",
      "        0, 3, 0, 3, 2, 1, 2, 1, 4, 4, 1, 0, 4, 2, 3, 3, 4, 2, 4, 2, 0, 0, 1, 4,\n",
      "        4, 3, 4, 2, 1, 3, 1, 2, 3, 2, 2, 4, 2, 1, 3, 3, 0, 1, 0, 0, 3, 3, 3, 1,\n",
      "        1, 2, 0, 1, 2, 2, 1, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 0, 4, 1, 4, 1, 4, 2, 3, 1, 1, 2, 1, 2, 3, 1, 0, 1, 3, 4, 0, 3, 4, 0,\n",
      "        0, 1, 2, 3, 0, 2, 2, 1, 4, 2, 4, 0, 1, 3, 4, 1, 3, 4, 4, 2, 4, 0, 0, 3,\n",
      "        1, 0, 3, 4, 2, 3, 1, 2, 3, 0, 3, 1, 0, 3, 1, 0, 1, 1, 0, 0, 2, 4, 0, 0,\n",
      "        2, 0, 1, 4, 1, 4, 2, 2, 1, 1, 3, 4, 0, 1, 0, 2, 1, 2, 2, 1, 3, 2, 1, 1,\n",
      "        2, 3, 1, 3, 2, 2, 4, 1, 0, 2, 4, 2, 0, 3, 2, 1, 2, 3, 4, 2, 0, 0, 1, 3,\n",
      "        0, 0, 2, 3, 2, 0, 3, 3, 0, 1, 1, 4, 2, 2, 4, 4, 4, 1, 3, 3, 4, 4, 2, 4,\n",
      "        1, 3, 0, 3, 2, 1, 2, 1, 4, 4, 1, 0, 3, 0, 3, 3, 2, 2, 4, 2, 2, 0, 0, 2,\n",
      "        3, 3, 2, 2, 1, 3, 1, 3, 4, 2, 2, 4, 2, 1, 3, 3, 0, 1, 1, 1, 3, 3, 1, 1,\n",
      "        1, 2, 0, 1, 2, 2, 1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 1, 2, 0, 1, 4, 3, 3, 1, 4, 3, 3, 2, 0, 1, 0, 1, 4, 0, 1, 3, 1, 0,\n",
      "        2, 4, 0, 0, 4, 0, 0, 4, 3, 2, 4, 2, 3, 2, 3, 1, 2, 0, 0, 3, 1, 1, 4, 4,\n",
      "        0, 4, 4, 4, 2, 0, 2, 1, 0, 3, 2, 4, 3, 2, 1, 4, 3, 3, 1, 2, 0, 0, 0, 0,\n",
      "        2, 2, 0, 2, 2, 1, 3, 4, 3, 1, 2, 0, 0, 1, 3, 4, 0, 4, 0, 1, 2, 4, 1, 1,\n",
      "        2, 2, 4, 4, 1, 2, 0, 0, 0, 0, 0, 3, 1, 2, 4, 2, 3, 1, 1, 1, 4, 3, 0, 1,\n",
      "        1, 2, 1, 2, 0, 4, 1, 3, 3, 1, 0, 0, 2, 2, 0, 1, 4, 1, 0, 0, 3, 0, 2, 2,\n",
      "        1, 0, 2, 1, 4, 0, 0, 3, 0, 2, 1, 2, 4, 2, 0, 1, 3, 0, 2, 2, 3, 3, 1, 1,\n",
      "        4, 2, 3, 0, 2, 4, 1, 0, 0, 1, 4, 3, 1, 0, 4, 1, 1, 2, 0, 0, 3, 0, 3, 2,\n",
      "        0, 0, 0, 4, 0, 1, 2, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 2, 1, 2, 0, 1, 4, 3, 3, 2, 4, 3, 3, 1, 1, 1, 2, 2, 3, 4, 1, 3, 1, 0,\n",
      "        2, 4, 0, 0, 2, 0, 0, 4, 3, 0, 2, 1, 3, 0, 3, 3, 2, 0, 0, 4, 1, 1, 4, 3,\n",
      "        1, 2, 4, 4, 2, 0, 0, 1, 0, 3, 1, 4, 3, 2, 1, 4, 3, 3, 1, 2, 0, 0, 0, 1,\n",
      "        2, 1, 0, 2, 2, 1, 3, 0, 2, 1, 2, 2, 2, 1, 3, 1, 0, 4, 1, 1, 2, 0, 2, 2,\n",
      "        2, 0, 2, 3, 2, 1, 0, 1, 0, 0, 0, 3, 1, 2, 4, 1, 4, 1, 3, 0, 2, 3, 0, 1,\n",
      "        4, 1, 1, 3, 1, 1, 4, 3, 3, 1, 0, 0, 2, 1, 0, 1, 3, 1, 0, 0, 3, 0, 2, 2,\n",
      "        1, 0, 0, 2, 4, 1, 4, 3, 1, 2, 1, 2, 4, 2, 0, 1, 4, 0, 2, 1, 3, 3, 1, 1,\n",
      "        4, 2, 3, 1, 2, 4, 2, 1, 0, 1, 4, 3, 1, 2, 3, 1, 1, 2, 0, 0, 3, 2, 3, 2,\n",
      "        0, 2, 0, 2, 0, 2, 2, 0], device='cuda:0')\n",
      "label\n",
      "tensor([0, 4, 2, 3, 2, 4, 2, 3, 1, 1, 4, 4, 4, 3, 3, 0, 2, 4, 1, 0, 3, 1, 0, 1,\n",
      "        4, 3, 3, 4, 0, 1, 2, 1, 1, 1, 4, 4, 2, 4, 1, 0, 3, 4, 1, 4, 2, 1, 2, 1,\n",
      "        4, 4, 0, 1, 4, 4, 3, 2, 0, 2, 0, 1, 2, 2, 0, 2, 4, 4, 4, 1, 4, 0, 4, 3,\n",
      "        2, 4, 2, 0, 1, 1, 4, 0, 3, 2, 0, 3, 0, 1, 2, 2, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 2, 3, 2, 2, 2, 3, 1, 1, 4, 1, 4, 3, 3, 0, 2, 0, 1, 0, 3, 1, 0, 1,\n",
      "        4, 3, 3, 4, 1, 2, 4, 1, 1, 1, 2, 2, 2, 4, 1, 0, 3, 4, 4, 0, 0, 1, 4, 3,\n",
      "        4, 3, 1, 0, 4, 2, 3, 2, 4, 1, 0, 1, 2, 3, 0, 2, 2, 2, 4, 1, 4, 0, 4, 4,\n",
      "        3, 3, 2, 0, 1, 0, 3, 0, 0, 2, 1, 3, 0, 3, 4, 2, 0], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6778, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(testloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = nn.MSELoss(size_average=False)\n",
    "criterion1.cuda() \n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.5166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.8471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.2313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.9584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.4478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.3309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.5304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.3693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.0970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.2976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.1472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.2913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.4840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.3276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.1068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8091, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.3494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.0686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.1912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.0336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.2322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.0763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.1527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0\n",
      "tensor(1.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.2875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.9964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.0808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "1\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.6571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.8000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.7192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.5224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "2\n",
      "tensor(1.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.4194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "3\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "4\n",
      "tensor(1.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.3694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "5\n",
      "tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.2843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.1096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "6\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "7\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "8\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(2.0771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5091, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "9\n",
      "tensor(1.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "10\n",
      "tensor(1.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.3307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "11\n",
      "tensor(1.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.8012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "12\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "13\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "14\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.5903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "15\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "16\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1952, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "17\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "18\n",
      "tensor(1.1488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "19\n",
      "tensor(1.1552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "20\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.4380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "21\n",
      "tensor(1.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.9218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "22\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "23\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.5768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "24\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "25\n",
      "tensor(1.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.6947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.6434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.6585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(3.7810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "26\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.5918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5978, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.7574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.5174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.6764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.6648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "27\n",
      "tensor(1.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "28\n",
      "tensor(1.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.4497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.6274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.7367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.2100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.0230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.8943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(0.9358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.1785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\n",
      " loss2\n",
      "tensor(1.3653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "#optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.0001)\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "import tqdm \n",
    "\n",
    "# Train Network\n",
    "for epoch in range(30):\n",
    "    #for batch_idx, (data, targets) in enumerate(tqdm(trainloader)):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        data, targets = data\n",
    "        data=data.cuda()\n",
    "        targets=targets.cuda()\n",
    "        #print('a')\n",
    "        # Get data to cuda if possible\n",
    "        #data = data.to(device)\n",
    "        #targets = targets.to(device)\n",
    "        \n",
    "        #optimizer.zero_grades()\n",
    "        out_train = model1(data)\n",
    "\n",
    "        loss1 =  criterion1(out_train, data) / (data.size()[0]*2)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        #scores1=scores1.cuda()\n",
    "\n",
    "        #scores2=torch.stack(list(scores), dim=0)\n",
    "        loss1 = criterion1(scores1, data)\n",
    "        #print(targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer1.step()\n",
    "        \"\"\"\n",
    "        scores2 =model2(out_train)\n",
    "        loss2 = criterion2(scores2,targets)\n",
    "        #loss=.593*loss1+.41*loss2\n",
    "        loss1.backward(retain_graph=True)\n",
    "        \n",
    "        loss2.backward()\n",
    "        #loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        #print(targets)\n",
    "\n",
    "        # backward\n",
    "        \"\"\"\n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        model2.eval()\n",
    "\n",
    "        print(loss1)\n",
    "        print('\\n loss2')\n",
    "        print(loss2)\n",
    "        \"\"\"\n",
    "        print(loss1)\n",
    "        print('\\n loss2')\n",
    "        print(loss2)\n",
    "    print(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6357, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5807, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5918, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7268, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4773, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5969, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7638, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4739, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4817, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6064, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5092, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2539, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4768, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3950, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3419, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4096, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7907, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6070, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2276, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4615, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3400, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3527, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2760, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2597, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4517, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2886, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2937, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2649, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3160, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1673, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3647, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6547, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2438, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4573, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3153, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3253, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1219, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3831, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2584, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2693, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2028, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3353, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2608, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4544, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3045, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2774, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3595, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3118, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2906, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2321, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1928, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5696, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3557, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3078, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1839, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5317, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2973, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1531, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2499, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2487, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3696, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2482, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2886, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1799, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3372, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1878, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1560, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1964, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2204, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2603, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1374, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2912, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2766, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1897, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1410, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward>)\n",
      "0\n",
      "tensor(0.2298, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3602, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4519, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3821, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3952, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2388, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3316, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4047, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2941, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1788, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4553, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2804, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2189, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2095, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1896, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2248, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2212, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6937, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2463, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1530, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3873, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2632, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2779, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2381, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1768, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2329, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1616, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2078, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0995, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1540, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0767, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2587, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3279, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1533, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1655, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1512, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0647, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0949, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3912, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0682, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1875, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1392, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2921, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1609, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0794, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0842, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2353, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2818, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1721, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1327, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1579, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1968, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1575, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1155, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1303, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1900, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0480, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2619, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2255, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1639, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1251, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1613, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3417, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1755, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2596, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2770, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2882, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0945, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1442, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2652, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3375, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0268, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2563, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1103, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4145, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1660, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1185, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0902, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2187, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0146, grad_fn=<NllLossBackward>)\n",
      "1\n",
      "tensor(0.1023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1334, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0905, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1898, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0817, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2894, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1660, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0392, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2841, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0352, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1331, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0781, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1513, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0179, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1049, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0507, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0896, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1327, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0341, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0756, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0479, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1117, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0361, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1101, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0672, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1494, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0836, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0487, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0537, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0831, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0159, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0527, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0704, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1103, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0906, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0537, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1783, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0629, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1650, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4639, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0146, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0939, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0536, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1596, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0915, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1881, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0640, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0915, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0889, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0551, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0282, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1629, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1596, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0553, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0575, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0880, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0588, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1426, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0441, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1555, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0552, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0957, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3525, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1358, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0320, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1101, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0866, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1186, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1665, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1506, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1559, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1590, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2268, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0680, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0310, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1213, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0964, grad_fn=<NllLossBackward>)\n",
      "2\n",
      "tensor(0.1965, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2590, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0694, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1254, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3430, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1743, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1959, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1936, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2279, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2188, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1802, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1672, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0568, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1359, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1440, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0701, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2651, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0560, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0279, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0663, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1438, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1553, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0419, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0675, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0991, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1411, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0415, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0627, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1738, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0844, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0131, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1185, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0617, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0205, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0891, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1327, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0527, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0905, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0358, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1324, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0843, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1235, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0406, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0685, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0536, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1534, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2068, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0566, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0816, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0544, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0619, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1744, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1608, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0567, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0373, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0603, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1310, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0091, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0704, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0375, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0794, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2034, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0816, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0950, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0334, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0317, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0908, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0219, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1957, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0410, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0478, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0640, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "3\n",
      "tensor(0.0132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0816, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0331, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0512, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0145, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0131, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0635, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0765, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0150, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0699, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0146, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0649, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0156, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1042, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0141, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0137, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0146, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0415, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0298, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0276, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0383, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0350, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0543, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1047, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0654, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0805, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0678, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0647, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0603, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0809, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0301, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0203, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0151, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0364, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0159, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0332, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0744, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0079, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0969, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0546, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0511, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0175, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0815, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0107, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0136, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0629, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0155, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0814, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0739, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1607, grad_fn=<NllLossBackward>)\n",
      "4\n",
      "tensor(0.0297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0905, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0273, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1907, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0536, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1232, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0908, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1687, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0845, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0579, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0814, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0336, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0812, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0781, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0635, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0496, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0479, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0254, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0406, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0327, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0781, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0506, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0537, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0303, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0224, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0670, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0663, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0321, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0567, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1529, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1361, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0327, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0357, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0238, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0276, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1565, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1528, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0502, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0560, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0087, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0717, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0339, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0136, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0516, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0106, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0160, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0615, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0253, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0332, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0965, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0344, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4429, grad_fn=<NllLossBackward>)\n",
      "5\n",
      "tensor(0.1213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0691, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5612, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1696, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0786, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2836, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2643, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0642, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1833, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0814, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1500, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0889, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1092, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0506, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1981, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1000, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1270, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0597, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0765, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0608, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0943, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1888, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1367, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0480, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1734, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0815, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0845, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0586, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0603, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0668, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0392, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0650, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0450, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0400, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0831, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0276, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0591, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0904, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0494, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0352, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0899, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0404, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0770, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0886, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0648, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2540, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0552, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1141, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3739, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0524, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2790, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1321, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0864, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0374, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0321, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0373, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0346, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0301, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1980, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0958, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0317, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0382, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1258, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0739, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0658, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0616, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0381, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0916, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0674, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0595, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0506, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0482, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0294, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1064, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0389, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0784, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "6\n",
      "tensor(0.0064, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0094, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0152, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0506, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0097, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0091, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0150, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0106, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0097, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0282, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0148, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0211, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0422, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0092, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0087, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0629, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0175, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0130, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0203, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0095, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0489, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0148, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0576, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0630, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0267, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0096, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0089, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0091, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0089, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1141, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0771, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0202, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0991, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1507, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0339, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0429, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0483, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0118, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0234, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0793, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5134, grad_fn=<NllLossBackward>)\n",
      "7\n",
      "tensor(0.0050, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0141, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0727, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1871, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0197, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0271, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1946, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4049, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1317, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1361, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0875, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1562, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0296, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0256, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0189, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0598, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3411, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2338, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0965, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0606, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0771, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0188, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0688, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1075, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1882, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0596, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0403, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1145, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1839, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0256, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0781, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0316, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0391, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0442, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0427, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0951, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0250, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0439, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0256, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0205, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0182, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0354, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0141, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0098, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0594, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0941, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0693, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0101, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0530, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0112, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1042, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0365, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0130, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward>)\n",
      "tensor(4.3664, grad_fn=<NllLossBackward>)\n",
      "8\n",
      "tensor(0.0033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2365, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1197, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0691, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1667, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1068, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1603, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0136, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0307, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2355, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1663, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2669, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0575, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0564, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0406, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0146, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0413, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0944, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0804, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0618, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0429, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0279, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0808, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0153, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0219, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0209, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0105, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0136, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0169, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0105, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0148, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0527, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0171, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0094, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0327, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0372, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0110, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0220, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0098, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0083, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0235, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0350, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0160, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0116, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2499, grad_fn=<NllLossBackward>)\n",
      "9\n",
      "tensor(0.0138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1311, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2713, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3696, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2250, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1770, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1668, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2356, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0928, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2621, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0593, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0659, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0291, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1628, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1175, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0842, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0964, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0560, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2934, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0458, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0875, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0943, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0152, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0637, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0607, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0429, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0335, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0955, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0666, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0090, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0878, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0112, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0373, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0418, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0167, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0318, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0767, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2659, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0254, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0773, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0624, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0517, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0765, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0593, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0559, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0130, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0220, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0197, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0121, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0688, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0112, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0161, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0717, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0600, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0324, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1955, grad_fn=<NllLossBackward>)\n",
      "10\n",
      "tensor(0.0062, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0187, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0484, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0585, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0714, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1106, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0792, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0350, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0318, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0097, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0816, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0156, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0580, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0312, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1147, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0232, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0390, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0352, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0204, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0426, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0346, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0095, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0108, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0393, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0689, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0136, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0182, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0092, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0299, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0107, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0078, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0703, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0329, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0391, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0529, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7957, grad_fn=<NllLossBackward>)\n",
      "11\n",
      "tensor(0.0080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1666, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5105, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5802, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0156, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1600, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0752, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0917, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1110, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1625, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2479, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2123, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2744, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2442, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0881, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0633, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0534, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0937, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0306, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0239, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1242, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0810, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1341, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2185, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0263, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0248, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0673, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0183, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0183, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0254, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0282, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0494, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0087, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0167, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0450, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0338, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0276, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0105, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0169, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0094, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0154, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1722, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0304, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0108, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0165, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0673, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0358, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0169, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0254, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0282, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5666, grad_fn=<NllLossBackward>)\n",
      "12\n",
      "tensor(0.0424, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0988, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4393, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6550, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4254, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2968, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1108, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2770, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0375, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0508, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0450, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2063, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0116, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0512, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0301, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0684, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0983, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0680, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0846, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0666, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0157, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0784, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0654, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0109, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1825, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0840, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0666, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0902, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0818, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0842, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0098, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0135, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0232, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0188, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1256, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0590, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0160, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0527, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0078, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0239, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0672, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0325, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0253, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0182, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0090, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2090, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0967, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0330, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0155, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0095, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0914, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0151, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0783, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0624, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0189, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0087, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0146, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0110, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0118, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0279, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0643, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward>)\n",
      "13\n",
      "tensor(0.0028, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0097, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0624, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0548, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0680, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0200, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0219, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0152, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0442, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0105, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1108, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0084, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0096, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "14\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(6.0872e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2424e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0418, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0768, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0251, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0549, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0381, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0118, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0631, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "15\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(9.8960e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3565e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(6.8553e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(4.6259e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(6.8988e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(7.6198e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(8.0239e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(4.3754e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(8.1142e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward>)\n",
      "tensor(4.5563e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3368, grad_fn=<NllLossBackward>)\n",
      "16\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0332, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0169, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2816, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0803, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0312, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0930, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0487, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1624, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1998, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0315, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0145, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1101, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0294, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0294, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0183, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "import tqdm \n",
    "\n",
    "# Train Network\n",
    "for epoch in range(25):\n",
    "    #for batch_idx, (data, targets) in enumerate(tqdm(trainloader)):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        data, targets = data\n",
    "        data=data\n",
    "        targets=targets\n",
    "        #print('a')\n",
    "        # Get data to cuda if possible\n",
    "        #data = data.to(device=device)\n",
    "        #targets = targets.to(device=device)\n",
    "        \n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "        scores = model(data)\n",
    "        #scores2=torch.stack(list(scores), dim=0)\n",
    "        loss = criterion(scores, targets)\n",
    "        #print(targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "        print(loss)\n",
    "    print(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=.1, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            print('label')\n",
    "            print(y)\n",
    "            print('prediction next')\n",
    "            print(predictions)\n",
    "            num_correct += (predictions == (y+0)).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return num_correct/num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "tensor([4, 0, 0, 1, 0, 4, 3, 4, 0, 1, 4, 1, 0, 0, 2, 0, 4, 4, 4, 0, 4, 1, 0, 3,\n",
      "        4, 0, 0, 1, 3, 4, 0, 2, 3, 3, 2, 0, 0, 3, 2, 4, 0, 1, 0, 2, 3, 1, 1, 0,\n",
      "        0, 3, 3, 3, 1, 4, 2, 4, 3, 0, 0, 0, 3, 4, 2, 2, 2, 4, 2, 4, 2, 0, 0, 0,\n",
      "        2, 3, 2, 2, 0, 0, 0, 0, 2, 4, 4, 4, 2, 0, 4, 0, 3, 0, 0, 2, 0, 3, 3, 1,\n",
      "        0, 3, 1, 3, 1, 0, 3, 1, 2, 3, 2, 0, 0, 2, 4, 2, 1, 0, 1, 4, 0, 1, 2, 2,\n",
      "        1, 0, 0, 1, 0, 1, 2, 0, 4, 1, 1, 4, 1, 0, 0, 2, 3, 2, 4, 0, 2, 2, 3, 4,\n",
      "        4, 1, 3, 1, 2, 2, 2, 2, 3, 3, 1, 1, 3, 3, 0, 1, 4, 2, 1, 3, 1, 3, 0, 2,\n",
      "        0, 2, 0, 3, 2, 3, 4, 3, 1, 1, 2, 2, 4, 1, 1, 1, 0, 3, 2, 2, 3, 2, 2, 3,\n",
      "        0, 0, 2, 0, 4, 0, 0, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 2, 2, 1, 4, 4, 4, 0, 3, 3, 1, 4, 2, 1, 0, 4, 2, 4, 0, 4, 3, 2, 0,\n",
      "        1, 0, 3, 4, 3, 2, 2, 2, 3, 3, 2, 4, 0, 3, 1, 4, 2, 2, 1, 3, 4, 1, 4, 0,\n",
      "        2, 2, 3, 3, 4, 4, 2, 3, 3, 1, 0, 2, 4, 3, 1, 2, 2, 4, 4, 4, 2, 1, 1, 0,\n",
      "        2, 2, 1, 2, 0, 0, 0, 1, 2, 2, 4, 4, 3, 2, 4, 2, 3, 0, 4, 2, 3, 3, 1, 1,\n",
      "        4, 2, 2, 3, 0, 3, 4, 1, 4, 3, 2, 2, 1, 4, 4, 2, 4, 0, 4, 4, 0, 2, 3, 2,\n",
      "        0, 0, 2, 1, 1, 2, 1, 0, 2, 2, 4, 1, 1, 2, 0, 2, 3, 4, 4, 1, 2, 4, 3, 4,\n",
      "        4, 1, 4, 3, 2, 2, 2, 1, 0, 4, 1, 0, 4, 4, 3, 4, 2, 2, 2, 2, 2, 3, 3, 2,\n",
      "        2, 0, 4, 0, 2, 4, 4, 3, 4, 1, 3, 2, 2, 3, 2, 3, 1, 3, 2, 1, 2, 0, 2, 4,\n",
      "        3, 1, 2, 0, 1, 2, 0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([4, 1, 1, 0, 0, 2, 4, 2, 2, 1, 4, 1, 1, 1, 3, 0, 3, 0, 1, 1, 0, 2, 0, 2,\n",
      "        2, 0, 4, 2, 2, 1, 4, 4, 4, 3, 3, 3, 3, 1, 0, 0, 2, 2, 3, 1, 4, 4, 3, 0,\n",
      "        2, 3, 2, 4, 4, 2, 4, 0, 1, 2, 1, 1, 1, 1, 0, 0, 2, 0, 2, 2, 0, 0, 4, 2,\n",
      "        2, 0, 2, 0, 3, 0, 1, 3, 2, 4, 1, 1, 3, 4, 4, 3, 2, 2, 1, 4, 0, 0, 3, 2,\n",
      "        1, 3, 1, 1, 1, 3, 3, 4, 1, 3, 0, 2, 0, 2, 1, 0, 1, 0, 0, 0, 4, 4, 1, 4,\n",
      "        4, 2, 0, 3, 0, 4, 3, 2, 1, 4, 4, 0, 0, 1, 1, 3, 2, 0, 4, 4, 0, 4, 3, 0,\n",
      "        2, 1, 2, 0, 1, 4, 3, 1, 2, 0, 1, 0, 4, 0, 4, 3, 2, 1, 2, 4, 0, 0, 2, 1,\n",
      "        0, 0, 4, 0, 3, 4, 4, 3, 0, 2, 0, 1, 4, 4, 4, 2, 2, 1, 0, 2, 0, 2, 2, 3,\n",
      "        4, 1, 0, 2, 2, 0, 3, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 4, 1, 0, 2, 0, 2, 2, 1, 4, 0, 2, 4, 3, 0, 3, 0, 3, 2, 3, 2, 0, 2,\n",
      "        2, 0, 3, 4, 4, 2, 2, 2, 4, 4, 3, 4, 3, 0, 0, 0, 3, 0, 0, 3, 4, 3, 4, 0,\n",
      "        2, 3, 4, 2, 4, 1, 2, 4, 4, 3, 0, 1, 1, 0, 3, 3, 1, 3, 4, 0, 0, 2, 2, 2,\n",
      "        2, 3, 4, 1, 0, 3, 2, 3, 4, 2, 3, 4, 4, 4, 3, 2, 3, 2, 4, 4, 0, 0, 4, 0,\n",
      "        3, 2, 1, 4, 1, 1, 3, 4, 1, 3, 0, 2, 3, 2, 1, 4, 0, 1, 1, 1, 3, 1, 4, 4,\n",
      "        4, 2, 3, 3, 1, 2, 2, 3, 1, 4, 4, 0, 1, 1, 4, 4, 0, 3, 3, 2, 2, 4, 2, 4,\n",
      "        4, 0, 1, 4, 0, 4, 3, 2, 1, 2, 1, 2, 4, 2, 4, 2, 1, 3, 1, 3, 1, 0, 2, 2,\n",
      "        0, 2, 2, 4, 4, 2, 1, 4, 1, 0, 0, 4, 4, 4, 1, 2, 4, 4, 0, 0, 0, 3, 1, 3,\n",
      "        3, 1, 4, 0, 4, 4, 3, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 3, 3, 4, 4, 0, 4, 1, 3, 4, 4, 2, 1, 1, 1, 4, 4, 1, 4, 3, 1, 3, 3, 1,\n",
      "        0, 0, 3, 3, 0, 0, 1, 0, 1, 1, 0, 4, 2, 1, 2, 4, 4, 4, 2, 1, 1, 1, 1, 1,\n",
      "        2, 2, 0, 2, 0, 1, 2, 4, 2, 1, 0, 2, 2, 4, 0, 2, 0, 2, 2, 0, 2, 0, 0, 3,\n",
      "        2, 4, 0, 1, 3, 3, 1, 2, 0, 4, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 3, 0,\n",
      "        0, 0, 1, 3, 0, 1, 2, 0, 0, 4, 3, 1, 3, 2, 1, 3, 1, 2, 2, 4, 4, 3, 2, 0,\n",
      "        0, 4, 3, 1, 1, 0, 2, 4, 1, 0, 3, 4, 4, 2, 2, 2, 0, 3, 4, 4, 0, 1, 1, 4,\n",
      "        2, 2, 3, 3, 1, 0, 1, 4, 3, 1, 2, 4, 1, 4, 0, 3, 4, 1, 1, 4, 1, 3, 3, 1,\n",
      "        3, 4, 4, 0, 0, 3, 2, 1, 0, 1, 0, 2, 0, 2, 2, 0, 3, 2, 1, 2, 2, 2, 1, 2,\n",
      "        2, 0, 1, 2, 0, 1, 3, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 2, 1, 3, 4, 4, 3, 4, 3, 2, 3, 4, 1, 0, 2, 4, 4, 1, 0, 3, 0, 3, 1, 1,\n",
      "        1, 4, 3, 4, 0, 1, 0, 0, 3, 1, 1, 1, 4, 4, 3, 4, 4, 1, 1, 3, 2, 0, 1, 2,\n",
      "        2, 2, 0, 3, 2, 1, 1, 2, 2, 1, 2, 4, 4, 4, 2, 2, 4, 2, 3, 0, 4, 1, 0, 4,\n",
      "        2, 2, 3, 4, 2, 2, 4, 1, 0, 4, 4, 3, 1, 1, 2, 4, 4, 0, 0, 2, 1, 2, 3, 4,\n",
      "        3, 2, 1, 2, 0, 4, 4, 3, 3, 2, 2, 4, 0, 2, 4, 3, 0, 3, 2, 4, 4, 3, 2, 0,\n",
      "        2, 4, 2, 1, 4, 0, 0, 1, 2, 2, 3, 0, 4, 4, 4, 4, 4, 2, 3, 4, 4, 2, 1, 2,\n",
      "        4, 3, 1, 3, 2, 0, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 4, 4, 2, 4,\n",
      "        2, 4, 2, 4, 4, 2, 4, 2, 4, 1, 2, 1, 1, 1, 4, 0, 3, 2, 3, 2, 4, 2, 1, 4,\n",
      "        1, 2, 1, 2, 1, 3, 3, 3], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 1, 3, 1, 3, 1, 2, 1, 3, 3, 0, 1, 0, 2, 1, 0, 3, 0, 0, 2, 3, 2, 1,\n",
      "        3, 4, 3, 2, 2, 2, 3, 0, 1, 0, 4, 0, 2, 3, 3, 1, 1, 3, 1, 2, 2, 2, 3, 0,\n",
      "        4, 0, 4, 0, 2, 3, 0, 0, 0, 1, 0, 1, 4, 1, 4, 1, 4, 4, 4, 0, 1, 4, 2, 4,\n",
      "        0, 2, 0, 4, 3, 4, 0, 4, 1, 0, 4, 4, 1, 2, 4, 4, 3, 1, 0, 2, 1, 1, 3, 3,\n",
      "        2, 4, 3, 2, 0, 1, 2, 3, 2, 1, 2, 0, 1, 4, 0, 1, 1, 0, 0, 4, 0, 3, 3, 4,\n",
      "        2, 1, 4, 3, 1, 3, 4, 2, 2, 4, 0, 1, 4, 4, 0, 4, 3, 1, 1, 0, 2, 0, 3, 0,\n",
      "        1, 2, 2, 3, 1, 3, 3, 0, 2, 2, 3, 4, 4, 1, 2, 0, 0, 0, 2, 3, 4, 4, 3, 0,\n",
      "        0, 0, 3, 3, 4, 3, 3, 1, 2, 2, 1, 1, 2, 1, 3, 4, 1, 1, 2, 1, 2, 0, 4, 3,\n",
      "        0, 3, 3, 0, 0, 1, 0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 2, 1, 4, 1, 3, 0, 2, 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 2, 1, 3, 3, 2, 1,\n",
      "        4, 4, 4, 2, 2, 4, 3, 1, 1, 1, 2, 2, 2, 0, 3, 3, 0, 3, 4, 4, 2, 2, 4, 0,\n",
      "        0, 1, 1, 0, 1, 3, 4, 1, 0, 2, 1, 1, 4, 1, 1, 2, 4, 4, 4, 4, 0, 1, 2, 3,\n",
      "        1, 1, 1, 2, 4, 4, 2, 3, 4, 0, 3, 1, 3, 2, 0, 2, 2, 2, 2, 4, 0, 1, 3, 3,\n",
      "        1, 0, 4, 2, 0, 1, 2, 4, 1, 4, 2, 0, 4, 3, 1, 1, 4, 0, 0, 3, 0, 3, 4, 2,\n",
      "        3, 4, 4, 2, 4, 4, 0, 2, 0, 3, 4, 3, 3, 2, 0, 3, 3, 1, 2, 3, 4, 2, 4, 0,\n",
      "        0, 2, 4, 2, 2, 4, 3, 1, 2, 2, 2, 2, 4, 2, 4, 4, 0, 0, 2, 0, 2, 0, 3, 1,\n",
      "        0, 4, 4, 3, 4, 2, 4, 3, 0, 2, 4, 0, 2, 4, 0, 2, 1, 1, 2, 3, 2, 2, 2, 4,\n",
      "        0, 4, 3, 4, 0, 4, 1, 4], device='cuda:0')\n",
      "label\n",
      "tensor([1, 4, 4, 2, 3, 0, 4, 1, 0, 0, 2, 4, 3, 3, 4, 0, 3, 0, 1, 2, 4, 4, 4, 2,\n",
      "        2, 1, 1, 2, 0, 0, 4, 0, 2, 0, 1, 0, 4, 0, 3, 0, 4, 0, 0, 0, 0, 2, 0, 3,\n",
      "        0, 3, 1, 4, 1, 4, 4, 4, 4, 3, 1, 1, 1, 0, 4, 1, 3, 0, 0, 0, 0, 2, 2, 2,\n",
      "        0, 2, 4, 1, 1, 4, 3, 2, 2, 4, 3, 0, 2, 4, 0, 0, 4, 2, 0, 2, 2, 1, 2, 3,\n",
      "        4, 0, 0, 4, 2, 4, 1, 1, 1, 4, 4, 4, 2, 0, 2, 2, 0, 0, 4, 4, 1, 2, 2, 4,\n",
      "        1, 4, 0, 1, 0, 0, 2, 2, 3, 3, 0, 2, 1, 0, 2, 3, 2, 3, 1, 1, 4, 4, 1, 0,\n",
      "        1, 4, 2, 3, 4, 3, 2, 0, 3, 1, 0, 2, 2, 1, 1, 2, 3, 3, 2, 1, 1, 2, 4, 4,\n",
      "        3, 3, 2, 1, 1, 3, 1, 2, 2, 3, 1, 1, 0, 2, 2, 4, 1, 1, 2, 3, 4, 4, 1, 2,\n",
      "        0, 4, 3, 1, 0, 0, 3, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 0, 4, 4, 3, 1, 4, 2, 3, 2, 4, 4, 2, 3, 2, 0, 3, 0, 0, 3, 3, 3, 1, 2,\n",
      "        2, 4, 2, 0, 4, 4, 4, 1, 0, 0, 3, 2, 4, 1, 3, 1, 3, 3, 2, 2, 3, 3, 4, 3,\n",
      "        1, 3, 1, 3, 2, 4, 4, 3, 3, 3, 1, 1, 1, 1, 4, 2, 4, 1, 1, 0, 2, 2, 2, 2,\n",
      "        0, 2, 4, 1, 1, 3, 3, 2, 4, 4, 3, 0, 2, 3, 4, 2, 2, 0, 0, 2, 3, 2, 4, 3,\n",
      "        3, 3, 0, 4, 4, 4, 1, 1, 1, 3, 4, 4, 2, 4, 4, 2, 3, 4, 4, 2, 4, 4, 4, 4,\n",
      "        4, 2, 0, 2, 0, 0, 2, 1, 3, 3, 4, 1, 4, 3, 2, 4, 0, 3, 1, 3, 4, 4, 1, 2,\n",
      "        3, 4, 1, 2, 2, 4, 2, 0, 3, 2, 1, 2, 3, 1, 1, 2, 2, 3, 2, 1, 4, 2, 0, 4,\n",
      "        4, 3, 2, 1, 1, 4, 1, 2, 2, 1, 1, 1, 0, 4, 3, 2, 2, 1, 4, 0, 4, 3, 2, 0,\n",
      "        3, 0, 3, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "label\n",
      "tensor([0, 2, 0, 1, 2, 3, 0, 1, 1, 0, 4, 2, 4, 2, 0, 0, 1, 4, 1, 3, 0, 0, 1, 4,\n",
      "        2, 3, 1, 1, 1, 2, 2, 2, 3, 4, 3, 4, 2, 4, 1, 2, 3, 3, 2, 0, 2, 0, 2, 2,\n",
      "        0, 1, 0, 4, 2, 3, 3, 4, 0, 3, 1, 2, 2, 1, 0, 3, 0, 0, 1, 1, 0, 1, 2, 2,\n",
      "        3, 0, 2, 4, 0, 4, 1, 3, 2, 4, 1, 2, 3, 1, 0, 1, 4, 0, 2, 4, 3, 2, 2, 0,\n",
      "        4, 2, 1, 3, 1, 0, 3, 3, 1, 2, 4, 2, 4, 3, 2, 4, 2, 2, 2, 3, 4, 4, 4, 4,\n",
      "        0, 1, 1, 3, 4, 3, 1, 0, 3, 2, 2, 3, 1, 1, 1, 0, 2, 1, 2, 2, 2, 4, 2, 2,\n",
      "        0, 4, 4, 0, 3, 1, 4, 3, 1, 3, 0, 3, 3, 0, 3, 0, 0, 4, 1, 0, 2, 1, 1, 1,\n",
      "        0, 2, 2, 1, 0, 1, 2, 4, 2, 1, 1, 1, 1, 1, 4, 0, 4, 0, 2, 1, 3, 0, 1, 0,\n",
      "        1, 1, 3, 0, 4, 2, 2, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 2, 1, 2, 4, 3, 2, 4, 4, 0, 4, 2, 4, 2, 0, 0, 1, 3, 1, 2, 1, 4, 1, 4,\n",
      "        3, 2, 4, 3, 1, 3, 2, 1, 2, 2, 4, 3, 2, 3, 1, 2, 0, 3, 2, 0, 2, 1, 3, 3,\n",
      "        0, 1, 1, 0, 4, 2, 4, 2, 0, 3, 0, 4, 2, 4, 3, 3, 0, 3, 1, 2, 1, 2, 3, 2,\n",
      "        0, 0, 2, 3, 2, 4, 1, 0, 0, 4, 2, 2, 0, 2, 3, 1, 4, 0, 1, 3, 3, 1, 4, 0,\n",
      "        4, 3, 1, 3, 1, 4, 4, 3, 1, 2, 4, 2, 4, 2, 4, 0, 2, 3, 4, 4, 4, 2, 3, 4,\n",
      "        1, 3, 3, 4, 1, 0, 3, 0, 3, 2, 3, 3, 2, 4, 1, 1, 4, 0, 2, 3, 2, 2, 3, 2,\n",
      "        2, 1, 2, 0, 3, 0, 2, 3, 4, 2, 0, 3, 3, 0, 3, 2, 0, 4, 4, 2, 2, 1, 4, 3,\n",
      "        4, 4, 2, 1, 0, 4, 2, 4, 4, 2, 1, 3, 1, 4, 1, 1, 1, 2, 4, 3, 3, 2, 0, 2,\n",
      "        0, 2, 3, 0, 3, 4, 2, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 1, 3, 2, 1, 1, 0, 2, 1, 2, 2, 2, 0, 3, 0, 2, 4, 2, 2, 3, 0, 0, 1,\n",
      "        4, 3, 2, 3, 0, 2, 2, 1, 4, 3, 1, 4, 0, 0, 3, 2, 2, 1, 0, 4, 0, 2, 4, 4,\n",
      "        0, 2, 2, 2, 1, 1, 3, 1, 0, 0, 1, 0, 0, 2, 3, 2, 2, 0, 3, 1, 4, 1, 1, 0,\n",
      "        1, 2, 1, 1, 4, 1, 4, 4, 3, 4, 3, 3, 2, 2, 0, 0, 4, 4, 1, 2, 2, 1, 3, 4,\n",
      "        3, 0, 2, 4, 4, 0, 1, 0, 3, 1, 1, 3, 4, 4, 0, 3, 2, 3, 3, 3, 0, 1, 3, 4,\n",
      "        4, 1, 2, 2, 2, 0, 1, 0, 4, 2, 0, 1, 0, 2, 0, 0, 2, 3, 0, 0, 4, 2, 0, 4,\n",
      "        4, 0, 4, 4, 4, 4, 0, 1, 2, 3, 0, 4, 2, 0, 0, 2, 2, 4, 1, 0, 1, 3, 4, 1,\n",
      "        4, 1, 1, 2, 0, 4, 4, 3, 0, 2, 3, 0, 2, 3, 4, 4, 1, 0, 3, 4, 4, 0, 2, 4,\n",
      "        3, 1, 4, 3, 4, 1, 3, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 3, 3, 3, 4, 1, 1, 2, 2, 1, 3, 2, 2, 2, 3, 2, 2, 4, 4, 4, 4, 0, 1, 0,\n",
      "        4, 4, 4, 0, 2, 4, 2, 2, 3, 3, 2, 3, 0, 4, 3, 2, 2, 0, 0, 1, 2, 1, 2, 3,\n",
      "        2, 2, 2, 1, 4, 1, 3, 2, 1, 3, 2, 2, 4, 2, 3, 4, 1, 4, 2, 1, 4, 1, 1, 3,\n",
      "        2, 0, 4, 3, 0, 3, 4, 2, 3, 4, 3, 3, 4, 1, 1, 0, 4, 4, 4, 2, 4, 4, 2, 3,\n",
      "        3, 1, 2, 1, 4, 4, 0, 0, 4, 2, 1, 3, 4, 1, 0, 4, 4, 4, 4, 2, 1, 2, 1, 4,\n",
      "        3, 3, 4, 2, 2, 0, 0, 0, 4, 2, 2, 4, 0, 2, 1, 1, 4, 4, 0, 2, 4, 2, 0, 4,\n",
      "        2, 0, 4, 3, 2, 4, 4, 1, 3, 3, 2, 4, 1, 2, 0, 4, 2, 2, 1, 0, 4, 2, 4, 3,\n",
      "        4, 2, 2, 2, 2, 4, 4, 1, 1, 4, 3, 1, 1, 3, 3, 4, 1, 1, 3, 4, 3, 2, 2, 2,\n",
      "        3, 2, 4, 4, 2, 2, 2, 3], device='cuda:0')\n",
      "label\n",
      "tensor([3, 3, 2, 4, 1, 1, 0, 4, 0, 0, 3, 4, 4, 1, 4, 1, 2, 4, 2, 3, 2, 2, 2, 4,\n",
      "        4, 2, 3, 3, 4, 3, 4, 2, 0, 2, 3, 3, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2,\n",
      "        3, 0, 1, 4, 0, 1, 2, 1, 0, 2, 3, 1, 2, 4, 1, 3, 1, 2, 4, 2, 4, 0, 3, 4,\n",
      "        2, 0, 3, 2, 0, 0, 3, 2, 1, 2, 2, 2, 0, 2, 4, 2, 2, 2, 0, 4, 0, 0, 1, 0,\n",
      "        2, 1, 3, 1, 1, 2, 2, 1, 0, 0, 3, 3, 2, 0, 2, 2, 3, 4, 3, 2, 0, 4, 0, 2,\n",
      "        4, 1, 2, 3, 4, 1, 1, 0, 4, 4, 0, 3, 2, 1, 0, 0, 4, 0, 4, 0, 3, 3, 0, 2,\n",
      "        2, 4, 3, 3, 4, 0, 1, 0, 3, 1, 0, 1, 3, 1, 0, 4, 2, 3, 3, 2, 4, 4, 3, 3,\n",
      "        3, 3, 0, 0, 4, 1, 1, 2, 2, 4, 1, 0, 1, 1, 1, 0, 0, 4, 3, 1, 3, 2, 3, 3,\n",
      "        1, 1, 0, 2, 0, 3, 1, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 0, 2, 4, 1, 2, 2, 3, 0, 3, 2, 1, 4, 1, 2, 3, 2, 1, 2, 4, 2, 2, 2, 4,\n",
      "        4, 2, 3, 0, 4, 3, 0, 4, 1, 2, 0, 4, 1, 4, 0, 1, 2, 1, 0, 3, 1, 1, 0, 2,\n",
      "        4, 4, 4, 4, 4, 0, 2, 3, 3, 4, 3, 1, 2, 4, 1, 1, 0, 3, 4, 2, 4, 0, 3, 0,\n",
      "        4, 4, 3, 2, 0, 0, 3, 3, 4, 4, 1, 2, 4, 2, 4, 2, 4, 4, 0, 2, 1, 0, 1, 0,\n",
      "        1, 2, 3, 4, 1, 2, 2, 0, 0, 4, 4, 3, 2, 2, 2, 4, 4, 2, 2, 1, 3, 4, 2, 2,\n",
      "        3, 0, 4, 3, 2, 1, 2, 3, 2, 4, 1, 2, 4, 1, 3, 1, 4, 3, 4, 1, 3, 4, 3, 2,\n",
      "        2, 4, 3, 3, 4, 1, 1, 0, 1, 1, 4, 1, 2, 3, 2, 3, 2, 3, 3, 2, 4, 2, 4, 3,\n",
      "        3, 3, 2, 3, 2, 3, 0, 4, 4, 4, 2, 4, 1, 1, 4, 2, 2, 0, 3, 4, 1, 3, 4, 3,\n",
      "        1, 2, 2, 2, 2, 3, 1, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 2, 2, 4, 1, 2, 4, 1, 2, 3, 4, 2, 4, 0, 0, 4, 4, 0, 1, 2, 1, 0, 0, 4,\n",
      "        1, 0, 0, 0, 4, 3, 3, 0, 0, 2, 1, 2, 4, 1, 2, 0, 2, 3, 0, 4, 3, 1, 1, 3,\n",
      "        4, 2, 0, 0, 4, 4, 2, 0, 0, 1, 0, 3, 4, 3, 4, 3, 2, 3, 1, 4, 3, 1, 3, 3,\n",
      "        4, 4, 2, 2, 0, 2, 1, 2, 2, 4, 4, 0, 3, 1, 0, 4, 2, 2, 4, 2, 3, 3, 2, 0,\n",
      "        2, 1, 2, 2, 2, 3, 2, 4, 1, 1, 3, 3, 0, 0, 3, 2, 3, 1, 0, 3, 3, 0, 2, 2,\n",
      "        0, 1, 2, 3, 2, 3, 1, 0, 0, 4, 3, 4, 1, 0, 4, 4, 2, 0, 1, 1, 3, 3, 4, 4,\n",
      "        1, 1, 4, 2, 2, 2, 2, 1, 3, 0, 2, 4, 2, 0, 2, 2, 2, 1, 3, 4, 1, 2, 2, 4,\n",
      "        1, 2, 3, 3, 2, 3, 0, 1, 2, 2, 0, 3, 0, 1, 1, 2, 4, 3, 3, 0, 1, 0, 1, 3,\n",
      "        1, 3, 4, 0, 2, 0, 1, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 2, 2, 1, 4, 2, 2, 4, 3, 2, 1, 4, 2, 3, 3, 2, 2, 1, 2, 2, 0, 1, 3,\n",
      "        1, 1, 2, 1, 2, 3, 3, 0, 2, 2, 1, 2, 4, 1, 1, 0, 2, 3, 0, 3, 3, 4, 4, 4,\n",
      "        3, 3, 4, 0, 3, 0, 2, 2, 0, 3, 1, 2, 3, 4, 4, 2, 4, 3, 4, 3, 2, 1, 2, 0,\n",
      "        2, 2, 4, 4, 2, 2, 1, 4, 4, 4, 3, 0, 4, 3, 4, 2, 0, 2, 2, 2, 3, 4, 2, 0,\n",
      "        2, 2, 4, 2, 2, 4, 2, 4, 1, 3, 4, 3, 0, 4, 2, 4, 3, 3, 0, 3, 3, 0, 4, 4,\n",
      "        0, 2, 2, 3, 2, 3, 4, 3, 4, 1, 4, 0, 3, 1, 1, 4, 4, 2, 1, 1, 1, 3, 4, 3,\n",
      "        2, 0, 2, 4, 1, 3, 4, 3, 0, 2, 2, 3, 2, 0, 4, 2, 2, 1, 1, 4, 1, 2, 0, 4,\n",
      "        0, 2, 4, 2, 2, 3, 2, 1, 2, 2, 0, 4, 0, 0, 1, 2, 2, 2, 3, 2, 4, 2, 2, 1,\n",
      "        1, 3, 4, 0, 3, 1, 1, 1], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 3, 0, 2, 0, 1, 1, 4, 1, 3, 3, 2, 4, 3, 0, 1, 0, 1, 1, 2, 2, 4, 0,\n",
      "        1, 3, 0, 4, 0, 2, 2, 2, 1, 0, 4, 0, 1, 1, 2, 1, 3, 2, 1, 1, 0, 2, 2, 4,\n",
      "        2, 0, 3, 2, 0, 3, 3, 3, 0, 2, 4, 0, 0, 0, 2, 1, 1, 4, 2, 1, 2, 0, 3, 3,\n",
      "        0, 4, 4, 1, 1, 2, 4, 0, 0, 4, 4, 3, 1, 0, 1, 4, 1, 1, 1, 4, 0, 1, 2, 4,\n",
      "        1, 4, 0, 4, 0, 0, 3, 2, 4, 1, 1, 1, 4, 2, 1, 0, 2, 0, 3, 1, 0, 3, 4, 4,\n",
      "        0, 4, 1, 2, 3, 3, 2, 1, 0, 4, 3, 2, 2, 3, 0, 1, 4, 0, 1, 0, 1, 2, 2, 0,\n",
      "        4, 2, 2, 2, 1, 3, 0, 3, 2, 0, 4, 3, 0, 1, 0, 2, 4, 1, 0, 2, 1, 4, 1, 0,\n",
      "        1, 1, 2, 2, 1, 2, 4, 4, 2, 1, 3, 3, 0, 4, 1, 4, 2, 0, 4, 0, 2, 4, 3, 1,\n",
      "        2, 4, 0, 0, 1, 0, 1, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 3, 4, 4, 4, 3, 2, 1, 3, 3, 4, 2, 4, 4, 3, 2, 1, 4, 0, 0, 1, 0, 4, 3,\n",
      "        3, 1, 1, 4, 0, 4, 4, 2, 4, 2, 4, 1, 0, 2, 2, 3, 2, 2, 1, 1, 4, 2, 2, 4,\n",
      "        1, 0, 3, 4, 0, 4, 2, 2, 0, 2, 3, 2, 4, 4, 4, 1, 4, 4, 2, 2, 2, 0, 3, 3,\n",
      "        0, 3, 2, 2, 0, 1, 2, 2, 1, 3, 2, 3, 2, 1, 1, 3, 4, 0, 2, 1, 0, 1, 2, 2,\n",
      "        1, 1, 4, 4, 0, 1, 3, 1, 2, 4, 1, 2, 3, 3, 3, 0, 2, 0, 2, 1, 4, 3, 4, 2,\n",
      "        0, 4, 4, 2, 3, 2, 2, 0, 4, 2, 3, 3, 4, 4, 1, 1, 4, 0, 1, 1, 0, 2, 3, 3,\n",
      "        4, 4, 2, 3, 3, 4, 0, 3, 4, 3, 0, 2, 2, 2, 4, 0, 3, 4, 1, 2, 1, 4, 2, 0,\n",
      "        1, 1, 2, 2, 2, 2, 1, 4, 4, 1, 4, 3, 4, 4, 2, 4, 2, 2, 0, 4, 4, 3, 3, 3,\n",
      "        1, 3, 0, 2, 2, 2, 1, 1], device='cuda:0')\n",
      "label\n",
      "tensor([2, 3, 0, 0, 0, 4, 2, 4, 2, 2, 2, 1, 0, 2, 4, 3, 2, 0, 0, 3, 2, 2, 2, 4,\n",
      "        1, 1, 4, 4, 3, 3, 1, 3, 0, 3, 1, 1, 1, 3, 0, 1, 1, 3, 4, 3, 0, 2, 1, 4,\n",
      "        4, 3, 4, 4, 4, 1, 0, 4, 4, 2, 0, 4, 3, 3, 3, 3, 2, 1, 2, 1, 2, 1, 2, 1,\n",
      "        0, 3, 0, 0, 3, 0, 1, 2, 0, 1, 1, 4, 0, 2, 3, 2, 0, 0, 3, 0, 2, 2, 1, 4,\n",
      "        3, 1, 2, 2, 2, 2, 0, 2, 3, 0, 1, 4, 0, 1, 0, 0, 4, 1, 0, 2, 0, 2, 2, 0,\n",
      "        2, 4, 1, 4, 0, 0, 1, 1, 3, 2, 1, 2, 3, 1, 0, 2, 3, 3, 2, 0, 1, 0, 2, 1,\n",
      "        2, 4, 0, 2, 3, 2, 0, 2, 0, 1, 3, 2, 3, 2, 1, 0, 2, 3, 2, 4, 0, 2, 1, 2,\n",
      "        0, 3, 0, 1, 4, 4, 2, 1, 0, 2, 1, 1, 4, 4, 1, 3, 1, 2, 0, 1, 4, 3, 1, 2,\n",
      "        3, 2, 4, 4, 4, 0, 4, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 3, 0, 0, 4, 1, 4, 4, 4, 2, 2, 0, 0, 4, 2, 4, 4, 2, 1, 3, 4, 2, 1, 3,\n",
      "        3, 0, 1, 4, 3, 2, 1, 4, 4, 0, 1, 1, 2, 3, 2, 2, 1, 3, 4, 0, 0, 4, 1, 4,\n",
      "        4, 0, 2, 4, 4, 4, 4, 4, 4, 2, 0, 4, 3, 3, 4, 3, 1, 0, 2, 1, 4, 1, 2, 1,\n",
      "        4, 3, 1, 1, 3, 3, 4, 1, 1, 3, 1, 2, 3, 3, 2, 2, 1, 4, 1, 0, 4, 1, 3, 2,\n",
      "        4, 4, 2, 2, 0, 1, 4, 4, 3, 3, 1, 3, 0, 4, 1, 4, 1, 0, 3, 2, 0, 4, 2, 1,\n",
      "        2, 1, 4, 2, 0, 1, 2, 4, 3, 0, 2, 3, 0, 0, 0, 2, 3, 3, 2, 4, 0, 3, 1, 2,\n",
      "        3, 4, 3, 4, 3, 2, 1, 1, 2, 3, 1, 2, 2, 1, 4, 4, 3, 4, 2, 2, 0, 0, 1, 4,\n",
      "        0, 3, 2, 2, 1, 4, 2, 1, 3, 2, 2, 3, 2, 2, 2, 2, 3, 3, 0, 2, 4, 4, 2, 2,\n",
      "        4, 1, 2, 4, 4, 2, 4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 0, 2, 0, 0, 2, 0, 3, 0, 2, 0, 4, 3, 2, 2, 1, 0, 4, 3, 0, 4, 0, 0,\n",
      "        3, 0, 2, 1, 0, 0, 1, 3, 1, 2, 0, 2, 0, 1, 0, 3, 1, 0, 0, 0, 4, 1, 1, 2,\n",
      "        1, 0, 4, 3, 1, 1, 3, 2, 1, 0, 0, 0, 4, 2, 3, 3, 1, 1, 2, 1, 0, 0, 2, 1,\n",
      "        4, 0, 0, 4, 1, 2, 1, 4, 1, 3, 4, 2, 4, 4, 1, 0, 1, 3, 4, 2, 2, 4, 4, 0,\n",
      "        1, 3, 2, 0, 2, 2, 0, 1, 0, 3, 4, 3, 1, 2, 3, 3, 3, 4, 2, 1, 4, 4, 1, 3,\n",
      "        2, 2, 0, 2, 4, 0, 2, 2, 1, 2, 0, 0, 3, 4, 2, 0, 1, 2, 2, 2, 2, 2, 0, 3,\n",
      "        2, 4, 2, 2, 1, 4, 0, 2, 1, 0, 3, 3, 1, 1, 2, 3, 2, 2, 3, 2, 3, 3, 0, 3,\n",
      "        2, 1, 2, 1, 2, 4, 1, 2, 3, 3, 2, 0, 0, 2, 3, 2, 2, 2, 3, 1, 1, 4, 1, 0,\n",
      "        2, 1, 1, 3, 2, 0, 0, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 0, 3, 2, 3, 4, 3, 1, 4, 1, 3, 2, 4, 3, 2, 0, 3, 0, 3, 2, 2, 4, 0, 3,\n",
      "        2, 1, 2, 1, 0, 1, 2, 3, 4, 2, 1, 1, 3, 1, 0, 3, 3, 0, 4, 1, 4, 4, 1, 3,\n",
      "        4, 0, 2, 3, 1, 1, 3, 3, 2, 1, 0, 4, 2, 2, 4, 0, 1, 1, 4, 1, 2, 2, 4, 4,\n",
      "        4, 1, 4, 4, 4, 4, 1, 3, 3, 4, 2, 1, 1, 4, 4, 2, 1, 3, 2, 3, 2, 0, 4, 4,\n",
      "        1, 0, 3, 1, 4, 2, 1, 4, 0, 3, 4, 3, 3, 2, 3, 3, 3, 4, 2, 4, 4, 3, 1, 4,\n",
      "        3, 0, 2, 1, 4, 4, 2, 2, 1, 2, 2, 1, 3, 4, 4, 0, 2, 1, 0, 2, 0, 4, 1, 3,\n",
      "        2, 4, 4, 2, 1, 2, 1, 2, 4, 1, 3, 3, 1, 0, 2, 4, 2, 4, 3, 4, 1, 3, 3, 3,\n",
      "        4, 1, 2, 1, 3, 4, 2, 4, 3, 3, 2, 3, 4, 2, 3, 4, 2, 2, 2, 3, 1, 3, 4, 3,\n",
      "        2, 2, 1, 3, 2, 3, 0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 2, 2, 3, 1, 3, 0, 1, 4, 4, 2, 4, 0, 0, 1, 2, 0, 4, 1, 4, 4, 1, 0,\n",
      "        0, 2, 4, 3, 2, 4, 1, 4, 3, 0, 1, 4, 3, 4, 1, 1, 0, 3, 0, 0, 4, 1, 3, 0,\n",
      "        1, 0, 1, 2, 1, 4, 0, 0, 4, 2, 0, 3, 1, 2, 1, 2, 1, 3, 2, 1, 2, 4, 3, 1,\n",
      "        4, 0, 1, 4, 2, 2, 0, 1, 2, 3, 0, 2, 1, 0, 0, 1, 1, 3, 0, 0, 0, 3, 2, 0,\n",
      "        3, 3, 0, 3, 1, 2, 3, 2, 4, 0, 0, 2, 0, 1, 4, 2, 2, 4, 2, 1, 4, 2, 3, 4,\n",
      "        2, 2, 2, 4, 1, 2, 0, 1, 1, 4, 4, 4, 2, 1, 3, 2, 0, 0, 3, 2, 0, 0, 4, 1,\n",
      "        1, 2, 3, 0, 1, 2, 3, 3, 2, 2, 4, 0, 2, 1, 0, 4, 1, 1, 4, 2, 0, 1, 4, 2,\n",
      "        2, 4, 2, 3, 0, 3, 3, 0, 2, 0, 1, 2, 2, 3, 0, 1, 2, 1, 4, 0, 2, 3, 1, 3,\n",
      "        1, 3, 2, 0, 0, 2, 4, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 0, 1, 2, 4, 1, 2, 4, 1, 4, 4, 2, 4, 1, 4, 1, 3, 2, 4, 1, 4, 2, 1, 4,\n",
      "        2, 4, 4, 0, 4, 4, 0, 2, 3, 2, 2, 4, 2, 0, 1, 2, 2, 3, 0, 4, 3, 2, 3, 0,\n",
      "        3, 2, 1, 3, 1, 4, 4, 1, 1, 4, 2, 2, 4, 2, 4, 4, 4, 4, 0, 3, 4, 2, 3, 1,\n",
      "        1, 3, 2, 3, 2, 4, 0, 1, 1, 4, 3, 2, 3, 1, 0, 2, 1, 3, 0, 4, 0, 4, 4, 1,\n",
      "        2, 4, 4, 2, 2, 4, 1, 2, 0, 0, 2, 2, 0, 2, 4, 3, 1, 3, 4, 2, 4, 0, 3, 1,\n",
      "        1, 4, 3, 4, 3, 4, 0, 3, 0, 3, 4, 2, 1, 4, 3, 4, 4, 1, 2, 2, 4, 4, 4, 2,\n",
      "        3, 3, 3, 0, 1, 0, 3, 3, 4, 2, 2, 0, 2, 4, 1, 2, 2, 4, 2, 0, 0, 0, 4, 4,\n",
      "        2, 2, 2, 4, 0, 2, 2, 3, 4, 4, 4, 3, 2, 3, 0, 1, 2, 4, 2, 0, 2, 3, 4, 3,\n",
      "        1, 3, 4, 4, 2, 2, 1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([4, 2, 0, 2, 0, 0, 3, 1, 1, 0, 2, 1, 2, 0, 1, 2, 4, 4, 4, 2, 2, 0, 2, 1,\n",
      "        4, 1, 2, 1, 4, 0, 2, 0, 4, 4, 0, 0, 4, 3, 4, 0, 0, 2, 4, 4, 2, 4, 0, 0,\n",
      "        2, 1, 2, 1, 1, 2, 3, 4, 0, 3, 2, 2, 2, 0, 2, 1, 3, 1, 0, 4, 4, 0, 4, 1,\n",
      "        0, 2, 1, 1, 1, 4, 0, 0, 0, 1, 0, 3, 1, 3, 0, 2, 3, 1, 4, 0, 4, 2, 3, 2,\n",
      "        4, 0, 2, 2, 0, 2, 4, 2, 3, 3, 3, 4, 4, 1, 1, 4, 0, 1, 3, 3, 1, 2, 2, 3,\n",
      "        3, 1, 0, 3, 2, 3, 4, 3, 2, 2, 2, 0, 1, 0, 4, 4, 0, 4, 2, 3, 3, 1, 0, 4,\n",
      "        4, 2, 0, 0, 0, 4, 1, 3, 1, 1, 0, 4, 3, 4, 4, 0, 0, 0, 2, 0, 0, 0, 4, 0,\n",
      "        3, 1, 3, 4, 1, 0, 4, 3, 4, 0, 0, 2, 1, 1, 4, 0, 2, 4, 1, 1, 1, 3, 1, 1,\n",
      "        3, 3, 3, 2, 4, 3, 4, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 1, 1, 3, 3, 3, 2, 3, 2, 2, 3, 2, 0, 1, 0, 0, 1, 3, 1, 3, 3, 2, 2,\n",
      "        4, 0, 2, 4, 4, 2, 0, 4, 2, 4, 0, 3, 3, 3, 4, 0, 1, 2, 4, 3, 1, 3, 2, 2,\n",
      "        2, 3, 0, 0, 2, 4, 2, 2, 1, 2, 4, 4, 4, 1, 2, 3, 2, 1, 2, 4, 2, 0, 2, 2,\n",
      "        2, 4, 3, 1, 1, 1, 1, 0, 2, 0, 0, 3, 1, 3, 1, 0, 1, 4, 4, 1, 4, 3, 3, 4,\n",
      "        4, 0, 2, 4, 0, 4, 4, 3, 0, 3, 2, 2, 4, 1, 2, 4, 4, 2, 1, 3, 0, 2, 2, 4,\n",
      "        2, 0, 2, 3, 4, 4, 4, 1, 2, 4, 2, 0, 3, 4, 4, 2, 2, 2, 2, 3, 2, 4, 1, 4,\n",
      "        3, 3, 0, 2, 0, 2, 4, 3, 3, 0, 0, 4, 3, 4, 3, 1, 0, 4, 2, 4, 2, 0, 4, 2,\n",
      "        0, 3, 4, 2, 1, 1, 2, 2, 2, 2, 0, 2, 2, 0, 3, 0, 2, 4, 1, 4, 0, 4, 3, 3,\n",
      "        3, 0, 1, 2, 3, 3, 4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([3, 3, 0, 2, 3, 0, 3, 0, 4, 1, 4, 0, 1, 0, 0, 0, 4, 3, 2, 0, 4, 0, 1, 1,\n",
      "        4, 3, 3, 1, 0, 3, 0, 3, 2, 3, 2, 1, 4, 2, 0, 2, 3, 4, 2, 4, 4, 3, 2, 0,\n",
      "        2, 2, 3, 0, 0, 0, 2, 1, 0, 1, 1, 4, 0, 1, 4, 3, 1, 4, 2, 2, 1, 2, 0, 0,\n",
      "        0, 2, 3, 0, 4, 2, 1, 4, 0, 2, 2, 4, 0, 3, 1, 1, 3, 4, 1, 0, 2, 0, 2, 2,\n",
      "        0, 3, 0, 3, 3, 3, 2, 3, 0, 1, 4, 3, 2, 4, 3, 0, 3, 1, 1, 4, 1, 4, 4, 1,\n",
      "        0, 4, 4, 0, 3, 3, 2, 0, 2, 3, 2, 4, 0, 0, 0, 4, 0, 0, 4, 4, 3, 4, 3, 2,\n",
      "        4, 2, 1, 2, 1, 4, 0, 3, 3, 1, 0, 0, 3, 3, 0, 3, 2, 4, 2, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 4, 2, 2, 3, 0, 2, 3, 4, 0, 2, 0, 4, 1, 4, 0, 4, 1, 4, 1, 1,\n",
      "        1, 1, 1, 4, 0, 4, 2, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 2, 0, 4, 3, 3, 4, 2, 4, 3, 4, 0, 1, 4, 4, 0, 2, 4, 2, 1, 3, 3, 4, 2,\n",
      "        2, 4, 4, 3, 2, 4, 2, 3, 2, 2, 3, 4, 4, 2, 1, 4, 3, 4, 2, 4, 2, 2, 3, 0,\n",
      "        4, 2, 2, 1, 1, 2, 3, 4, 1, 1, 3, 3, 0, 1, 3, 4, 1, 4, 4, 2, 1, 0, 2, 0,\n",
      "        1, 4, 3, 0, 3, 2, 2, 2, 2, 1, 2, 2, 2, 3, 4, 2, 3, 2, 1, 1, 2, 2, 4, 2,\n",
      "        2, 2, 2, 4, 2, 4, 1, 4, 3, 2, 4, 3, 2, 1, 3, 0, 4, 1, 4, 3, 2, 4, 3, 0,\n",
      "        4, 4, 0, 2, 0, 2, 2, 4, 2, 1, 2, 2, 2, 1, 4, 2, 3, 2, 2, 3, 3, 2, 3, 2,\n",
      "        4, 4, 1, 2, 3, 4, 2, 3, 1, 3, 0, 1, 3, 3, 4, 1, 1, 2, 3, 0, 1, 0, 4, 4,\n",
      "        2, 1, 0, 3, 4, 0, 2, 0, 0, 2, 3, 2, 0, 3, 1, 4, 4, 4, 0, 3, 0, 2, 1, 4,\n",
      "        0, 4, 0, 3, 1, 4, 2, 0], device='cuda:0')\n",
      "label\n",
      "tensor([4, 2, 0, 4, 1, 3, 2, 4, 3, 3, 3, 1, 1, 4, 4, 2, 3, 3, 0, 0, 0, 2, 4, 4,\n",
      "        2, 1, 4, 3, 0, 2, 3, 0, 1, 4, 0, 0, 2, 2, 1, 1, 0, 1, 3, 4, 0, 1, 0, 2,\n",
      "        1, 3, 2, 3, 0, 0, 4, 2, 0, 0, 2, 3, 0, 1, 3, 0, 3, 3, 2, 0, 3, 2, 4, 0,\n",
      "        1, 3, 3, 1, 3, 1, 0, 2, 2, 0, 2, 3, 4, 2, 2, 2, 3, 2, 2, 2, 0, 4, 1, 0,\n",
      "        3, 4, 1, 0, 0, 0, 4, 1, 1, 4, 4, 2, 2, 4, 0, 1, 2, 2, 4, 3, 4, 0, 0, 1,\n",
      "        0, 4, 2, 1, 1, 0, 4, 1, 0, 2, 0, 1, 0, 0, 1, 3, 4, 2, 4, 3, 0, 4, 1, 0,\n",
      "        2, 1, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 2, 0, 3, 3, 0, 4, 1, 2, 3, 2, 1,\n",
      "        4, 4, 4, 1, 2, 0, 2, 0, 3, 2, 3, 3, 2, 3, 1, 2, 0, 3, 2, 3, 2, 1, 1, 1,\n",
      "        4, 1, 0, 2, 3, 1, 0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 2, 0, 4, 4, 3, 2, 4, 3, 3, 2, 1, 1, 1, 2, 1, 3, 2, 1, 1, 3, 1, 4, 2,\n",
      "        4, 0, 4, 0, 0, 1, 3, 0, 4, 4, 2, 0, 2, 2, 0, 4, 1, 1, 0, 4, 1, 1, 2, 0,\n",
      "        1, 3, 1, 2, 1, 3, 4, 4, 2, 0, 3, 4, 0, 2, 3, 0, 3, 3, 3, 4, 3, 1, 2, 4,\n",
      "        1, 3, 3, 2, 3, 2, 2, 2, 2, 2, 4, 4, 1, 2, 1, 2, 1, 2, 4, 2, 0, 0, 4, 1,\n",
      "        4, 0, 4, 2, 4, 4, 4, 1, 1, 4, 4, 2, 0, 4, 0, 1, 1, 4, 2, 3, 3, 1, 3, 2,\n",
      "        0, 3, 4, 1, 1, 2, 4, 3, 4, 4, 0, 4, 1, 4, 4, 3, 1, 2, 2, 3, 1, 4, 1, 0,\n",
      "        4, 4, 0, 0, 3, 0, 4, 3, 3, 2, 0, 2, 2, 2, 2, 2, 3, 0, 4, 2, 4, 3, 4, 3,\n",
      "        2, 4, 2, 1, 4, 4, 2, 0, 3, 4, 3, 3, 2, 3, 2, 3, 3, 2, 1, 2, 2, 2, 1, 2,\n",
      "        2, 1, 1, 4, 4, 2, 2, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 4, 4, 1, 4, 1, 1, 4, 0, 0, 2, 0, 2, 1, 1, 0, 4, 3, 2, 1, 2, 0, 4,\n",
      "        3, 2, 3, 4, 2, 1, 4, 2, 0, 4, 0, 0, 1, 2, 2, 0, 2, 1, 3, 4, 1, 0, 2, 0,\n",
      "        1, 2, 2, 1, 4, 0, 1, 3, 2, 0, 3, 4, 4, 3, 4, 0, 4, 2, 2, 1, 3, 4, 0, 2,\n",
      "        0, 3, 0, 0, 4, 0, 0, 0, 0, 4, 2, 0, 3, 4, 4, 1, 0, 3, 0, 1, 1, 2, 0, 0,\n",
      "        1, 0, 2, 4, 0, 4, 3, 3, 0, 1, 1, 0, 0, 0, 0, 0, 4, 2, 1, 1, 1, 1, 1, 3,\n",
      "        1, 3, 3, 4, 1, 1, 4, 3, 1, 3, 0, 2, 0, 2, 1, 0, 1, 4, 0, 1, 1, 1, 1, 0,\n",
      "        4, 4, 0, 3, 0, 1, 4, 4, 1, 0, 3, 2, 3, 0, 2, 2, 3, 4, 2, 3, 3, 4, 3, 4,\n",
      "        3, 3, 3, 3, 4, 4, 2, 1, 2, 2, 0, 2, 1, 2, 4, 3, 3, 0, 3, 4, 3, 1, 2, 2,\n",
      "        4, 0, 0, 2, 2, 2, 4, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 3, 4, 2, 1, 3, 3, 4, 0, 0, 0, 2, 1, 2, 1, 4, 0, 3, 4, 2, 0, 1, 0, 3,\n",
      "        3, 2, 0, 4, 4, 1, 1, 2, 2, 4, 0, 2, 2, 4, 2, 3, 3, 1, 4, 4, 2, 0, 2, 4,\n",
      "        2, 1, 3, 3, 4, 2, 2, 1, 2, 1, 3, 1, 0, 4, 4, 1, 2, 2, 4, 1, 2, 2, 0, 4,\n",
      "        0, 3, 2, 3, 4, 3, 1, 1, 1, 3, 2, 3, 3, 2, 4, 2, 2, 0, 0, 1, 4, 4, 0, 3,\n",
      "        0, 0, 4, 2, 0, 4, 3, 3, 4, 2, 2, 4, 0, 4, 4, 2, 4, 0, 4, 3, 1, 1, 4, 4,\n",
      "        2, 0, 3, 4, 2, 4, 3, 4, 4, 4, 2, 2, 0, 3, 1, 4, 3, 3, 0, 2, 4, 1, 3, 0,\n",
      "        2, 3, 0, 2, 0, 1, 3, 4, 2, 0, 4, 0, 4, 2, 2, 2, 3, 3, 3, 3, 3, 4, 0, 4,\n",
      "        2, 3, 4, 3, 4, 4, 2, 2, 4, 2, 0, 0, 3, 3, 2, 2, 4, 2, 4, 3, 1, 1, 1, 2,\n",
      "        4, 0, 4, 2, 4, 3, 4, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 0, 2, 0, 1, 1, 0, 1, 2, 2, 0, 4, 2, 1, 2, 2, 0, 3, 4, 3, 2, 4, 2,\n",
      "        3, 1, 1, 0, 4, 1, 1, 3, 0, 0, 3, 4, 4, 1, 1, 2, 0, 2, 2, 3, 3, 1, 1, 1,\n",
      "        2, 3, 0, 4, 1, 4, 0, 4, 0, 4, 1, 1, 3, 0, 1, 0, 0, 1, 3, 4, 2, 3, 2, 2,\n",
      "        1, 1, 2, 2, 2, 1, 3, 1, 0, 4, 0, 0, 2, 0, 2, 2, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 1, 4, 4, 2, 3, 2, 2, 2, 1, 4, 2, 3, 3, 4, 2, 4, 1,\n",
      "        3, 0, 3, 4, 3, 0, 1, 2, 0, 0, 4, 4, 3, 4, 4, 2, 0, 1, 2, 2, 3, 0, 4, 4,\n",
      "        2, 3, 0, 2, 4, 1, 0, 4, 0, 4, 4, 4, 2, 2, 1, 1, 0, 1, 2, 2, 2, 2, 2, 4,\n",
      "        0, 4, 0, 2, 4, 0, 2, 1, 4, 2, 4, 3, 2, 4, 3, 0, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4093, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(testloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model1, model2):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            x2=model1(x)\n",
    "            scores = model2(x2)\n",
    "            _, predictions = scores.max(1)\n",
    "            print('label')\n",
    "            print(y)\n",
    "            print('prediction next')\n",
    "            print(predictions)\n",
    "            num_correct += (predictions == (y+0)).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "\n",
    "    \n",
    "    model1.train()\n",
    "    model2.train()\n",
    "    return num_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "tensor([4, 4, 0, 1, 3, 1, 4, 1, 2, 3, 1, 2, 0, 0, 0, 3, 1, 2, 3, 1, 2, 3, 3, 0,\n",
      "        4, 0, 2, 0, 0, 0, 1, 3, 3, 4, 0, 2, 0, 2, 0, 1, 1, 2, 4, 2, 2, 2, 2, 4,\n",
      "        1, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 2, 4, 4, 1, 0, 1, 4, 4, 4, 2, 3, 1, 2, 4, 1, 4, 4, 0, 2, 3, 4, 4,\n",
      "        3, 0, 4, 0, 3, 4, 0, 2, 4, 4, 2, 4, 1, 2, 0, 1, 2, 2, 4, 2, 4, 4, 4, 4,\n",
      "        1, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 4, 3, 0, 0, 1, 4, 0, 1, 2, 4, 2, 4, 3, 1, 0, 2, 0, 4, 0, 2, 3, 3, 4,\n",
      "        2, 1, 4, 4, 1, 4, 3, 1, 4, 2, 3, 1, 2, 0, 0, 2, 4, 3, 3, 4, 2, 2, 3, 0,\n",
      "        0, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 4, 1, 0, 3, 2, 2, 2, 2, 4, 2, 4, 0, 0, 4, 4, 1, 4, 0, 4, 1, 3, 4,\n",
      "        4, 4, 4, 4, 1, 4, 4, 0, 4, 3, 4, 3, 3, 4, 2, 2, 2, 3, 4, 4, 2, 4, 4, 3,\n",
      "        0, 0], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 4, 4, 2, 1, 2, 3, 1, 2, 1, 3, 1, 0, 1, 0, 0, 2, 2, 3, 3, 2, 2, 0,\n",
      "        1, 4, 0, 4, 1, 1, 1, 3, 4, 4, 4, 0, 0, 0, 4, 3, 2, 4, 1, 3, 1, 4, 1, 3,\n",
      "        1, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 3, 2, 4, 2, 4, 4, 4, 2, 1, 0, 3, 4, 1, 1, 0, 2, 2, 2, 0, 4, 2, 4, 4,\n",
      "        3, 4, 4, 0, 1, 0, 1, 3, 4, 4, 4, 0, 0, 2, 4, 2, 2, 4, 0, 4, 0, 4, 0, 2,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([1, 4, 2, 0, 4, 0, 1, 2, 3, 3, 3, 0, 2, 1, 1, 1, 2, 0, 4, 4, 1, 4, 4, 3,\n",
      "        2, 3, 2, 0, 2, 2, 2, 0, 0, 0, 0, 3, 0, 4, 0, 4, 0, 0, 0, 0, 4, 2, 2, 4,\n",
      "        3, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 4, 0, 4, 4, 4, 3, 3, 2, 3, 1, 4, 1, 2, 4, 4, 1, 3, 4, 1, 2, 4, 4,\n",
      "        2, 4, 4, 0, 1, 2, 4, 3, 0, 1, 4, 4, 0, 2, 3, 4, 0, 4, 0, 3, 2, 2, 4, 4,\n",
      "        4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 0, 2, 2, 1, 0, 0, 3, 1, 2, 4, 0, 2, 2, 0, 2, 0, 2, 2, 3, 3, 0, 4,\n",
      "        3, 2, 3, 4, 1, 1, 1, 4, 2, 2, 3, 4, 1, 2, 2, 4, 1, 4, 1, 0, 0, 1, 1, 4,\n",
      "        0, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 4, 2, 4, 2, 0, 4, 3, 4, 2, 4, 2, 2, 1, 1, 4, 4, 2, 4, 4, 2, 2, 4,\n",
      "        4, 4, 4, 4, 1, 3, 2, 4, 4, 4, 4, 3, 4, 2, 1, 2, 2, 4, 2, 0, 0, 2, 3, 4,\n",
      "        3, 2], device='cuda:0')\n",
      "label\n",
      "tensor([0, 3, 2, 2, 2, 3, 4, 4, 4, 3, 3, 1, 0, 0, 2, 1, 0, 4, 0, 3, 2, 4, 2, 2,\n",
      "        4, 4, 4, 3, 3, 2, 1, 0, 3, 3, 0, 4, 4, 2, 1, 3, 2, 2, 2, 3, 0, 2, 2, 1,\n",
      "        1, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 4, 4, 4, 4, 3, 3, 3, 4, 3, 4, 1, 0, 1, 4, 2, 1, 2, 4, 4, 2, 4, 1, 2,\n",
      "        4, 4, 2, 4, 3, 4, 3, 0, 3, 4, 1, 4, 2, 4, 2, 4, 3, 4, 3, 3, 3, 2, 0, 2,\n",
      "        2, 0], device='cuda:0')\n",
      "label\n",
      "tensor([0, 1, 1, 2, 1, 3, 4, 2, 1, 3, 2, 1, 4, 2, 0, 1, 4, 3, 2, 3, 3, 0, 0, 0,\n",
      "        1, 3, 2, 4, 4, 4, 0, 4, 1, 2, 2, 3, 2, 4, 4, 3, 3, 0, 3, 0, 1, 0, 2, 3,\n",
      "        2, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 1, 1, 4, 0, 4, 2, 4, 4, 4, 4, 1, 4, 2, 0, 4, 4, 2, 4, 4, 3, 2, 3, 0,\n",
      "        2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 0, 4, 0, 4, 4, 1, 0, 4, 0, 2, 2, 4, 4,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([1, 4, 1, 2, 1, 2, 3, 1, 0, 1, 2, 4, 0, 0, 0, 0, 4, 4, 0, 2, 1, 1, 3, 1,\n",
      "        0, 3, 0, 4, 0, 4, 4, 1, 4, 0, 0, 0, 0, 2, 4, 0, 2, 0, 4, 0, 0, 4, 1, 4,\n",
      "        1, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 1, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 0, 2, 1, 2, 3, 4, 4, 1, 1, 4, 1,\n",
      "        0, 4, 0, 4, 0, 4, 4, 1, 4, 2, 0, 1, 0, 2, 4, 1, 2, 2, 4, 0, 3, 4, 2, 4,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 3, 4, 2, 3, 0, 1, 1, 1, 4, 1, 4, 3, 4, 0, 2, 0, 4, 2, 4, 0, 1, 1,\n",
      "        1, 4, 0, 4, 3, 3, 1, 2, 2, 0, 3, 3, 0, 0, 0, 1, 4, 3, 0, 2, 1, 4, 3, 1,\n",
      "        0, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 0, 4, 4, 4, 4, 4, 2, 2, 1, 3, 0, 4, 3, 4, 0, 2, 1, 4, 2, 4, 1, 1, 1,\n",
      "        1, 4, 1, 4, 4, 3, 0, 1, 1, 0, 2, 4, 4, 0, 1, 1, 4, 4, 0, 4, 0, 4, 4, 1,\n",
      "        4, 1], device='cuda:0')\n",
      "label\n",
      "tensor([4, 1, 3, 1, 0, 3, 3, 2, 0, 3, 0, 3, 0, 2, 4, 1, 2, 1, 4, 4, 3, 0, 3, 1,\n",
      "        3, 0, 3, 0, 1, 1, 0, 1, 0, 4, 3, 4, 1, 0, 2, 4, 0, 2, 2, 0, 0, 2, 4, 1,\n",
      "        0, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 2, 4, 3, 3, 3, 3, 4, 1, 3, 1, 4, 1, 2, 2, 1, 2, 2, 4, 4, 4, 3, 3, 2,\n",
      "        4, 4, 3, 0, 4, 2, 4, 1, 0, 2, 4, 2, 3, 4, 2, 4, 1, 2, 2, 0, 0, 4, 2, 3,\n",
      "        3, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 2, 1, 0, 2, 3, 2, 3, 2, 2, 2, 0, 3, 0, 1, 1, 4, 4, 2, 4, 0, 2, 3, 3,\n",
      "        4, 2, 0, 1, 1, 3, 0, 2, 3, 0, 3, 4, 4, 1, 4, 2, 2, 4, 3, 4, 4, 0, 0, 3,\n",
      "        4, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 1, 1, 0, 4, 3, 4, 4, 2, 2, 4, 4, 4, 4, 0, 1, 4, 4, 2, 4, 4, 0, 3, 0,\n",
      "        2, 2, 2, 2, 1, 3, 3, 4, 3, 4, 0, 4, 4, 2, 4, 0, 2, 3, 4, 4, 4, 4, 0, 4,\n",
      "        4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([1, 2, 1, 3, 0, 0, 2, 4, 2, 2, 0, 4, 0, 0, 4, 0, 0, 1, 0, 4, 0, 2, 0, 2,\n",
      "        1, 2, 3, 4, 1, 3, 1, 0, 0, 0, 0, 4, 4, 1, 2, 2, 3, 4, 2, 0, 0, 3, 1, 1,\n",
      "        0, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 2, 4, 3, 1, 2, 4, 4, 2, 3, 4, 4, 1, 4, 4, 0, 0, 2, 0, 4, 0, 4, 0, 2,\n",
      "        3, 3, 4, 4, 0, 4, 1, 3, 1, 3, 2, 4, 4, 1, 2, 2, 4, 4, 2, 4, 4, 4, 1, 0,\n",
      "        0, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 4, 4, 4, 3, 1, 1, 1, 1, 1, 0, 0, 4, 2, 0, 2, 0, 3, 3, 1, 4, 4, 0,\n",
      "        0, 4, 4, 3, 2, 2, 2, 0, 3, 0, 0, 1, 3, 2, 0, 3, 2, 0, 4, 0, 3, 3, 3, 0,\n",
      "        4, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 4, 4, 4, 4, 1, 4, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 4, 4, 3, 4, 4, 0,\n",
      "        4, 4, 4, 3, 2, 0, 4, 0, 3, 0, 1, 2, 2, 4, 4, 4, 4, 0, 4, 0, 3, 0, 4, 0,\n",
      "        2, 2], device='cuda:0')\n",
      "label\n",
      "tensor([3, 0, 2, 0, 2, 2, 2, 3, 3, 3, 0, 2, 3, 1, 1, 4, 0, 1, 3, 4, 1, 4, 0, 3,\n",
      "        4, 1, 2, 3, 2, 0, 0, 3, 0, 4, 1, 3, 1, 2, 3, 3, 0, 1, 4, 0, 1, 0, 0, 0,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 2, 4, 2, 2, 0, 2, 4, 4, 4, 0, 4, 4, 2, 4, 4, 0, 1, 2, 3, 1, 4, 0, 0,\n",
      "        4, 2, 4, 4, 2, 0, 3, 4, 4, 4, 1, 4, 2, 4, 1, 4, 0, 4, 4, 0, 3, 0, 0, 1,\n",
      "        1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([1, 4, 3, 1, 3, 1, 2, 2, 0, 4, 4, 3, 1, 0, 4, 0, 2, 4, 3, 0, 3, 0, 4, 0,\n",
      "        0, 2, 2, 2, 2, 0, 2, 2, 4, 4, 1, 0, 1, 2, 1, 4, 1, 0, 2, 0, 1, 4, 4, 1,\n",
      "        2, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 4, 1, 4, 4, 2, 2, 4, 4, 4, 3, 3, 0, 0, 4, 2, 4, 4, 3, 4, 4, 4, 4,\n",
      "        4, 2, 4, 3, 4, 4, 2, 1, 2, 4, 1, 1, 2, 4, 1, 4, 1, 4, 2, 3, 0, 4, 3, 4,\n",
      "        4, 3], device='cuda:0')\n",
      "label\n",
      "tensor([3, 2, 3, 0, 0, 4, 1, 1, 4, 2, 3, 0, 2, 1, 3, 1, 4, 4, 1, 3, 2, 2, 3, 2,\n",
      "        4, 0, 1, 2, 3, 0, 2, 2, 0, 4, 1, 3, 0, 4, 0, 3, 0, 4, 3, 1, 1, 4, 0, 1,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 2, 4, 4, 0, 4, 4, 1, 4, 2, 2, 1, 2, 1, 3, 3, 3, 4, 1, 4, 2, 4, 4, 2,\n",
      "        2, 4, 2, 2, 4, 4, 4, 1, 3, 3, 1, 3, 4, 4, 4, 4, 0, 4, 4, 3, 4, 4, 0, 2,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 4, 2, 1, 4, 4, 4, 1, 4, 1, 4, 2, 3, 2, 1, 1, 0, 4, 2, 3, 1, 0, 0,\n",
      "        2, 3, 1, 0, 0, 1, 2, 4, 4, 4, 2, 1, 0, 2, 0, 3, 0, 4, 1, 3, 0, 0, 1, 3,\n",
      "        2, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 4, 2, 0, 4, 3, 2, 3, 2, 0, 4, 2, 0, 0, 1, 4, 0, 4, 2, 3, 2, 3, 0,\n",
      "        2, 4, 2, 4, 3, 2, 2, 2, 3, 2, 4, 2, 4, 3, 0, 4, 0, 4, 2, 4, 2, 4, 1, 4,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 2, 1, 2, 0, 3, 1, 3, 2, 4, 0, 1, 4, 0, 3, 4, 2, 3, 1, 4, 3, 3, 2,\n",
      "        3, 2, 1, 1, 3, 2, 0, 4, 1, 1, 4, 0, 0, 2, 3, 0, 2, 0, 2, 1, 4, 1, 2, 3,\n",
      "        1, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 4, 4, 4, 0, 4, 1, 3, 4, 4, 1, 0, 3, 3, 3, 4, 2, 2, 3, 4, 4, 4, 2,\n",
      "        4, 4, 2, 3, 3, 3, 4, 2, 2, 4, 0, 2, 4, 2, 2, 0, 2, 3, 4, 1, 4, 4, 4, 4,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 1, 2, 2, 1, 3, 1, 3, 1, 3, 2, 4, 4, 3, 2, 2, 3, 3, 1, 2, 1, 4, 2,\n",
      "        0, 3, 3, 3, 4, 0, 4, 0, 0, 0, 2, 4, 0, 2, 4, 3, 1, 0, 2, 4, 2, 1, 3, 4,\n",
      "        0, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 2, 4, 2, 0, 3, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 3, 3, 1, 1, 2, 4, 4,\n",
      "        0, 1, 4, 4, 4, 0, 4, 3, 0, 0, 2, 4, 0, 2, 3, 4, 4, 3, 3, 4, 4, 0, 4, 4,\n",
      "        4, 3], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 1, 2, 0, 4, 0, 3, 3, 2, 0, 4, 2, 3, 3, 4, 1, 0, 2, 4, 0, 3, 2, 4,\n",
      "        2, 2, 3, 0, 1, 4, 1, 2, 4, 4, 1, 2, 0, 3, 2, 1, 2, 0, 2, 1, 3, 0, 0, 2,\n",
      "        3, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 0, 4, 2, 3, 4, 1, 3, 4, 4, 0, 0, 4, 3, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4,\n",
      "        0, 3, 4, 3, 0, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 3, 2, 3, 2, 2, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 1, 0, 2, 3, 4, 2, 1, 4, 0, 1, 1, 3, 3, 0, 1, 0, 2, 0, 2, 1, 1, 1, 4,\n",
      "        2, 2, 0, 1, 2, 2, 4, 1, 2, 1, 2, 2, 2, 1, 1, 4, 0, 0, 2, 4, 2, 1, 0, 2,\n",
      "        3, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 1, 1, 2, 4, 4, 4, 1, 1, 4, 2, 1, 4, 2, 4, 0, 4, 2, 0, 4, 2, 2, 4, 2,\n",
      "        0, 4, 0, 4, 4, 4, 4, 3, 2, 1, 2, 3, 4, 1, 4, 2, 0, 0, 2, 2, 2, 0, 0, 2,\n",
      "        3, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 1, 1, 2, 2, 3, 3, 1, 0, 1, 0, 0, 1, 1, 1, 4, 3, 3, 0, 4, 4, 3, 3, 0,\n",
      "        1, 2, 2, 4, 0, 2, 3, 4, 3, 1, 3, 3, 4, 0, 3, 0, 1, 0, 1, 4, 1, 0, 1, 0,\n",
      "        1, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 1, 2, 4, 2, 4, 1, 0, 2, 3, 1, 1, 2, 2, 2, 3, 4, 4, 4, 4, 3, 1, 1,\n",
      "        2, 2, 2, 2, 4, 4, 4, 2, 3, 1, 0, 3, 4, 1, 3, 3, 1, 3, 2, 4, 1, 4, 4, 0,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 4, 2, 0, 2, 4, 1, 3, 3, 0, 1, 2, 2, 0, 3, 2, 2, 2, 0, 2, 0, 1, 4,\n",
      "        0, 2, 0, 1, 3, 4, 1, 0, 3, 2, 3, 1, 3, 2, 4, 0, 1, 1, 1, 0, 3, 1, 0, 0,\n",
      "        0, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 2, 3, 4, 3, 4, 1, 3, 4, 0, 2, 4, 2, 4, 4, 2, 4, 1, 2, 4, 1, 2, 4,\n",
      "        3, 2, 0, 2, 3, 4, 4, 2, 3, 2, 1, 1, 4, 4, 3, 3, 2, 2, 2, 3, 4, 3, 4, 3,\n",
      "        2, 3], device='cuda:0')\n",
      "label\n",
      "tensor([3, 3, 2, 1, 4, 4, 4, 3, 3, 1, 2, 4, 2, 2, 4, 4, 0, 0, 0, 2, 0, 2, 0, 3,\n",
      "        2, 1, 0, 2, 4, 1, 0, 0, 0, 1, 4, 1, 3, 1, 2, 2, 0, 3, 2, 0, 3, 2, 0, 3,\n",
      "        2, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 2, 2, 4, 4, 4, 3, 4, 0, 2, 4, 4, 2, 3, 4, 3, 4, 0, 2, 3, 2, 0, 4,\n",
      "        4, 4, 0, 4, 3, 2, 4, 3, 0, 4, 4, 2, 4, 0, 4, 1, 0, 4, 4, 3, 4, 2, 2, 3,\n",
      "        4, 3], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 3, 1, 4, 0, 4, 2, 4, 3, 2, 4, 0, 1, 4, 2, 1, 4, 1, 0, 2, 0, 2, 4,\n",
      "        1, 4, 3, 0, 1, 4, 1, 2, 2, 1, 2, 1, 3, 2, 3, 0, 1, 4, 3, 2, 1, 0, 4, 2,\n",
      "        4, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 4, 4, 1, 2, 1, 4, 2, 4, 4, 2, 4, 4, 1, 0, 4, 1, 4, 4, 4, 2, 4, 2, 2,\n",
      "        0, 4, 4, 2, 2, 4, 3, 4, 2, 2, 2, 2, 4, 4, 4, 3, 2, 4, 3, 4, 2, 4, 4, 4,\n",
      "        4, 3], device='cuda:0')\n",
      "label\n",
      "tensor([4, 4, 3, 0, 1, 2, 1, 3, 2, 3, 3, 4, 3, 0, 4, 3, 0, 4, 1, 2, 1, 2, 2, 2,\n",
      "        3, 2, 3, 4, 4, 2, 3, 1, 4, 3, 0, 0, 2, 3, 4, 4, 3, 1, 0, 3, 3, 1, 0, 3,\n",
      "        2, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 4, 1, 2, 4, 1, 4, 2, 2, 3, 2, 4, 0, 4, 3, 4, 2, 1, 4, 1, 2, 2, 4,\n",
      "        4, 2, 3, 4, 4, 0, 4, 4, 2, 4, 1, 2, 2, 3, 0, 2, 4, 2, 2, 2, 3, 1, 1, 1,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 0, 0, 1, 1, 1, 4, 0, 3, 2, 0, 2, 2, 1, 2, 0, 0, 0, 3, 1, 0, 0, 1,\n",
      "        3, 0, 3, 1, 3, 2, 4, 2, 1, 1, 1, 0, 2, 4, 1, 4, 2, 3, 0, 0, 2, 0, 1, 0,\n",
      "        2, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 0, 1, 2, 2, 1, 4, 0, 4, 4, 0, 3, 4, 1, 3, 1, 1, 1, 3, 0, 1, 3, 0,\n",
      "        4, 4, 4, 1, 4, 2, 4, 2, 4, 4, 4, 0, 4, 4, 1, 4, 2, 4, 1, 2, 1, 0, 3, 4,\n",
      "        1, 3], device='cuda:0')\n",
      "label\n",
      "tensor([2, 4, 3, 4, 1, 3, 3, 2, 2, 1, 2, 3, 3, 2, 2, 4, 2, 4, 1, 4, 2, 1, 4, 3,\n",
      "        3, 1, 0, 2, 2, 2, 1, 3, 4, 4, 0, 0, 4, 2, 2, 0, 4, 1, 0, 3, 0, 2, 3, 0,\n",
      "        3, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 2, 4, 1, 4, 3, 2, 4, 2, 3, 4, 4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4,\n",
      "        2, 4, 2, 2, 2, 3, 0, 4, 4, 2, 0, 1, 4, 4, 2, 3, 2, 0, 0, 2, 4, 4, 4, 1,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([4, 1, 0, 3, 3, 4, 2, 2, 0, 4, 1, 0, 0, 1, 0, 0, 4, 0, 3, 2, 0, 2, 0, 1,\n",
      "        0, 2, 2, 1, 0, 0, 0, 1, 4, 0, 2, 1, 3, 3, 1, 2, 3, 1, 1, 2, 4, 0, 1, 4,\n",
      "        1, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 0, 4, 4, 4, 4, 4, 2, 4, 4, 2, 0, 2, 2, 1, 4, 0, 3, 4, 0, 4, 4, 1,\n",
      "        0, 3, 4, 4, 0, 0, 4, 2, 4, 2, 2, 1, 4, 4, 4, 2, 3, 2, 4, 4, 4, 4, 4, 4,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([4, 1, 3, 1, 2, 0, 2, 0, 1, 4, 3, 2, 0, 4, 2, 2, 1, 2, 1, 2, 4, 0, 1, 1,\n",
      "        1, 2, 0, 4, 4, 1, 2, 4, 2, 2, 0, 1, 4, 2, 4, 2, 2, 3, 1, 1, 0, 2, 4, 4,\n",
      "        3, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 2, 4, 4, 2, 2, 4, 0, 2, 4, 4, 1, 1, 4, 4, 2, 4, 4, 4, 2, 2, 1, 2, 4,\n",
      "        4, 3, 0, 4, 4, 2, 1, 4, 2, 2, 0, 2, 4, 4, 2, 4, 2, 1, 1, 2, 3, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 2, 4, 3, 1, 1, 4, 2, 1, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 3,\n",
      "        4, 4, 3, 1, 1, 1, 2, 1, 2, 1, 4, 2, 0, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 3,\n",
      "        3, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 2, 2, 4, 4, 3, 0, 2, 2, 0, 0, 4, 3, 2, 2, 1, 2, 2, 0, 0, 4, 4, 4, 0,\n",
      "        4, 4, 4, 4, 1, 3, 2, 2, 4, 3, 4, 4, 4, 0, 3, 2, 2, 1, 4, 4, 4, 0, 0, 4,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 4, 1, 4, 1, 3, 0, 2, 0, 3, 2, 0, 4, 0, 3, 2, 2, 3, 4, 0, 1, 3, 2,\n",
      "        4, 0, 4, 2, 1, 0, 4, 0, 0, 4, 4, 2, 1, 1, 0, 3, 3, 1, 3, 1, 1, 0, 3, 4,\n",
      "        1, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 3, 1, 4, 2, 4, 0, 4, 4, 4, 4, 4, 4, 1, 4, 4, 2, 2, 4, 0, 0, 4, 4,\n",
      "        2, 1, 4, 3, 3, 2, 4, 2, 2, 4, 2, 4, 1, 4, 0, 3, 3, 2, 4, 1, 4, 1, 3, 4,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([2, 3, 0, 3, 1, 4, 2, 1, 0, 2, 1, 0, 1, 3, 2, 4, 2, 1, 3, 4, 1, 0, 0, 3,\n",
      "        2, 1, 3, 4, 3, 2, 3, 2, 1, 3, 0, 3, 0, 0, 4, 0, 2, 2, 4, 1, 0, 0, 3, 1,\n",
      "        2, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 3, 0, 2, 1, 4, 4, 1, 1, 0, 2, 0, 2, 4, 2, 2, 4, 4, 1, 4, 4, 4, 0, 4,\n",
      "        4, 1, 4, 3, 2, 4, 4, 2, 1, 3, 0, 4, 4, 4, 4, 2, 2, 4, 4, 1, 0, 1, 3, 2,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 2, 3, 4, 3, 0, 1, 0, 4, 0, 2, 0, 1, 2, 4, 1, 1, 0, 2, 0, 2, 1, 0,\n",
      "        4, 2, 3, 3, 2, 1, 2, 4, 4, 4, 1, 0, 3, 4, 1, 1, 0, 0, 3, 4, 1, 1, 1, 0,\n",
      "        1, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 0, 2, 4, 4, 3, 2, 1, 2, 4, 0, 4, 1, 2, 2, 4, 4, 4, 0, 4, 0, 2, 2, 4,\n",
      "        4, 2, 4, 3, 0, 4, 4, 4, 4, 2, 2, 0, 2, 3, 1, 2, 2, 3, 3, 4, 2, 3, 3, 1,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 3, 4, 4, 2, 0, 1, 0, 1, 2, 2, 3, 2, 2, 4, 4, 0, 2, 0, 2, 4, 2, 0, 2,\n",
      "        2, 2, 1, 1, 4, 2, 2, 1, 4, 1, 2, 4, 4, 1, 1, 2, 2, 0, 2, 0, 4, 4, 2, 1,\n",
      "        4, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 2, 4, 4, 1, 4, 0, 1, 3, 3, 3, 4, 4, 4, 4, 0, 4, 0, 2, 4, 4, 1, 2,\n",
      "        4, 4, 1, 3, 2, 3, 4, 1, 4, 2, 2, 4, 4, 2, 2, 4, 1, 0, 2, 2, 4, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 2, 4, 4, 2, 2, 4, 1, 0, 2, 1, 3, 2, 3, 2, 4, 1, 0, 4, 3, 2, 0, 0,\n",
      "        0, 2, 0, 0, 0, 4, 0, 4, 2, 1, 1, 3, 0, 1, 0, 3, 2, 0, 2, 4, 1, 0, 1, 1,\n",
      "        2, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 0, 2, 2, 4, 4, 2, 4, 2, 3, 2, 1, 2, 4, 3, 4, 4, 4, 0, 4, 3, 0, 4, 4,\n",
      "        2, 2, 4, 0, 1, 2, 0, 4, 4, 2, 4, 4, 0, 3, 4, 4, 2, 0, 4, 4, 1, 4, 4, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([1, 1, 1, 0, 0, 4, 4, 2, 1, 0, 4, 2, 4, 0, 2, 4, 0, 2, 0, 0, 1, 2, 4, 1,\n",
      "        2, 1, 2, 0, 0, 0, 3, 1, 0, 0, 1, 1, 0, 1, 3, 2, 4, 2, 2, 1, 2, 4, 3, 0,\n",
      "        1, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 3, 0, 0, 2, 4, 1, 2, 4, 4, 0, 4, 1, 0, 2, 4, 4, 0, 4, 1, 4, 4, 4,\n",
      "        2, 0, 4, 4, 1, 0, 3, 4, 1, 3, 1, 1, 3, 0, 4, 4, 3, 2, 1, 1, 4, 2, 0, 2,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 4, 3, 1, 3, 3, 4, 2, 2, 1, 3, 3, 2, 4, 4, 0, 4, 4, 3, 2, 4, 3, 1, 0,\n",
      "        2, 4, 0, 0, 0, 4, 1, 2, 2, 1, 3, 1, 3, 1, 1, 2, 0, 2, 3, 4, 2, 2, 0, 0,\n",
      "        2, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 4, 4, 1, 4, 4, 4, 2, 1, 2, 3, 2, 4, 4, 2, 0, 1, 4, 3, 4, 4, 4, 1, 0,\n",
      "        2, 4, 1, 3, 1, 4, 0, 2, 4, 2, 4, 2, 3, 2, 1, 4, 4, 2, 4, 4, 4, 2, 2, 4,\n",
      "        2, 3], device='cuda:0')\n",
      "label\n",
      "tensor([1, 2, 4, 3, 1, 1, 1, 0, 1, 1, 0, 0, 3, 2, 2, 1, 4, 3, 1, 2, 3, 4, 4, 0,\n",
      "        1, 4, 3, 1, 4, 2, 2, 0, 0, 0, 1, 2, 1, 0, 0, 1, 2, 2, 3, 1, 1, 1, 0, 0,\n",
      "        0, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 4, 4, 4, 2, 4, 3, 1, 1, 0, 1, 3, 2, 4, 0, 4, 2, 2, 1, 4, 4, 4, 4,\n",
      "        4, 4, 4, 0, 2, 2, 1, 1, 0, 4, 1, 0, 4, 2, 4, 3, 2, 4, 4, 1, 2, 0, 0, 0,\n",
      "        4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([0, 2, 3, 3, 3, 0, 0, 1, 2, 1, 3, 2, 2, 2, 3, 2, 3, 1, 4, 0, 1, 4, 4, 4,\n",
      "        0, 0, 1, 2, 2, 2, 0, 0, 3, 4, 4, 4, 3, 2, 4, 0, 3, 0, 1, 1, 3, 2, 2, 1,\n",
      "        3, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 4, 3, 4, 1, 1, 1, 0, 2, 1, 4, 2, 4, 3, 3, 0, 2, 4, 0, 1, 4, 2, 2,\n",
      "        0, 2, 4, 2, 4, 2, 1, 1, 4, 4, 2, 4, 4, 2, 4, 0, 3, 1, 1, 2, 2, 2, 2, 3,\n",
      "        4, 3], device='cuda:0')\n",
      "label\n",
      "tensor([4, 1, 4, 2, 0, 2, 1, 3, 1, 0, 1, 3, 0, 3, 4, 1, 1, 4, 4, 3, 2, 3, 2, 4,\n",
      "        1, 4, 4, 0, 4, 3, 2, 1, 3, 3, 2, 2, 3, 2, 2, 1, 3, 4, 1, 2, 0, 4, 0, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 3, 4, 2, 2, 2, 2, 4, 0, 0, 0, 3, 4, 4, 4, 2, 2, 0, 4, 2, 4, 4, 4, 4,\n",
      "        1, 4, 0, 0, 4, 3, 2, 2, 4, 2, 2, 1, 3, 3, 2, 4, 4, 4, 1, 0, 0, 4, 0, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([4, 4, 3, 4, 0, 3, 3, 0, 1, 3, 2, 1, 3, 4, 3, 4, 2, 3, 0, 2, 3, 4, 3, 4,\n",
      "        2, 0, 4, 2, 1, 4, 3, 4, 4, 4, 1, 2, 4, 3, 1, 4, 0, 2, 3, 2, 3, 1, 2, 1,\n",
      "        1, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 4, 4, 4, 4, 2, 1, 2, 3, 1, 4, 3, 2, 4, 4, 2, 4, 1, 2, 0, 4, 4, 2,\n",
      "        2, 0, 4, 2, 2, 3, 3, 4, 2, 2, 2, 4, 2, 3, 1, 4, 2, 1, 2, 4, 4, 2, 2, 3,\n",
      "        1, 1], device='cuda:0')\n",
      "label\n",
      "tensor([4, 0, 4, 2, 4, 1, 1, 2, 0, 0, 0, 3, 0, 1, 1, 1, 1, 1, 3, 0, 0, 0, 4, 0,\n",
      "        3, 1, 3, 2, 0, 1, 0, 3, 4, 0, 0, 2, 2, 1, 1, 2, 0, 2, 0, 2, 0, 2, 2, 3,\n",
      "        0, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 4, 4, 4, 2, 2, 2, 1, 0, 0, 0, 3, 0, 2, 4, 1, 3, 4, 3, 3, 3, 4, 0,\n",
      "        2, 2, 4, 2, 1, 1, 1, 4, 3, 0, 2, 2, 3, 4, 0, 1, 4, 2, 0, 4, 0, 4, 4, 4,\n",
      "        1, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 3, 0, 4, 1, 2, 1, 3, 4, 4, 1, 2, 1, 0, 2, 2, 0, 4, 1, 2, 4, 4, 1,\n",
      "        1, 3, 0, 0, 4, 3, 2, 1, 4, 3, 1, 2, 1, 2, 1, 0, 0, 0, 4, 2, 0, 1, 2, 0,\n",
      "        2, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 2, 3, 4, 1, 2, 2, 2, 4, 2, 0, 4, 1, 1, 2, 2, 0, 4, 2, 3, 4, 4, 2,\n",
      "        4, 4, 0, 1, 4, 4, 1, 2, 4, 3, 2, 4, 0, 1, 2, 4, 4, 1, 2, 4, 0, 0, 4, 3,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 4, 0, 0, 0, 2, 2, 3, 0, 2, 1, 2, 0, 0, 1, 2, 3, 4, 4, 0, 1, 1, 3,\n",
      "        3, 1, 2, 2, 4, 3, 1, 3, 1, 2, 3, 4, 4, 0, 4, 2, 2, 3, 0, 3, 1, 4, 0, 0,\n",
      "        1, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 0, 4, 2, 3, 2, 2, 2, 4, 1, 3, 4, 2, 3, 0, 1, 2, 3, 4, 2, 0, 4, 4, 4,\n",
      "        4, 0, 2, 2, 4, 3, 1, 2, 2, 4, 3, 4, 4, 4, 4, 4, 3, 2, 0, 4, 1, 4, 2, 3,\n",
      "        1, 0], device='cuda:0')\n",
      "label\n",
      "tensor([1, 2, 0, 4, 0, 1, 1, 0, 2, 2, 2, 0, 0, 1, 4, 0, 0, 3, 0, 0, 1, 2, 2, 2,\n",
      "        3, 3, 0, 3, 1, 3, 3, 1, 2, 0, 4, 2, 2, 2, 0, 1, 2, 2, 3, 4, 4, 3, 1, 2,\n",
      "        1, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 0, 4, 0, 2, 1, 4, 4, 4, 2, 2, 1, 1, 2, 2, 4, 4, 4, 1, 2, 4, 4, 4,\n",
      "        4, 4, 0, 3, 0, 2, 4, 1, 4, 0, 4, 4, 2, 2, 0, 2, 2, 3, 3, 2, 4, 4, 2, 4,\n",
      "        1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([1, 4, 0, 1, 1, 1, 1, 4, 3, 2, 4, 2, 2, 2, 0, 1, 4, 1, 0, 0, 2, 1, 1, 4,\n",
      "        4, 0, 4, 0, 0, 1, 1, 3, 2, 0, 4, 4, 3, 4, 1, 3, 3, 3, 2, 0, 3, 0, 2, 4,\n",
      "        0, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 3, 2, 2, 0, 1, 4, 2, 0, 4, 4, 2, 0, 0, 1, 4, 0, 0, 4, 0, 1, 1, 3,\n",
      "        4, 1, 2, 0, 1, 4, 1, 3, 2, 1, 4, 4, 4, 4, 1, 4, 4, 1, 2, 2, 0, 0, 2, 3,\n",
      "        0, 1], device='cuda:0')\n",
      "label\n",
      "tensor([0, 3, 2, 0, 0, 4, 3, 4, 2, 0, 4, 1, 1, 2, 2, 1, 1, 2, 3, 3, 1, 4, 0, 4,\n",
      "        2, 0, 4, 2, 1, 1, 0, 4, 0, 3, 4, 3, 4, 2, 1, 2, 2, 3, 0, 3, 3, 4, 4, 1,\n",
      "        3, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 4, 2, 3, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 1, 1, 1, 0, 2, 2, 3, 4,\n",
      "        4, 2, 2, 2, 1, 3, 0, 4, 4, 3, 4, 4, 4, 4, 1, 2, 2, 2, 3, 4, 4, 4, 2, 1,\n",
      "        3, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 4, 3, 4, 1, 1, 0, 1, 0, 0, 2, 4, 0, 0, 3, 3, 0, 0, 3, 2, 0, 0, 1,\n",
      "        4, 0, 4, 3, 0, 2, 1, 4, 0, 3, 3, 3, 2, 0, 0, 3, 2, 3, 1, 1, 4, 0, 2, 2,\n",
      "        0, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 4, 4, 2, 2, 2, 0, 2, 4, 0, 1, 4, 4, 3, 4, 4, 0, 0, 3, 4, 2, 4, 3,\n",
      "        3, 2, 4, 3, 0, 4, 1, 4, 1, 4, 4, 4, 2, 2, 3, 3, 4, 3, 2, 1, 4, 1, 0, 2,\n",
      "        1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([4, 3, 2, 2, 1, 1, 2, 1, 4, 4, 0, 0, 2, 1, 0, 3, 0, 1, 3, 0, 1, 0, 2, 4,\n",
      "        2, 1, 4, 3, 4, 3, 1, 1, 2, 4, 0, 2, 2, 0, 3, 1, 1, 0, 0, 0, 3, 1, 2, 2,\n",
      "        3, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 4, 2, 4, 2, 4, 1, 4, 4, 1, 4, 0, 3, 0, 4, 2, 1, 4, 0, 4, 1, 4, 4,\n",
      "        2, 1, 4, 4, 4, 3, 2, 1, 2, 4, 2, 1, 4, 3, 4, 4, 1, 3, 0, 4, 4, 0, 2, 0,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 2, 0, 4, 2, 0, 2, 2, 1, 0, 1, 0, 3, 4, 4, 1, 2, 0, 4, 0, 0, 3, 1, 3,\n",
      "        3, 3, 1, 3, 2, 2, 2, 1, 3, 0, 0, 3, 4, 2, 1, 2, 2, 3, 1, 2, 1, 3, 0, 0,\n",
      "        4, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 4, 4, 4, 4, 0, 4, 4, 3, 0, 1, 4, 4, 4, 4, 2, 2, 1, 4, 0, 1, 3, 3, 2,\n",
      "        3, 4, 2, 4, 1, 2, 2, 3, 4, 0, 0, 4, 3, 3, 1, 0, 2, 4, 1, 4, 2, 4, 4, 0,\n",
      "        4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([3, 2, 0, 3, 1, 0, 1, 3, 3, 2, 2, 1, 3, 1, 4, 2, 0, 1, 4, 0, 0, 3, 4, 2,\n",
      "        0, 4, 2, 2, 2, 3, 0, 2, 4, 4, 4, 1, 2, 0, 4, 2, 1, 2, 4, 1, 2, 2, 3, 4,\n",
      "        2, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 2, 0, 4, 1, 2, 4, 4, 3, 2, 0, 4, 3, 4, 4, 3, 4, 2, 4, 0, 3, 4, 4, 2,\n",
      "        2, 4, 2, 2, 4, 4, 2, 4, 2, 4, 2, 4, 1, 4, 2, 1, 1, 2, 4, 1, 2, 0, 3, 4,\n",
      "        0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 1, 0, 2, 1, 1, 0, 4, 0, 2, 1, 3, 2, 1, 0, 4, 4, 3, 2, 0, 1, 2, 4,\n",
      "        0, 3, 2, 1, 3, 2, 2, 1, 3, 4, 3, 4, 0, 4, 0, 0, 2, 3, 1, 2, 4, 1, 2, 1,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 2, 1, 1, 4, 2, 2, 3, 4, 0, 2, 1, 2, 2, 2, 3, 4, 2, 3, 2, 0, 2, 2, 4,\n",
      "        2, 3, 4, 1, 4, 4, 2, 0, 4, 4, 4, 4, 2, 4, 4, 0, 4, 4, 1, 4, 4, 1, 2, 2,\n",
      "        1, 3], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 2, 0, 1, 2, 2, 2, 0, 1, 2, 0, 2, 0, 0, 2, 0, 2, 3, 1, 1, 1, 2, 1,\n",
      "        4, 1, 1, 1, 2, 2, 1, 2, 4, 3, 3, 1, 2, 2, 2, 4, 3, 3, 2, 1, 1, 2, 2, 0,\n",
      "        2, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 2, 4, 1, 2, 4, 4, 4, 1, 4, 0, 4, 0, 0, 4, 0, 4, 3, 4, 4, 1, 2, 1,\n",
      "        4, 4, 4, 2, 4, 2, 0, 4, 4, 2, 3, 4, 2, 2, 4, 4, 4, 3, 2, 1, 2, 3, 2, 0,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 0, 3, 4, 4, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0, 1, 2, 3, 0, 1, 2, 3, 1,\n",
      "        4, 3, 2, 2, 4, 0, 0, 0, 2, 3, 4, 0, 3, 4, 2, 1, 2, 3, 0, 2, 3, 3, 4, 1,\n",
      "        0, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 0, 3, 4, 4, 0, 3, 1, 4, 0, 0, 2, 1, 1, 0, 2, 2, 3, 0, 3, 4, 4, 2,\n",
      "        2, 4, 2, 4, 4, 4, 3, 0, 4, 4, 4, 2, 4, 4, 2, 3, 2, 4, 1, 4, 4, 4, 2, 3,\n",
      "        1, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 4, 0, 0, 0, 3, 2, 1, 3, 3, 2, 2, 0, 0, 4, 0, 2, 3, 4, 2, 2, 1, 0, 2,\n",
      "        3, 1, 3, 1, 4, 1, 4, 1, 4, 2, 1, 1, 4, 1, 4, 0, 3, 1, 0, 3, 0, 0, 0, 0,\n",
      "        1, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 1, 1, 4, 2, 0, 0, 4, 4, 2, 2, 0, 4, 3, 2, 2, 4, 4, 2, 2, 4, 0, 4,\n",
      "        4, 4, 3, 1, 3, 2, 3, 4, 2, 2, 3, 0, 4, 2, 3, 0, 4, 1, 4, 2, 4, 2, 1, 1,\n",
      "        1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([0, 1, 1, 1, 1, 4, 1, 1, 4, 3, 1, 2, 0, 2, 4, 4, 0, 3, 2, 1, 1, 0, 3, 1,\n",
      "        4, 3, 2, 2, 0, 0, 2, 1, 1, 0, 3, 1, 4, 0, 4, 0, 4, 4, 1, 0, 3, 1, 0, 3,\n",
      "        1, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 2, 1, 3, 2, 0, 0, 4, 4, 0, 1, 4, 4, 4, 3, 0, 4, 2, 2, 4, 2, 4, 1,\n",
      "        4, 3, 4, 2, 0, 0, 3, 1, 1, 4, 3, 0, 2, 1, 4, 0, 4, 4, 0, 0, 4, 0, 0, 0,\n",
      "        4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 1, 2, 4, 1, 4, 0, 2, 3, 3, 3, 0, 3, 3, 1, 1, 4, 3, 2, 2, 3, 3, 0,\n",
      "        4, 0, 2, 0, 0, 0, 4, 3, 1, 3, 0, 4, 1, 4, 4, 2, 4, 4, 4, 0, 0, 4, 0, 0,\n",
      "        1, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 0, 3, 2, 4, 1, 4, 2, 2, 4, 1, 4, 1, 4, 3, 2, 4, 4, 3, 3, 2, 4, 4, 4,\n",
      "        4, 0, 1, 0, 0, 2, 4, 4, 1, 3, 1, 4, 2, 4, 2, 1, 2, 4, 4, 4, 4, 4, 0, 1,\n",
      "        4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 3, 2, 1, 4, 0, 0, 0, 0, 0, 3, 0, 1, 3, 3, 4, 2, 1, 1, 4, 4, 3, 1,\n",
      "        2, 0, 4, 0, 4, 4, 2, 2, 0, 3, 3, 2, 2, 0, 3, 1, 2, 1, 1, 1, 0, 1, 0, 2,\n",
      "        3, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 3, 2, 2, 4, 3, 4, 4, 3, 4, 4, 1, 2, 2, 4, 4, 4, 1, 1, 4, 3, 4, 2,\n",
      "        4, 0, 2, 4, 4, 4, 4, 2, 4, 3, 3, 2, 4, 2, 4, 4, 4, 1, 1, 4, 0, 4, 1, 3,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([1, 1, 1, 4, 1, 3, 1, 2, 2, 0, 4, 3, 4, 0, 0, 0, 1, 4, 3, 1, 3, 0, 2, 0,\n",
      "        2, 2, 0, 0, 1, 2, 2, 1, 2, 1, 0, 3, 4, 0, 0, 1, 2, 3, 2, 3, 2, 0, 2, 3,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 1, 4, 3, 4, 1, 4, 4, 1, 4, 4, 4, 0, 0, 2, 1, 2, 3, 3, 3, 0, 4, 2,\n",
      "        2, 4, 0, 4, 0, 2, 4, 0, 4, 2, 2, 4, 1, 3, 0, 3, 4, 4, 4, 4, 4, 0, 1, 3,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([2, 3, 3, 3, 2, 0, 1, 3, 1, 1, 4, 0, 4, 4, 4, 2, 0, 0, 4, 0, 3, 2, 0, 2,\n",
      "        4, 4, 3, 3, 0, 2, 2, 1, 4, 0, 0, 0, 0, 2, 1, 3, 1, 0, 2, 1, 0, 2, 0, 2,\n",
      "        1, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 4, 3, 1, 2, 4, 2, 3, 4, 2, 2, 0, 4, 4, 4, 4, 1, 0, 4, 1, 4, 4, 2, 3,\n",
      "        2, 3, 3, 4, 3, 4, 4, 2, 4, 2, 0, 4, 2, 2, 2, 0, 1, 4, 1, 1, 0, 2, 0, 2,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([4, 0, 1, 4, 3, 0, 2, 2, 3, 1, 4, 1, 0, 1, 4, 0, 0, 1, 1, 2, 1, 3, 0, 0,\n",
      "        2, 3, 2, 1, 0, 4, 0, 3, 2, 2, 2, 4, 2, 4, 3, 4, 0, 2, 0, 4, 2, 2, 3, 3,\n",
      "        1, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 2, 2, 4, 4, 3, 2, 4, 3, 1, 2, 4, 0, 2, 4, 4, 0, 3, 4, 2, 4, 4, 0, 1,\n",
      "        2, 3, 2, 2, 0, 2, 4, 1, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 2, 3, 3,\n",
      "        0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 3, 2, 2, 2, 1, 0, 2, 1, 1, 0, 2, 3, 0, 0, 2, 2, 4, 3, 3, 1, 3, 4, 4,\n",
      "        2, 1, 2, 0, 0, 3, 0, 0, 0, 2, 0, 4, 2, 2, 3, 2, 2, 2, 2, 2, 4, 3, 2, 1,\n",
      "        1, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 4, 4, 3, 1, 4, 2, 1, 4, 2, 2, 4, 1, 0, 2, 2, 4, 4, 0, 2, 2, 3, 3,\n",
      "        3, 1, 4, 0, 2, 4, 2, 2, 0, 2, 4, 4, 2, 2, 3, 2, 4, 1, 2, 4, 4, 3, 0, 1,\n",
      "        3, 2], device='cuda:0')\n",
      "label\n",
      "tensor([1, 4, 1, 2, 4, 0, 4, 0, 1, 4, 2, 3, 3, 1, 4, 4, 2, 0, 0, 0, 0, 1, 2, 4,\n",
      "        2, 4, 0, 1, 3, 2, 0, 0, 4, 0, 1, 4, 2, 4, 0, 2, 2, 1, 4, 1, 1, 4, 1, 4,\n",
      "        3, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 2, 0, 2, 4, 3, 4, 2, 4, 1, 4, 4, 3, 1, 2, 4, 2, 4, 2, 1, 0, 2, 2, 4,\n",
      "        2, 4, 1, 1, 1, 2, 2, 0, 4, 4, 4, 3, 2, 4, 4, 4, 1, 2, 4, 2, 4, 4, 1, 4,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([4, 4, 4, 2, 1, 2, 4, 0, 1, 2, 2, 2, 0, 3, 0, 4, 4, 2, 0, 0, 4, 0, 1, 4,\n",
      "        1, 3, 1, 1, 0, 4, 3, 0, 0, 1, 0, 0, 1, 1, 2, 4, 2, 1, 1, 0, 1, 2, 0, 0,\n",
      "        2, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 4, 4, 0, 4, 2, 0, 1, 4, 4, 2, 4, 4, 0, 4, 4, 2, 0, 0, 2, 3, 2, 4,\n",
      "        0, 3, 2, 0, 3, 4, 4, 1, 4, 3, 4, 4, 4, 0, 4, 4, 4, 1, 2, 1, 4, 2, 3, 1,\n",
      "        4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 3, 0, 1, 0, 1, 4, 0, 1, 3, 3, 1, 1, 0, 4, 3, 1, 0, 4, 3, 0, 3, 2,\n",
      "        3, 2, 2, 2, 4, 0, 0, 0, 1, 3, 0, 1, 1, 4, 0, 2, 1, 3, 2, 2, 3, 4, 4, 1,\n",
      "        4, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 0, 4, 0, 2, 4, 1, 4, 0, 0, 0, 3, 2, 0, 4, 4, 2, 2, 2, 4, 4, 3, 4, 2,\n",
      "        3, 2, 4, 2, 4, 3, 1, 0, 0, 4, 0, 3, 4, 4, 0, 3, 3, 4, 4, 3, 3, 4, 4, 2,\n",
      "        4, 1], device='cuda:0')\n",
      "label\n",
      "tensor([4, 3, 2, 2, 0, 0, 0, 2, 0, 0, 0, 4, 2, 2, 3, 1, 2, 1, 0, 0, 0, 4, 4, 2,\n",
      "        3, 0, 2, 0, 1, 4, 0, 2, 0, 1, 2, 3, 3, 1, 4, 0, 4, 2, 0, 0, 1, 0, 3, 4,\n",
      "        3, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 4, 2, 4, 0, 3, 2, 4, 2, 0, 4, 4, 2, 3, 0, 2, 1, 0, 3, 4, 4, 4, 4,\n",
      "        4, 1, 3, 0, 4, 4, 4, 2, 4, 1, 2, 4, 4, 3, 3, 1, 4, 2, 2, 1, 1, 3, 3, 4,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 3, 4, 1, 4, 0, 4, 0, 3, 0, 2, 4, 1, 0, 1, 3, 2, 4, 2, 4, 0, 0, 0, 0,\n",
      "        4, 2, 3, 0, 1, 3, 4, 3, 2, 2, 0, 3, 1, 1, 0, 3, 1, 0, 2, 1, 2, 3, 0, 1,\n",
      "        0, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 4, 2, 0, 1, 4, 0, 3, 3, 2, 2, 1, 3, 1, 4, 4, 4, 4, 4, 4, 4, 1, 3,\n",
      "        4, 4, 3, 0, 0, 3, 2, 0, 3, 2, 3, 3, 1, 3, 3, 3, 1, 0, 4, 3, 2, 4, 3, 3,\n",
      "        0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 2, 0, 1, 4, 3, 2, 1, 4, 3, 2, 3, 3, 4, 3, 1, 4, 2, 1, 4, 0, 2, 4, 0,\n",
      "        4, 4, 3, 0, 3, 4, 4, 0, 2, 3, 3, 3, 4, 0, 0, 2, 0, 4, 1, 4, 3, 4, 0, 3,\n",
      "        4, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 2, 2, 4, 4, 4, 2, 4, 4, 3, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 0, 2, 4, 4,\n",
      "        2, 0, 3, 1, 4, 4, 4, 3, 4, 2, 3, 4, 4, 0, 1, 4, 0, 4, 4, 4, 4, 3, 4, 4,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([4, 2, 2, 1, 2, 2, 2, 2, 0, 4, 2, 1, 4, 3, 2, 1, 2, 0, 0, 2, 4, 2, 2, 4,\n",
      "        3, 2, 2, 4, 0, 2, 3, 3, 2, 2, 0, 0, 0, 2, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 4, 2, 4, 2, 2, 4, 0, 3, 2, 0, 4, 4, 4, 1, 2, 0, 3, 2, 4, 2, 2, 4,\n",
      "        3, 4, 4, 3, 2, 0, 3, 4, 2, 2, 3, 0, 0, 2, 4], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4122, device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(testloader, model1,model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"/home/shoaibmerajsami/Desktop/Model_hadi/abc.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "tensor([3, 0, 1, 4, 3, 2, 1, 4, 2, 3, 2, 2, 0, 3, 2, 1, 3, 2, 4, 1, 4, 1, 2, 0,\n",
      "        0, 1, 4, 1, 2, 3, 2, 4, 2, 1, 4, 1, 2, 3, 0, 0, 1, 2, 0, 2, 1, 0, 2, 0,\n",
      "        3, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 1, 1, 3, 3, 2, 4, 3, 1, 3, 4, 2, 0, 3, 2, 1, 3, 2, 4, 1, 2, 1, 2, 0,\n",
      "        3, 1, 4, 1, 4, 3, 4, 4, 4, 1, 4, 1, 2, 3, 0, 0, 1, 2, 2, 4, 4, 0, 1, 0,\n",
      "        3, 3], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 1, 0, 0, 2, 1, 1, 0, 0, 4, 3, 0, 1, 3, 1, 2, 4, 0, 2, 2, 4, 2, 4,\n",
      "        1, 0, 4, 4, 2, 1, 0, 0, 2, 1, 2, 4, 1, 2, 0, 0, 2, 2, 2, 2, 2, 4, 2, 2,\n",
      "        4, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 2, 0, 1, 2, 1, 1, 4, 0, 1, 3, 0, 1, 3, 1, 2, 4, 0, 2, 1, 4, 4, 1,\n",
      "        1, 1, 4, 4, 2, 1, 1, 0, 2, 1, 2, 4, 2, 2, 1, 0, 2, 2, 2, 2, 2, 4, 4, 2,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 4, 0, 3, 4, 2, 2, 2, 4, 0, 3, 3, 1, 1, 2, 2, 4, 0, 2, 0, 2, 1, 4,\n",
      "        4, 4, 2, 2, 4, 1, 0, 1, 2, 4, 2, 3, 2, 2, 0, 1, 1, 2, 3, 3, 2, 1, 2, 0,\n",
      "        4, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 4, 4, 3, 2, 3, 2, 4, 4, 2, 3, 3, 4, 2, 4, 2, 4, 1, 4, 4, 2, 1, 4,\n",
      "        2, 4, 1, 2, 2, 1, 4, 1, 2, 4, 2, 3, 2, 4, 0, 1, 1, 2, 3, 4, 2, 1, 2, 0,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 1, 0, 4, 3, 4, 2, 3, 2, 0, 3, 1, 4, 2, 4, 0, 2, 0, 1, 0, 4, 3, 2, 0,\n",
      "        0, 3, 4, 1, 0, 1, 0, 2, 2, 3, 4, 0, 0, 3, 3, 2, 1, 4, 0, 1, 2, 0, 2, 2,\n",
      "        3, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 1, 0, 4, 2, 4, 3, 3, 2, 0, 3, 1, 4, 2, 4, 0, 2, 1, 1, 0, 4, 3, 2, 4,\n",
      "        1, 3, 4, 1, 0, 1, 0, 2, 2, 3, 4, 1, 1, 3, 3, 2, 4, 4, 0, 1, 2, 0, 2, 2,\n",
      "        0, 1], device='cuda:0')\n",
      "label\n",
      "tensor([4, 1, 4, 0, 1, 2, 0, 2, 0, 1, 3, 1, 0, 1, 2, 0, 0, 1, 4, 1, 1, 3, 4, 1,\n",
      "        3, 0, 3, 2, 4, 4, 2, 0, 2, 0, 3, 0, 0, 1, 2, 0, 2, 1, 1, 2, 4, 0, 1, 0,\n",
      "        2, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 4, 1, 1, 2, 0, 1, 1, 2, 3, 1, 1, 1, 4, 0, 2, 1, 4, 1, 1, 4, 2, 0,\n",
      "        3, 0, 4, 2, 4, 4, 4, 0, 4, 1, 1, 0, 0, 4, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1,\n",
      "        2, 3], device='cuda:0')\n",
      "label\n",
      "tensor([4, 3, 4, 0, 1, 1, 0, 2, 0, 3, 2, 1, 0, 1, 4, 0, 4, 0, 4, 4, 1, 1, 2, 2,\n",
      "        2, 3, 2, 1, 1, 0, 3, 0, 1, 2, 2, 1, 2, 2, 1, 0, 3, 2, 3, 3, 0, 4, 4, 3,\n",
      "        1, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 3, 4, 4, 1, 1, 4, 4, 0, 2, 1, 1, 1, 1, 4, 0, 4, 0, 4, 4, 4, 1, 2, 0,\n",
      "        2, 3, 2, 0, 1, 4, 3, 1, 1, 1, 2, 1, 4, 2, 1, 0, 3, 2, 4, 0, 1, 4, 4, 3,\n",
      "        1, 3], device='cuda:0')\n",
      "label\n",
      "tensor([4, 4, 0, 4, 3, 1, 1, 3, 4, 4, 0, 2, 1, 4, 2, 4, 2, 3, 2, 3, 2, 1, 4, 1,\n",
      "        1, 3, 4, 0, 3, 4, 0, 4, 0, 1, 1, 1, 3, 1, 1, 3, 3, 4, 3, 4, 4, 1, 1, 0,\n",
      "        3, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 1, 4, 3, 1, 4, 1, 4, 4, 4, 2, 2, 4, 2, 4, 1, 3, 4, 3, 2, 1, 4, 1,\n",
      "        1, 1, 3, 1, 3, 2, 0, 4, 2, 1, 1, 1, 3, 1, 1, 3, 3, 4, 2, 4, 3, 3, 0, 0,\n",
      "        3, 1], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 1, 1, 1, 0, 3, 2, 4, 1, 3, 0, 2, 0, 1, 2, 0, 3, 1, 0, 1, 2, 3, 1,\n",
      "        0, 1, 3, 1, 4, 1, 2, 1, 3, 3, 0, 3, 4, 0, 2, 1, 4, 3, 4, 4, 1, 4, 0, 2,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 3, 2, 1, 1, 2, 3, 2, 4, 1, 3, 0, 2, 4, 4, 2, 1, 3, 1, 4, 2, 2, 3, 1,\n",
      "        1, 2, 3, 1, 4, 1, 2, 1, 1, 3, 4, 3, 4, 0, 1, 1, 4, 0, 4, 3, 4, 4, 0, 1,\n",
      "        1, 1], device='cuda:0')\n",
      "label\n",
      "tensor([0, 3, 0, 1, 1, 4, 0, 1, 2, 3, 1, 3, 0, 3, 0, 4, 0, 2, 0, 0, 3, 0, 0, 2,\n",
      "        1, 0, 2, 2, 3, 1, 0, 1, 1, 0, 0, 3, 3, 0, 2, 0, 4, 1, 0, 1, 2, 1, 4, 0,\n",
      "        3, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 3, 0, 1, 1, 4, 0, 1, 2, 1, 1, 4, 0, 3, 0, 4, 0, 2, 1, 1, 4, 0, 0, 2,\n",
      "        1, 0, 3, 2, 3, 1, 0, 1, 1, 0, 1, 3, 4, 0, 2, 1, 2, 1, 0, 1, 2, 2, 4, 0,\n",
      "        0, 0], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 0, 0, 0, 3, 4, 1, 3, 2, 2, 0, 1, 2, 1, 2, 0, 3, 2, 2, 0, 4, 2, 3,\n",
      "        0, 4, 1, 0, 0, 2, 3, 3, 1, 3, 0, 0, 3, 0, 4, 3, 2, 1, 1, 2, 2, 3, 4, 0,\n",
      "        1, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 2, 1, 0, 0, 1, 2, 1, 3, 2, 2, 1, 1, 2, 1, 4, 0, 3, 1, 2, 4, 4, 4, 0,\n",
      "        2, 3, 1, 4, 1, 4, 3, 3, 0, 3, 1, 1, 3, 0, 2, 3, 2, 1, 1, 2, 3, 2, 4, 0,\n",
      "        1, 4], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 2, 0, 4, 2, 0, 4, 2, 0, 1, 1, 0, 4, 2, 3, 2, 1, 0, 0, 1, 0, 0, 4,\n",
      "        1, 2, 0, 0, 1, 2, 4, 2, 3, 3, 2, 2, 4, 4, 1, 2, 0, 0, 0, 0, 3, 0, 3, 1,\n",
      "        0, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 0, 1, 0, 4, 2, 0, 4, 2, 0, 1, 1, 0, 4, 2, 3, 2, 1, 0, 1, 1, 0, 1, 4,\n",
      "        1, 2, 4, 0, 1, 2, 4, 2, 3, 3, 4, 4, 4, 4, 2, 3, 0, 0, 0, 0, 4, 0, 3, 1,\n",
      "        0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 2, 4, 1, 0, 2, 4, 1, 0, 4, 2, 3, 4, 2, 1, 1, 2, 3, 4, 3, 1, 4, 0, 2,\n",
      "        4, 1, 3, 0, 2, 0, 2, 3, 3, 3, 2, 2, 4, 2, 4, 0, 1, 4, 0, 1, 3, 1, 2, 2,\n",
      "        2, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 2, 4, 1, 4, 2, 4, 1, 1, 4, 2, 3, 2, 2, 1, 1, 4, 3, 4, 3, 1, 4, 0, 1,\n",
      "        4, 1, 3, 0, 4, 1, 2, 3, 3, 3, 2, 2, 2, 2, 4, 1, 4, 4, 1, 0, 3, 2, 4, 2,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([4, 4, 2, 0, 3, 2, 4, 1, 0, 3, 4, 2, 2, 2, 4, 0, 0, 4, 0, 2, 3, 4, 4, 1,\n",
      "        0, 2, 0, 3, 1, 4, 0, 2, 2, 0, 0, 4, 3, 1, 1, 0, 2, 1, 2, 0, 3, 4, 3, 1,\n",
      "        1, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 2, 1, 3, 0, 4, 1, 2, 4, 2, 2, 2, 2, 4, 0, 0, 4, 0, 4, 3, 4, 4, 1,\n",
      "        0, 2, 0, 3, 1, 4, 0, 1, 2, 0, 0, 4, 3, 1, 1, 0, 2, 1, 0, 1, 3, 4, 3, 4,\n",
      "        1, 0], device='cuda:0')\n",
      "label\n",
      "tensor([3, 4, 0, 0, 4, 3, 0, 2, 1, 2, 4, 0, 0, 4, 2, 1, 4, 0, 1, 2, 4, 1, 4, 0,\n",
      "        1, 1, 0, 0, 3, 2, 2, 0, 2, 1, 3, 0, 4, 4, 2, 1, 2, 0, 0, 0, 2, 3, 3, 1,\n",
      "        2, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 4, 0, 0, 2, 4, 4, 2, 2, 2, 4, 0, 4, 4, 2, 1, 4, 0, 4, 2, 4, 1, 4, 0,\n",
      "        1, 1, 1, 0, 3, 4, 1, 1, 2, 1, 3, 0, 4, 4, 2, 3, 4, 0, 4, 0, 2, 3, 3, 2,\n",
      "        2, 3], device='cuda:0')\n",
      "label\n",
      "tensor([4, 0, 2, 1, 4, 4, 0, 3, 0, 2, 3, 2, 2, 4, 3, 1, 0, 0, 1, 4, 0, 4, 0, 0,\n",
      "        0, 0, 4, 0, 2, 4, 3, 2, 0, 0, 2, 0, 0, 0, 0, 4, 1, 0, 2, 0, 2, 0, 4, 3,\n",
      "        4, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 0, 2, 1, 4, 2, 0, 3, 4, 2, 3, 2, 2, 4, 3, 1, 2, 2, 1, 4, 2, 4, 1, 4,\n",
      "        1, 0, 4, 1, 1, 4, 4, 4, 4, 2, 4, 0, 1, 1, 0, 4, 1, 0, 2, 1, 2, 4, 4, 3,\n",
      "        4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 2, 0, 2, 1, 0, 1, 1, 1, 2, 4, 3, 0, 2, 3, 2, 3, 2, 2, 1, 3, 2, 2,\n",
      "        4, 3, 3, 0, 1, 4, 1, 4, 3, 1, 2, 2, 1, 0, 4, 3, 0, 3, 0, 1, 2, 1, 4, 2,\n",
      "        2, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 2, 0, 4, 1, 1, 1, 1, 2, 3, 4, 3, 2, 4, 3, 4, 1, 2, 2, 2, 1, 2, 2,\n",
      "        4, 1, 3, 0, 1, 4, 1, 2, 3, 1, 0, 2, 1, 0, 4, 3, 0, 3, 1, 1, 2, 1, 4, 2,\n",
      "        2, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 2, 1, 1, 0, 4, 1, 3, 1, 1, 1, 1, 2, 2, 4, 2, 2, 2, 0, 2, 2, 3, 2,\n",
      "        4, 3, 4, 1, 0, 2, 3, 0, 0, 0, 2, 4, 2, 0, 4, 2, 2, 2, 3, 2, 1, 0, 2, 3,\n",
      "        3, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 2, 1, 2, 0, 4, 2, 1, 1, 1, 1, 1, 2, 2, 4, 4, 2, 4, 0, 2, 2, 0, 2,\n",
      "        4, 3, 4, 1, 1, 2, 3, 1, 0, 1, 1, 4, 2, 1, 4, 2, 1, 2, 3, 2, 1, 1, 4, 3,\n",
      "        3, 2], device='cuda:0')\n",
      "label\n",
      "tensor([1, 3, 0, 4, 0, 1, 4, 2, 0, 1, 0, 3, 0, 1, 0, 2, 1, 0, 3, 2, 0, 0, 2, 2,\n",
      "        2, 4, 2, 2, 3, 2, 2, 0, 2, 0, 0, 1, 1, 1, 3, 4, 2, 1, 2, 1, 3, 4, 0, 1,\n",
      "        2, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 3, 0, 4, 0, 1, 3, 2, 0, 1, 1, 3, 1, 1, 2, 2, 1, 1, 3, 2, 0, 3, 2, 2,\n",
      "        2, 4, 2, 2, 1, 2, 2, 1, 2, 0, 1, 1, 1, 1, 0, 4, 2, 4, 1, 1, 3, 1, 0, 1,\n",
      "        1, 0], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 0, 0, 1, 2, 1, 0, 2, 1, 1, 2, 3, 3, 3, 0, 0, 2, 3, 0, 2, 1, 2, 2,\n",
      "        4, 2, 0, 1, 3, 1, 3, 4, 1, 4, 1, 0, 4, 3, 2, 1, 0, 0, 3, 0, 4, 4, 2, 3,\n",
      "        1, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 0, 0, 0, 2, 2, 4, 0, 2, 1, 4, 2, 3, 3, 3, 0, 1, 1, 3, 2, 2, 4, 4, 2,\n",
      "        4, 2, 1, 1, 3, 2, 3, 1, 1, 4, 1, 0, 1, 3, 4, 3, 1, 0, 3, 4, 4, 3, 2, 3,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 4, 0, 0, 2, 1, 2, 4, 3, 1, 1, 2, 2, 0, 1, 4, 0, 0, 1, 2, 2, 0, 1, 4,\n",
      "        0, 1, 2, 2, 4, 1, 0, 3, 0, 4, 2, 3, 4, 0, 0, 3, 4, 3, 0, 0, 4, 4, 1, 4,\n",
      "        2, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 4, 0, 2, 2, 1, 2, 4, 3, 1, 1, 4, 2, 0, 0, 4, 2, 1, 1, 2, 2, 0, 1, 2,\n",
      "        0, 2, 2, 2, 4, 1, 1, 3, 0, 4, 2, 4, 4, 1, 0, 3, 4, 0, 1, 0, 4, 4, 1, 4,\n",
      "        1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([1, 1, 1, 4, 4, 0, 1, 2, 0, 1, 0, 4, 3, 0, 3, 2, 4, 2, 2, 1, 4, 4, 0, 3,\n",
      "        2, 3, 1, 4, 0, 2, 0, 0, 1, 2, 1, 3, 2, 0, 2, 3, 2, 1, 1, 0, 1, 1, 0, 2,\n",
      "        0, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 1, 1, 2, 4, 0, 1, 2, 0, 0, 1, 4, 3, 0, 3, 4, 4, 2, 2, 1, 4, 4, 1, 4,\n",
      "        2, 3, 1, 3, 0, 1, 0, 0, 1, 2, 1, 3, 2, 1, 2, 3, 2, 1, 1, 1, 1, 1, 0, 2,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 2, 2, 0, 4, 4, 3, 4, 1, 4, 0, 1, 2, 2, 4, 4, 4, 4, 0, 1, 0, 3, 2,\n",
      "        2, 3, 3, 0, 0, 3, 0, 4, 3, 2, 0, 4, 2, 4, 1, 0, 3, 1, 1, 3, 3, 0, 1, 2,\n",
      "        4, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 0, 1, 2, 0, 4, 4, 3, 4, 1, 4, 0, 1, 2, 2, 3, 4, 4, 4, 0, 1, 0, 3, 2,\n",
      "        2, 0, 4, 0, 4, 0, 1, 4, 3, 1, 0, 4, 2, 4, 1, 0, 3, 1, 2, 1, 3, 0, 2, 2,\n",
      "        4, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 3, 3, 2, 3, 4, 2, 0, 0, 0, 0, 1, 1, 2, 2, 1, 0, 0, 1, 0, 2, 2, 3,\n",
      "        4, 3, 3, 0, 3, 3, 2, 3, 2, 3, 0, 4, 2, 1, 2, 3, 4, 0, 3, 4, 3, 4, 2, 4,\n",
      "        0, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 3, 4, 1, 2, 1, 2, 0, 1, 3, 0, 1, 4, 2, 2, 1, 3, 0, 1, 1, 2, 2, 3,\n",
      "        2, 3, 3, 4, 3, 3, 1, 3, 2, 3, 1, 4, 2, 1, 2, 3, 4, 4, 3, 4, 3, 4, 2, 4,\n",
      "        0, 1], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 4, 0, 0, 4, 0, 0, 0, 4, 2, 4, 3, 2, 3, 0, 3, 1, 0, 3, 3, 4, 2, 0,\n",
      "        2, 2, 1, 0, 3, 0, 4, 3, 2, 4, 3, 2, 4, 1, 4, 0, 3, 2, 3, 2, 2, 1, 0, 3,\n",
      "        4, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 2, 0, 1, 4, 4, 1, 0, 4, 2, 4, 2, 2, 3, 0, 3, 1, 0, 3, 3, 4, 2, 0,\n",
      "        4, 2, 1, 0, 3, 0, 3, 3, 4, 4, 3, 2, 4, 0, 4, 0, 3, 4, 3, 1, 2, 1, 1, 4,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 4, 0, 1, 1, 3, 1, 2, 2, 0, 1, 1, 2, 4, 2, 0, 0, 3, 0, 3, 0, 2, 2,\n",
      "        0, 2, 1, 1, 0, 0, 1, 2, 4, 2, 2, 0, 2, 3, 2, 3, 2, 3, 4, 1, 4, 0, 1, 1,\n",
      "        1, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 4, 1, 1, 1, 3, 1, 2, 2, 0, 4, 1, 0, 4, 1, 0, 4, 3, 0, 3, 0, 2, 2,\n",
      "        0, 2, 1, 1, 1, 0, 1, 2, 4, 2, 2, 0, 2, 3, 2, 3, 4, 3, 2, 1, 4, 1, 1, 1,\n",
      "        1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([0, 3, 3, 1, 1, 2, 1, 4, 4, 3, 1, 2, 4, 3, 4, 4, 2, 0, 0, 0, 2, 0, 2, 1,\n",
      "        2, 2, 1, 4, 3, 3, 3, 3, 4, 0, 0, 0, 3, 2, 4, 0, 4, 4, 3, 4, 1, 0, 1, 4,\n",
      "        0, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 3, 3, 1, 1, 4, 1, 4, 4, 3, 1, 2, 4, 3, 4, 4, 2, 1, 1, 0, 2, 1, 1, 1,\n",
      "        2, 2, 1, 4, 3, 3, 3, 1, 4, 0, 0, 1, 3, 2, 4, 0, 4, 4, 3, 4, 1, 1, 2, 1,\n",
      "        0, 3], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 3, 4, 1, 2, 0, 0, 1, 4, 1, 2, 0, 0, 1, 1, 4, 0, 2, 3, 4, 4, 3, 3,\n",
      "        0, 4, 1, 4, 3, 0, 1, 1, 0, 1, 3, 1, 3, 2, 3, 1, 3, 3, 1, 0, 4, 2, 0, 1,\n",
      "        1, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 4, 3, 4, 1, 2, 0, 0, 1, 4, 1, 2, 0, 1, 1, 1, 4, 3, 2, 3, 4, 4, 3, 3,\n",
      "        1, 4, 1, 4, 4, 2, 1, 1, 4, 1, 3, 1, 3, 4, 3, 0, 3, 3, 1, 0, 4, 2, 1, 1,\n",
      "        2, 2], device='cuda:0')\n",
      "label\n",
      "tensor([3, 4, 1, 0, 1, 1, 2, 4, 2, 0, 3, 0, 0, 1, 3, 0, 1, 1, 2, 3, 3, 1, 0, 3,\n",
      "        2, 4, 0, 4, 3, 0, 0, 2, 4, 0, 2, 0, 1, 1, 3, 1, 0, 3, 4, 1, 1, 0, 0, 3,\n",
      "        0, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 4, 1, 0, 3, 1, 2, 4, 2, 0, 3, 0, 0, 1, 1, 0, 1, 1, 2, 3, 3, 1, 2, 3,\n",
      "        3, 4, 0, 4, 3, 0, 1, 2, 4, 0, 2, 0, 1, 1, 3, 1, 1, 4, 2, 4, 1, 0, 0, 3,\n",
      "        0, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 1, 2, 1, 1, 0, 3, 0, 0, 2, 1, 0, 2, 0, 3, 0, 0, 1, 3, 2, 1, 3, 0,\n",
      "        4, 0, 2, 2, 1, 3, 4, 3, 0, 2, 0, 2, 4, 2, 1, 2, 1, 3, 3, 1, 0, 4, 1, 2,\n",
      "        3, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 1, 1, 4, 2, 1, 0, 1, 0, 0, 3, 2, 1, 2, 0, 3, 0, 4, 1, 3, 4, 1, 3, 0,\n",
      "        2, 2, 2, 2, 1, 3, 4, 3, 0, 4, 1, 4, 4, 2, 1, 4, 1, 3, 3, 1, 0, 4, 4, 2,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([0, 3, 3, 2, 2, 2, 1, 1, 1, 2, 0, 1, 0, 0, 2, 0, 2, 2, 4, 2, 0, 4, 3, 1,\n",
      "        0, 3, 3, 3, 0, 0, 1, 4, 2, 4, 2, 3, 2, 3, 2, 2, 4, 1, 1, 3, 0, 0, 4, 3,\n",
      "        4, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 3, 3, 4, 2, 2, 1, 1, 1, 2, 0, 1, 1, 1, 2, 0, 4, 2, 4, 2, 0, 4, 3, 1,\n",
      "        1, 1, 4, 3, 0, 0, 4, 4, 4, 4, 1, 3, 1, 3, 2, 2, 4, 4, 1, 0, 2, 1, 4, 3,\n",
      "        4, 0], device='cuda:0')\n",
      "label\n",
      "tensor([3, 2, 0, 0, 4, 3, 3, 3, 1, 4, 0, 2, 0, 0, 1, 2, 2, 0, 1, 1, 4, 3, 1, 2,\n",
      "        1, 4, 3, 1, 4, 2, 3, 1, 2, 0, 2, 2, 4, 1, 2, 0, 0, 3, 4, 2, 1, 1, 0, 2,\n",
      "        0, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 1, 2, 0, 4, 3, 3, 3, 1, 4, 0, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 4,\n",
      "        1, 4, 3, 1, 4, 2, 3, 1, 2, 0, 1, 2, 4, 1, 2, 0, 0, 3, 4, 1, 1, 1, 0, 4,\n",
      "        1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([1, 4, 3, 0, 4, 3, 1, 4, 4, 1, 1, 1, 0, 3, 0, 4, 4, 3, 0, 1, 0, 3, 4, 4,\n",
      "        2, 4, 0, 0, 0, 1, 4, 3, 1, 3, 2, 3, 1, 2, 1, 4, 4, 2, 0, 0, 3, 1, 3, 1,\n",
      "        3, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 4, 3, 0, 4, 3, 1, 4, 4, 1, 1, 4, 0, 3, 2, 4, 4, 3, 3, 1, 1, 3, 4, 2,\n",
      "        2, 4, 2, 0, 0, 1, 4, 3, 1, 3, 2, 3, 4, 4, 1, 4, 4, 4, 2, 2, 3, 1, 3, 1,\n",
      "        3, 2], device='cuda:0')\n",
      "label\n",
      "tensor([0, 1, 3, 1, 3, 0, 0, 2, 3, 3, 2, 0, 0, 3, 2, 2, 1, 0, 2, 1, 4, 1, 0, 3,\n",
      "        4, 3, 3, 2, 3, 0, 0, 4, 1, 1, 4, 0, 3, 2, 4, 2, 1, 2, 4, 4, 0, 2, 0, 0,\n",
      "        1, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 3, 1, 3, 2, 0, 2, 3, 3, 2, 0, 1, 3, 2, 2, 1, 0, 2, 1, 4, 2, 1, 3,\n",
      "        4, 2, 4, 2, 0, 1, 0, 1, 1, 1, 4, 0, 3, 1, 4, 1, 1, 2, 2, 4, 0, 2, 4, 0,\n",
      "        2, 3], device='cuda:0')\n",
      "label\n",
      "tensor([3, 3, 4, 4, 0, 0, 2, 1, 3, 2, 0, 0, 3, 3, 1, 0, 3, 0, 2, 4, 1, 3, 1, 0,\n",
      "        4, 0, 1, 4, 3, 1, 0, 0, 0, 0, 2, 1, 1, 4, 2, 1, 0, 4, 4, 4, 1, 0, 0, 1,\n",
      "        0, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 3, 2, 4, 2, 0, 0, 4, 3, 2, 0, 3, 3, 3, 1, 0, 3, 0, 0, 4, 1, 3, 4, 0,\n",
      "        4, 0, 1, 4, 1, 1, 0, 0, 0, 0, 4, 1, 1, 4, 2, 1, 0, 4, 4, 4, 1, 0, 1, 1,\n",
      "        1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 2, 4, 1, 1, 0, 3, 1, 2, 2, 2, 1, 1, 2, 1, 3, 2, 2, 4, 4, 2, 3, 0,\n",
      "        2, 2, 0, 3, 4, 2, 1, 4, 3, 2, 1, 3, 0, 1, 0, 4, 1, 4, 4, 3, 3, 0, 0, 0,\n",
      "        1, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 2, 3, 4, 1, 1, 1, 3, 1, 4, 2, 2, 1, 1, 2, 1, 3, 2, 2, 4, 4, 2, 2, 3,\n",
      "        2, 2, 1, 3, 4, 2, 1, 4, 3, 4, 1, 1, 0, 2, 1, 1, 1, 4, 3, 3, 0, 0, 1, 0,\n",
      "        4, 1], device='cuda:0')\n",
      "label\n",
      "tensor([3, 2, 0, 1, 3, 0, 4, 2, 4, 2, 1, 0, 0, 4, 4, 4, 2, 2, 0, 0, 1, 0, 3, 4,\n",
      "        1, 1, 2, 0, 1, 2, 2, 0, 4, 2, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 2, 0, 2,\n",
      "        1, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 2, 4, 1, 3, 0, 2, 2, 2, 4, 1, 0, 0, 4, 4, 4, 4, 2, 0, 4, 1, 4, 3, 4,\n",
      "        1, 1, 3, 0, 1, 4, 2, 0, 4, 4, 4, 0, 2, 1, 2, 1, 0, 1, 1, 1, 4, 2, 0, 2,\n",
      "        1, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 4, 2, 0, 1, 0, 0, 4, 3, 4, 2, 0, 4, 4, 2, 2, 3, 2, 2, 0, 1, 4, 2,\n",
      "        3, 1, 1, 1, 4, 1, 3, 1, 1, 2, 4, 0, 4, 4, 2, 1, 4, 2, 0, 1, 4, 0, 3, 3,\n",
      "        4, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 1, 4, 4, 0, 1, 1, 0, 4, 3, 4, 2, 0, 4, 4, 2, 1, 3, 2, 2, 1, 1, 4, 2,\n",
      "        3, 1, 1, 1, 0, 1, 3, 1, 1, 2, 2, 1, 1, 4, 4, 4, 4, 0, 1, 1, 4, 4, 3, 3,\n",
      "        4, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 3, 4, 2, 3, 1, 4, 2, 0, 2, 2, 4, 0, 3, 0, 0, 1, 1, 0, 2, 4, 4, 2,\n",
      "        0, 4, 2, 3, 0, 1, 2, 3, 2, 0, 0, 2, 2, 1, 0, 4, 4, 4, 1, 0, 2, 3, 3, 2,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 0, 3, 4, 2, 3, 1, 4, 2, 0, 2, 2, 4, 0, 3, 0, 0, 1, 1, 1, 2, 4, 4, 2,\n",
      "        0, 4, 2, 4, 0, 4, 2, 3, 2, 0, 0, 2, 2, 1, 1, 4, 4, 4, 1, 0, 2, 4, 2, 1,\n",
      "        2, 2], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 3, 0, 2, 2, 3, 3, 0, 3, 3, 2, 3, 1, 0, 1, 4, 0, 2, 2, 3, 1, 1, 0,\n",
      "        1, 0, 4, 4, 4, 3, 0, 1, 3, 4, 2, 0, 1, 1, 4, 1, 2, 2, 2, 4, 1, 0, 0, 0,\n",
      "        4, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 0, 3, 4, 2, 2, 3, 2, 0, 3, 3, 1, 1, 0, 0, 1, 0, 0, 2, 2, 4, 0, 1, 0,\n",
      "        1, 0, 4, 4, 1, 3, 1, 1, 0, 2, 1, 3, 1, 1, 4, 4, 1, 1, 3, 4, 2, 0, 1, 0,\n",
      "        4, 3], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 2, 1, 2, 1, 4, 2, 1, 0, 2, 3, 3, 2, 3, 0, 3, 2, 1, 1, 1, 4, 2, 2,\n",
      "        4, 3, 0, 1, 1, 4, 0, 2, 2, 1, 3, 1, 1, 2, 4, 1, 2, 1, 1, 2, 3, 0, 0, 2,\n",
      "        2, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 1, 3, 1, 2, 1, 2, 2, 1, 4, 4, 3, 3, 2, 1, 1, 1, 4, 1, 1, 1, 4, 2, 4,\n",
      "        4, 3, 2, 1, 2, 4, 0, 2, 2, 1, 3, 1, 0, 2, 4, 1, 3, 1, 1, 2, 3, 1, 1, 4,\n",
      "        2, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 4, 0, 1, 3, 0, 2, 0, 1, 3, 2, 3, 3, 2, 0, 4, 2, 2, 2, 2, 0, 0, 4, 0,\n",
      "        0, 1, 1, 2, 2, 1, 0, 3, 0, 2, 1, 1, 2, 0, 1, 4, 3, 4, 4, 0, 3, 4, 0, 3,\n",
      "        3, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 4, 0, 1, 4, 0, 1, 0, 4, 1, 4, 2, 3, 2, 0, 2, 2, 1, 2, 2, 0, 0, 4, 0,\n",
      "        1, 1, 1, 1, 2, 1, 4, 3, 1, 2, 1, 1, 1, 0, 4, 1, 3, 4, 2, 1, 3, 4, 4, 3,\n",
      "        3, 2], device='cuda:0')\n",
      "label\n",
      "tensor([2, 0, 1, 4, 0, 1, 1, 4, 0, 3, 1, 1, 0, 2, 2, 1, 2, 4, 2, 3, 1, 4, 0, 0,\n",
      "        4, 0, 1, 4, 2, 2, 0, 0, 3, 1, 1, 2, 2, 2, 0, 1, 0, 1, 2, 4, 0, 4, 0, 2,\n",
      "        2, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 1, 1, 0, 2, 1, 1, 0, 3, 1, 1, 4, 2, 2, 1, 1, 4, 2, 4, 2, 4, 1, 0,\n",
      "        4, 4, 1, 4, 4, 2, 1, 0, 3, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 4, 3, 4, 0, 1,\n",
      "        1, 3], device='cuda:0')\n",
      "label\n",
      "tensor([3, 0, 0, 2, 0, 0, 4, 3, 3, 0, 1, 2, 4, 4, 2, 3, 4, 1, 0, 2, 3, 1, 3, 4,\n",
      "        3, 1, 0, 0, 2, 2, 0, 4, 0, 4, 2, 2, 0, 4, 2, 1, 4, 3, 1, 3, 4, 2, 2, 0,\n",
      "        1, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 0, 1, 2, 1, 1, 4, 3, 3, 0, 1, 2, 4, 4, 2, 3, 4, 2, 1, 2, 3, 2, 1, 4,\n",
      "        3, 4, 0, 0, 2, 2, 0, 2, 1, 4, 1, 2, 0, 2, 4, 4, 2, 3, 4, 0, 4, 2, 4, 0,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 2, 4, 0, 2, 2, 2, 2, 0, 1, 0, 4, 4, 0, 0, 1, 4, 0, 4, 4, 4, 0, 3, 3,\n",
      "        1, 1, 1, 3, 0, 1, 1, 3, 2, 1, 1, 4, 1, 2, 4, 1, 0, 2, 0, 3, 3, 3, 0, 2,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 2, 4, 1, 4, 2, 2, 2, 2, 1, 4, 4, 4, 2, 0, 1, 4, 4, 4, 4, 2, 1, 0, 3,\n",
      "        1, 1, 1, 3, 4, 4, 1, 3, 2, 2, 1, 4, 1, 1, 4, 1, 0, 2, 4, 0, 3, 3, 1, 1,\n",
      "        0, 2], device='cuda:0')\n",
      "label\n",
      "tensor([0, 2, 4, 4, 0, 0, 0, 2, 3, 4, 2, 1, 3, 4, 4, 4, 0, 2, 3, 0, 1, 2, 0, 2,\n",
      "        3, 1, 3, 3, 3, 4, 4, 0, 3, 3, 0, 2, 2, 0, 2, 3, 2, 2, 4, 4, 1, 0, 2, 1,\n",
      "        3, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 2, 4, 4, 0, 0, 1, 2, 3, 2, 2, 1, 3, 1, 4, 0, 0, 1, 3, 0, 1, 3, 0, 2,\n",
      "        3, 1, 3, 3, 3, 4, 2, 3, 3, 0, 1, 2, 4, 0, 4, 3, 2, 2, 4, 4, 2, 4, 2, 1,\n",
      "        3, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 4, 0, 2, 3, 3, 0, 2, 4, 1, 3, 0, 4, 1, 0, 1, 0, 0, 0, 2, 1, 4, 3, 2,\n",
      "        3, 0, 3, 3, 3, 0, 0, 4, 2, 2, 0, 4, 0, 4, 4, 2, 2, 2, 0, 0, 3, 4, 1, 3,\n",
      "        2, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 4, 1, 2, 3, 3, 4, 2, 2, 1, 3, 0, 3, 1, 0, 4, 0, 0, 1, 1, 4, 4, 4, 2,\n",
      "        3, 1, 2, 3, 3, 1, 0, 4, 2, 2, 0, 4, 0, 4, 3, 2, 2, 1, 2, 4, 0, 4, 1, 3,\n",
      "        3, 4], device='cuda:0')\n",
      "label\n",
      "tensor([2, 2, 2, 0, 1, 2, 2, 3, 3, 2, 1, 0, 2, 2, 1, 1, 1, 4, 2, 2, 2, 4, 1, 2,\n",
      "        0, 3, 1, 2, 3, 2, 1, 3, 3, 4, 1, 2, 2, 2, 1, 2, 4, 0, 0, 4, 2, 1, 3, 0,\n",
      "        0, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 2, 1, 0, 1, 2, 4, 3, 1, 4, 4, 4, 2, 0, 1, 0, 1, 4, 2, 2, 1, 4, 1, 1,\n",
      "        0, 3, 1, 1, 4, 2, 1, 3, 2, 4, 1, 4, 2, 4, 4, 2, 4, 0, 0, 0, 2, 1, 3, 1,\n",
      "        0, 1], device='cuda:0')\n",
      "label\n",
      "tensor([0, 1, 1, 0, 0, 2, 3, 1, 3, 3, 2, 0, 4, 1, 3, 2, 1, 1, 0, 0, 1, 2, 3, 2,\n",
      "        4, 1, 3, 1, 3, 3, 4, 2, 0, 4, 1, 1, 2, 1, 0, 0, 0, 3, 1, 1, 4, 2, 0, 1,\n",
      "        2, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 1, 0, 0, 0, 2, 2, 1, 3, 1, 2, 0, 4, 1, 3, 1, 1, 1, 0, 0, 2, 2, 3, 2,\n",
      "        4, 1, 3, 1, 1, 3, 4, 2, 0, 4, 1, 4, 2, 1, 0, 0, 0, 2, 1, 1, 4, 2, 1, 1,\n",
      "        2, 2], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 1, 2, 0, 0, 4, 0, 3, 3, 3, 0, 0, 1, 0, 2, 1, 1, 3, 3, 3, 4, 1, 2,\n",
      "        1, 1, 3, 1, 1, 3, 1, 2, 0, 2, 2, 3, 0, 3, 3, 2, 1, 3, 4, 3, 4, 2, 1, 4,\n",
      "        1, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 3, 1, 4, 1, 1, 4, 1, 3, 3, 3, 0, 0, 1, 1, 2, 2, 4, 3, 3, 3, 4, 2, 2,\n",
      "        1, 1, 3, 1, 1, 3, 1, 1, 0, 2, 2, 3, 0, 1, 3, 2, 1, 3, 1, 3, 3, 2, 1, 4,\n",
      "        1, 0], device='cuda:0')\n",
      "label\n",
      "tensor([3, 0, 2, 4, 4, 1, 1, 1, 3, 3, 3, 1, 1, 0, 4, 3, 3, 1, 4, 0, 3, 2, 3, 0,\n",
      "        3, 1, 2, 2, 0, 4, 2, 1, 1, 0, 2, 4, 4, 1, 1, 0, 3, 1, 1, 1, 0, 4, 4, 1,\n",
      "        2, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 0, 1, 1, 4, 1, 1, 1, 3, 3, 4, 1, 1, 0, 4, 2, 3, 1, 4, 1, 3, 2, 3, 0,\n",
      "        3, 1, 2, 2, 0, 2, 1, 1, 1, 0, 2, 3, 4, 1, 1, 0, 3, 1, 4, 1, 4, 4, 4, 1,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([4, 2, 0, 1, 1, 4, 4, 3, 4, 4, 1, 2, 4, 0, 0, 3, 1, 0, 0, 4, 2, 1, 2, 4,\n",
      "        2, 4, 2, 0, 2, 2, 0, 0, 0, 2, 3, 1, 2, 3, 3, 3, 0, 0, 3, 4, 0, 2, 0, 4,\n",
      "        2, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 1, 1, 1, 4, 4, 3, 4, 4, 1, 2, 4, 0, 1, 1, 1, 0, 3, 4, 2, 1, 2, 4,\n",
      "        4, 4, 2, 0, 2, 2, 1, 0, 3, 0, 3, 1, 1, 0, 3, 3, 1, 4, 2, 4, 0, 2, 0, 2,\n",
      "        1, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 3, 3, 3, 0, 1, 2, 0, 2, 1, 0, 1, 0, 4, 2, 4, 3, 2, 2, 0, 1, 0, 2, 3,\n",
      "        4, 4, 2, 3, 3, 0, 2, 0, 4, 1, 0, 0, 0, 1, 0, 3, 4, 2, 4, 1, 4, 1, 2, 3,\n",
      "        3, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 3, 3, 3, 0, 1, 4, 0, 2, 1, 4, 1, 4, 2, 2, 4, 3, 4, 2, 1, 1, 0, 4, 3,\n",
      "        4, 4, 2, 3, 3, 0, 2, 0, 4, 1, 0, 0, 0, 1, 4, 3, 4, 1, 4, 4, 4, 1, 1, 3,\n",
      "        3, 3], device='cuda:0')\n",
      "label\n",
      "tensor([4, 1, 1, 3, 1, 4, 3, 1, 3, 1, 2, 0, 0, 4, 1, 0, 4, 3, 3, 2, 4, 2, 0, 4,\n",
      "        2, 4, 1, 3, 0, 2, 4, 0, 1, 0, 3, 0, 1, 0, 4, 4, 4, 4, 1, 0, 2, 0, 1, 0,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 1, 3, 1, 4, 3, 0, 3, 1, 2, 1, 1, 4, 1, 3, 4, 3, 3, 2, 1, 1, 1, 4,\n",
      "        4, 3, 1, 3, 0, 2, 4, 0, 1, 0, 1, 0, 4, 0, 4, 1, 1, 4, 1, 0, 2, 0, 1, 0,\n",
      "        0, 2], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 2, 2, 4, 4, 2, 1, 1, 3, 3, 4, 0, 4, 0, 2, 0, 0, 0, 4, 0, 3, 4, 3,\n",
      "        2, 2, 1, 2, 4, 3, 0, 3, 0, 0, 2, 0, 0, 3, 2, 2, 4, 2, 1, 0, 1, 4, 4, 0,\n",
      "        1, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 1, 2, 4, 4, 4, 2, 1, 1, 4, 3, 4, 4, 1, 0, 1, 0, 1, 1, 4, 0, 1, 4, 3,\n",
      "        2, 2, 1, 4, 4, 3, 0, 3, 0, 1, 2, 0, 0, 3, 2, 2, 0, 2, 2, 1, 1, 4, 4, 0,\n",
      "        1, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 0, 4, 1, 4, 0, 1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 2, 3, 3, 3, 1, 0, 0, 1,\n",
      "        1, 2, 4, 4, 2, 2, 3, 2, 2, 0, 2, 1, 0, 2, 0, 4, 4, 3, 0, 1, 2, 1, 1, 1,\n",
      "        2, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 1, 4, 1, 4, 3, 1, 4, 2, 1, 2, 1, 2, 1, 0, 2, 2, 3, 3, 3, 1, 1, 0, 1,\n",
      "        1, 2, 1, 4, 2, 1, 0, 2, 2, 0, 2, 1, 0, 2, 0, 2, 4, 3, 0, 1, 2, 1, 1, 1,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([0, 4, 3, 3, 4, 2, 4, 3, 0, 0, 3, 4, 0, 1, 0, 0, 0, 2, 4, 2, 2, 4, 2, 2,\n",
      "        2, 4, 3, 4, 0, 4, 2, 2, 2, 1, 3, 2, 2, 2, 2, 4, 4, 4, 1, 3, 0, 1, 1, 1,\n",
      "        2, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 4, 3, 3, 4, 2, 4, 3, 1, 1, 3, 4, 2, 2, 1, 0, 1, 2, 4, 4, 3, 4, 2, 1,\n",
      "        3, 4, 3, 4, 0, 4, 4, 2, 1, 1, 3, 4, 4, 2, 1, 4, 2, 3, 1, 3, 1, 1, 1, 3,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([0, 2, 4, 0, 4, 4, 3, 1, 0, 3, 1, 3, 4, 2, 4, 4, 2, 3, 2, 0, 1, 1, 2, 2,\n",
      "        4, 0, 2, 2, 3, 1, 4, 2, 2, 3, 2, 1, 0, 1, 1, 0, 0, 0, 4, 1, 4, 2, 4, 3,\n",
      "        0, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 2, 1, 0, 4, 4, 3, 1, 0, 3, 1, 1, 4, 2, 4, 4, 2, 3, 2, 4, 1, 1, 1, 2,\n",
      "        4, 0, 2, 2, 0, 1, 4, 2, 1, 3, 1, 1, 0, 1, 1, 0, 1, 0, 4, 1, 4, 2, 4, 3,\n",
      "        0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([3, 4, 4, 2, 3, 3, 3, 1, 2, 2, 4, 1, 3, 3, 4, 3, 1, 4, 0, 4, 1, 3, 0, 4,\n",
      "        3, 1, 0, 0, 2, 1, 0, 2, 0, 1, 3, 4, 0, 4, 2, 2, 0, 2, 0, 0, 2, 1, 3, 3,\n",
      "        4, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 4, 2, 1, 3, 3, 2, 2, 2, 2, 4, 3, 3, 2, 0, 1, 4, 0, 2, 1, 3, 1, 4,\n",
      "        3, 0, 0, 0, 4, 1, 0, 2, 0, 1, 3, 4, 1, 4, 4, 2, 1, 2, 0, 0, 2, 1, 4, 0,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([4, 3, 3, 1, 3, 2, 2, 2, 4, 1, 1, 0, 1, 1, 4, 3, 2, 2, 4, 0, 1, 1, 1, 1,\n",
      "        4, 1, 4, 2, 1, 2, 2, 2, 1, 4, 1, 1, 1, 3, 2, 3, 3, 2, 4, 4, 3, 0, 1, 4,\n",
      "        4, 0], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 3, 0, 1, 3, 2, 1, 2, 4, 1, 1, 0, 0, 1, 4, 1, 1, 2, 4, 0, 4, 1, 1, 2,\n",
      "        4, 1, 4, 1, 2, 2, 2, 2, 1, 4, 1, 1, 1, 2, 2, 4, 3, 4, 4, 4, 1, 0, 2, 4,\n",
      "        4, 1], device='cuda:0')\n",
      "label\n",
      "tensor([0, 4, 1, 4, 1, 3, 3, 2, 2, 4, 0, 3, 1, 4, 0, 1, 3, 3, 0, 4, 4, 0, 4, 0,\n",
      "        0, 0, 2, 2, 0, 0, 0, 1, 3, 0, 1, 0, 3, 1, 0, 4, 2, 4, 1, 4, 0, 2, 0, 4,\n",
      "        2, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 4, 4, 4, 1, 3, 1, 2, 2, 4, 0, 3, 1, 4, 0, 1, 3, 3, 1, 4, 4, 0, 4, 0,\n",
      "        0, 2, 2, 4, 0, 1, 4, 1, 3, 4, 1, 0, 3, 1, 1, 4, 2, 4, 1, 4, 0, 2, 0, 4,\n",
      "        2, 1], device='cuda:0')\n",
      "label\n",
      "tensor([3, 1, 0, 2, 0, 4, 4, 2, 2, 2, 2, 1, 4, 3, 2, 4, 0, 0, 3, 0, 2, 0, 4, 4,\n",
      "        1, 4, 1, 3, 2, 3, 4, 3, 4, 2, 3, 2, 2, 2, 4, 3, 2, 1, 4, 0, 1, 4, 2, 1,\n",
      "        4, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 1, 1, 2, 0, 4, 3, 2, 2, 2, 2, 4, 2, 3, 4, 4, 0, 0, 1, 1, 2, 0, 4, 4,\n",
      "        1, 4, 1, 1, 2, 0, 4, 3, 4, 4, 0, 2, 2, 4, 4, 1, 4, 2, 4, 1, 4, 4, 1, 1,\n",
      "        4, 1], device='cuda:0')\n",
      "label\n",
      "tensor([1, 4, 1, 1, 3, 2, 2, 1, 0, 4, 2, 0, 2, 2, 1, 1, 2, 4, 2, 2, 3, 0, 1, 4,\n",
      "        3, 1, 1, 2, 0, 0, 1, 2, 1, 4, 0, 4, 2, 0, 0, 4, 2, 0, 0, 4, 3, 2, 0, 3,\n",
      "        0, 1], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 1, 1, 1, 3, 2, 2, 4, 4, 4, 4, 0, 4, 2, 1, 1, 4, 4, 2, 4, 0, 0, 1, 2,\n",
      "        3, 1, 4, 2, 4, 1, 1, 2, 1, 4, 4, 4, 2, 1, 3, 4, 4, 1, 4, 4, 3, 2, 0, 3,\n",
      "        0, 1], device='cuda:0')\n",
      "label\n",
      "tensor([4, 1, 4, 1, 3, 0, 4, 1, 2, 3, 4, 1, 0, 3, 2, 0, 2, 1, 2, 1, 3, 2, 0, 2,\n",
      "        3, 1, 4, 4, 1, 1, 4, 4, 1, 4, 3, 4, 1, 0, 0, 1, 2, 2, 0, 1, 2, 3, 1, 4,\n",
      "        4, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 0, 4, 1, 3, 0, 2, 1, 1, 3, 4, 1, 0, 4, 2, 0, 4, 1, 2, 2, 3, 2, 0, 2,\n",
      "        3, 1, 2, 2, 1, 1, 4, 4, 1, 4, 4, 4, 1, 0, 3, 1, 3, 2, 0, 4, 4, 3, 4, 0,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([4, 0, 2, 2, 1, 0, 0, 4, 2, 0, 3, 0, 0, 1, 0, 3, 0, 1, 1, 2, 0, 1, 2, 0,\n",
      "        2, 1, 2, 4, 4, 0, 2, 1, 2, 4, 0, 0, 1, 2, 0, 2, 0, 0, 4, 4, 0, 2, 3, 0,\n",
      "        4, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([2, 0, 2, 2, 1, 1, 4, 4, 2, 0, 3, 0, 2, 1, 0, 3, 0, 4, 1, 4, 4, 1, 2, 0,\n",
      "        2, 1, 4, 4, 4, 1, 2, 1, 4, 3, 1, 0, 1, 2, 0, 2, 0, 0, 4, 4, 4, 1, 3, 0,\n",
      "        4, 1], device='cuda:0')\n",
      "label\n",
      "tensor([2, 1, 4, 2, 1, 2, 2, 3, 4, 4, 1, 3, 2, 4, 0, 2, 0, 3, 4, 3, 0, 1, 3, 3,\n",
      "        0, 0, 4, 3, 2, 2, 3, 0, 4, 1, 1, 4, 4, 3, 1, 4, 4, 4, 4, 4, 1, 2, 3, 1,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 1, 4, 2, 1, 2, 3, 3, 4, 4, 1, 3, 2, 4, 1, 2, 1, 4, 4, 3, 1, 2, 3, 3,\n",
      "        0, 1, 4, 3, 0, 2, 3, 1, 4, 1, 1, 0, 4, 3, 1, 4, 4, 4, 4, 4, 1, 2, 3, 1,\n",
      "        1, 2], device='cuda:0')\n",
      "label\n",
      "tensor([3, 4, 2, 3, 1, 2, 1, 2, 1, 1, 1, 2, 1, 4, 1, 3, 0, 2, 0, 3, 3, 4, 2, 4,\n",
      "        1, 1, 0, 0, 2, 2, 1, 1, 0, 2, 3, 2, 3, 0, 1, 3, 4, 3, 1, 0, 2, 2, 3, 0,\n",
      "        0, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([3, 4, 2, 3, 1, 2, 1, 2, 1, 2, 1, 1, 1, 4, 1, 1, 0, 2, 0, 1, 1, 4, 2, 4,\n",
      "        1, 1, 0, 1, 2, 2, 1, 1, 2, 2, 3, 1, 3, 0, 1, 1, 4, 3, 1, 0, 2, 2, 3, 0,\n",
      "        0, 4], device='cuda:0')\n",
      "label\n",
      "tensor([0, 1, 2, 2, 0, 2, 4, 0, 1, 4, 0, 0, 1, 0, 3, 1, 0, 4, 4, 2, 0, 0, 0, 1,\n",
      "        4, 4, 3, 4, 3, 4, 2, 3, 3, 4, 0, 1, 2, 4, 3, 3, 1, 4, 3, 4, 2, 3, 0, 4,\n",
      "        1, 4], device='cuda:0')\n",
      "prediction next\n",
      "tensor([0, 1, 2, 2, 0, 2, 4, 0, 2, 4, 0, 2, 1, 1, 3, 1, 1, 4, 4, 4, 1, 2, 0, 1,\n",
      "        0, 4, 3, 4, 3, 4, 1, 3, 3, 2, 0, 1, 2, 4, 3, 2, 1, 4, 3, 4, 2, 0, 0, 4,\n",
      "        1, 3], device='cuda:0')\n",
      "label\n",
      "tensor([4, 4, 0, 0, 1, 4, 2, 3, 0, 0, 4, 2, 3, 0, 1, 4, 2, 3, 4, 0, 0, 3, 0, 3,\n",
      "        3, 0, 2, 1, 4, 4, 4, 2, 2, 3, 1, 3, 0, 2, 1, 0, 4, 2, 3, 3, 0, 3, 3, 0,\n",
      "        1, 3], device='cuda:0')\n",
      "prediction next\n",
      "tensor([4, 4, 4, 4, 4, 3, 1, 3, 1, 1, 2, 2, 3, 0, 1, 4, 2, 3, 4, 0, 1, 3, 1, 1,\n",
      "        3, 0, 2, 1, 4, 4, 4, 2, 2, 3, 1, 2, 0, 2, 1, 2, 4, 2, 3, 3, 1, 3, 3, 0,\n",
      "        4, 3], device='cuda:0')\n",
      "label\n",
      "tensor([1, 1, 4, 1, 1, 1, 0, 0, 4, 2, 3, 2, 0, 1, 1, 3, 0, 3, 3, 2, 0, 2, 0, 1,\n",
      "        1, 4, 2, 2, 0, 2, 1, 0, 1, 3, 3, 2, 1, 4, 1, 2, 3, 3, 0, 4, 1, 0, 2, 4,\n",
      "        0, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 1, 4, 1, 1, 1, 0, 0, 4, 1, 1, 2, 4, 1, 1, 3, 0, 3, 0, 4, 1, 2, 0, 1,\n",
      "        1, 4, 4, 2, 0, 2, 1, 1, 1, 3, 3, 2, 1, 4, 1, 2, 4, 1, 4, 4, 1, 0, 2, 4,\n",
      "        4, 2], device='cuda:0')\n",
      "label\n",
      "tensor([1, 0, 3, 1, 3, 1, 0, 4, 4, 1, 3, 1, 1, 1, 2, 3, 2, 4, 0, 0, 2, 3, 0, 0,\n",
      "        3, 0, 3, 4, 4, 3, 3, 4, 0, 1, 1, 3, 3, 2, 2], device='cuda:0')\n",
      "prediction next\n",
      "tensor([1, 0, 3, 1, 3, 2, 1, 4, 4, 4, 3, 1, 3, 1, 2, 3, 2, 4, 0, 1, 2, 3, 1, 0,\n",
      "        2, 0, 3, 4, 4, 1, 3, 0, 0, 1, 1, 3, 3, 2, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7120, device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(testloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir_test = \"/home/shoaibmerajsami/Desktop/roi_test/\"\n",
    "test_data = YourDataset(root_dir_test)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=True,  num_workers=4)\n",
    "len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Conv_BN_Relu_first(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,padding,groups,bias):\n",
    "        super(Conv_BN_Relu_first,self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 64\n",
    "        groups =1 \n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding,groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class Conv_BN_Relu_other(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,padding,groups,bias):\n",
    "        super(Conv_BN_Relu_other,self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = out_channels\n",
    "        groups =1 \n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=features, kernel_size=kernel_size, padding=padding,groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,padding,groups,bais):\n",
    "        super(Conv,self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 1\n",
    "        groups =1 \n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding,groups=groups, bias=False)\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Self_Attn(nn.Module):\n",
    "    def __init__(self,in_dim):\n",
    "        super(Self_Attn,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim//8,kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim//8,kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim,kernel_size=1)\n",
    "        self.gamma=nn.Parameter(torch.zeros(1))\n",
    "        self.softmax=nn.Softmax(dim=-1)\n",
    "    def forward(self,x):\n",
    "        m_batchsize, C, width,height = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize,-1,width*height)\n",
    "        #print proj_query.size()\n",
    "        #print proj_key.size()\n",
    "        energy = torch.bmm(proj_query,proj_key)\n",
    "        attention = self.softmax(energy)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) \n",
    "        out = torch.bmm(proj_value,attention.permute(0,2,1))\n",
    "        out = out.view(m_batchsize,C,width,height)\n",
    "        out = self.gamma*out + x\n",
    "        return out, attention\n",
    "\n",
    "class ADNet(nn.Module):\n",
    "    def __init__(self, channels, num_of_layers=15):\n",
    "        super(ADNet, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 64\n",
    "        groups =1 \n",
    "        layers = []\n",
    "        kernel_size1 = 1\n",
    "        self.conv1_1 = nn.Sequential(nn.Conv2d(in_channels=channels,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_2 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_3 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_4 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_5 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_6 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_7 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_8 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_9 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_10 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_11 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_12 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_13 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_14 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_15 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(features, 5)\n",
    "        \n",
    "        \n",
    "        #self.conv1_16 = nn.Conv2d(in_channels=features,out_channels=3,kernel_size=kernel_size,padding=1,groups=groups,bias=False)\n",
    "        #self.conv3 = nn.Conv2d(in_channels=6,out_channels=3,kernel_size=1,stride=1,padding=0,groups=1,bias=True)\n",
    "        #self.ReLU = nn.ReLU(inplace=True)\n",
    "        #self.Tanh= nn.Tanh()\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2 / (9.0 * 64)) ** 0.5)\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(0, (2 / (9.0 * 64)) ** 0.5)\n",
    "                clip_b = 0.025\n",
    "                w = m.weight.data.shape[0]\n",
    "                for j in range(w):\n",
    "                    if m.weight.data[j] >= 0 and m.weight.data[j] < clip_b:\n",
    "                        m.weight.data[j] = clip_b\n",
    "                    elif m.weight.data[j] > -clip_b and m.weight.data[j] < 0:\n",
    "                        m.weight.data[j] = -clip_b\n",
    "                m.running_var.fill_(0.01)\n",
    "    def _make_layers(self, block,features, kernel_size, num_of_layers, padding=1, groups=1, bias=False):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layers):\n",
    "            layers.append(block(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, groups=groups, bias=bias))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        input = x \n",
    "        x1 = self.conv1_1(x)\n",
    "        x1 = self.conv1_2(x1)\n",
    "        x1 = self.conv1_3(x1)\n",
    "        x1 = self.conv1_4(x1)\n",
    "        x1 = self.conv1_5(x1)\n",
    "        x1 = self.conv1_6(x1)\n",
    "        x1 = self.conv1_7(x1)   \n",
    "        x1t = self.conv1_8(x1)\n",
    "        x1 = self.conv1_9(x1t)\n",
    "        x1 = self.conv1_10(x1)\n",
    "        x1 = self.conv1_11(x1)\n",
    "        x1 = self.conv1_12(x1)\n",
    "        x1 = self.conv1_13(x1)\n",
    "        x1 = self.conv1_14(x1)\n",
    "        x1 = self.conv1_15(x1)\n",
    "        out = self.avgpool(x1)\n",
    "        #print(x1)\n",
    "        #x1 = x1.view(x1.size(0), -1)\n",
    "        #x1 = self.fc(x1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "        #x1 = self.conv1_16(x1)\n",
    "        #out = torch.cat([x,x1],1)\n",
    "        #out= self.Tanh(out)\n",
    "        #out = self.conv3(out)\n",
    "        #out = out*x1\n",
    "        #out2 = x - out\n",
    "        #return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ADNet(channels=3, num_of_layers=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADNet(\n",
      "  (conv1_1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_3): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_4): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_5): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_6): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_7): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_8): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_9): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_10): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_11): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_12): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_13): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_14): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv1_15): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (linear): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channel, reduction_ratio=16, num_layers=1):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_activation = torch.nn.ReLU(inplace=False)\n",
    "        self.gate_c = nn.Sequential()\n",
    "        self.gate_c.add_module( 'flatten', Flatten() )\n",
    "        gate_channels = [gate_channel]\n",
    "        gate_channels += [gate_channel // reduction_ratio] * num_layers\n",
    "        gate_channels += [gate_channel]\n",
    "        for i in range( len(gate_channels) - 2 ):\n",
    "            self.gate_c.add_module( 'gate_c_fc_%d'%i, nn.Linear(gate_channels[i], gate_channels[i+1]) )\n",
    "            self.gate_c.add_module( 'gate_c_bn_%d'%(i+1), nn.BatchNorm1d(gate_channels[i+1]) )\n",
    "            self.gate_c.add_module( 'gate_c_relu_%d'%(i+1), nn.ReLU() )\n",
    "        self.gate_c.add_module( 'gate_c_fc_final', nn.Linear(gate_channels[-2], gate_channels[-1]) )\n",
    "    def forward(self, in_tensor):\n",
    "        avg_pool = F.avg_pool2d( in_tensor, in_tensor.size(2), stride=in_tensor.size(2) )\n",
    "        return self.gate_c( avg_pool ).unsqueeze(2).unsqueeze(3).expand_as(in_tensor)\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self, gate_channel, reduction_ratio=16, dilation_conv_num=2, dilation_val=4):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        self.gate_s = nn.Sequential()\n",
    "        self.gate_s.add_module( 'gate_s_conv_reduce0', nn.Conv2d(gate_channel, gate_channel//reduction_ratio, kernel_size=1))\n",
    "        self.gate_s.add_module( 'gate_s_bn_reduce0',nn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
    "        self.gate_s.add_module( 'gate_s_relu_reduce0',nn.ReLU() )\n",
    "        for i in range( dilation_conv_num ):\n",
    "            self.gate_s.add_module( 'gate_s_conv_di_%d'%i, nn.Conv2d(gate_channel//reduction_ratio, gate_channel//reduction_ratio, kernel_size=3, padding=dilation_val, dilation=dilation_val) )\n",
    "            self.gate_s.add_module( 'gate_s_bn_di_%d'%i, nn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
    "            self.gate_s.add_module( 'gate_s_relu_di_%d'%i, nn.ReLU() )\n",
    "        self.gate_s.add_module( 'gate_s_conv_final', nn.Conv2d(gate_channel//reduction_ratio, 1, kernel_size=1) )\n",
    "    def forward(self, in_tensor):\n",
    "        return self.gate_s( in_tensor ).expand_as(in_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BAM(nn.Module):\n",
    "    def __init__(self, gate_channel):\n",
    "        super(BAM, self).__init__()\n",
    "        self.channel_att = ChannelGate(gate_channel)\n",
    "        self.spatial_att = SpatialGate(gate_channel)\n",
    "    def forward(self,in_tensor):\n",
    "        att = 1 + F.sigmoid( self.channel_att(in_tensor) * self.spatial_att(in_tensor) )\n",
    "        return att * in_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.nn import init\n",
    "#from .cbam import *\n",
    "#from .bam import *\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes * 4, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers,  network_type, num_classes, att_type=None):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.network_type = network_type\n",
    "        # different model config between ImageNet and CIFAR \n",
    "        if network_type == \"ImageNet\":\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            self.avgpool = nn.AvgPool2d(7)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if att_type=='BAM':\n",
    "            self.bam1 = BAM(64*block.expansion)\n",
    "            self.bam2 = BAM(128*block.expansion)\n",
    "            self.bam3 = BAM(256*block.expansion)\n",
    "        else:\n",
    "            self.bam1, self.bam2, self.bam3 = None, None, None\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], att_type=att_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, att_type=att_type)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, att_type=att_type)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, att_type=att_type)\n",
    "\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        init.kaiming_normal(self.fc.weight)\n",
    "        for key in self.state_dict():\n",
    "            if key.split('.')[-1]==\"weight\":\n",
    "                if \"conv\" in key:\n",
    "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
    "                if \"bn\" in key:\n",
    "                    if \"SpatialGate\" in key:\n",
    "                        self.state_dict()[key][...] = 0\n",
    "                    else:\n",
    "                        self.state_dict()[key][...] = 1\n",
    "            elif key.split(\".\")[-1]=='bias':\n",
    "                self.state_dict()[key][...] = 0\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, att_type=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, use_cbam=att_type=='CBAM'))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, use_cbam=att_type=='CBAM'))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        if not self.bam1 is None:\n",
    "            x = self.bam1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        if not self.bam2 is None:\n",
    "            x = self.bam2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        if not self.bam3 is None:\n",
    "            x = self.bam3(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.avgpool(x)\n",
    "        else:\n",
    "            x = F.avg_pool2d(x, 4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shoaibmerajsami/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:129: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "/home/shoaibmerajsami/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:133: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    " model = ResNet(BasicBlock, [2, 2, 2, 2], \"CIFAR10\", 5, \"BAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (bam1): BAM(\n",
      "    (channel_att): ChannelGate(\n",
      "      (gate_activation): ReLU()\n",
      "      (gate_c): Sequential(\n",
      "        (flatten): Flatten()\n",
      "        (gate_c_fc_0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        (gate_c_bn_1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_c_relu_1): ReLU()\n",
      "        (gate_c_fc_final): Linear(in_features=4, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (spatial_att): SpatialGate(\n",
      "      (gate_s): Sequential(\n",
      "        (gate_s_conv_reduce0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate_s_bn_reduce0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_s_relu_reduce0): ReLU()\n",
      "        (gate_s_conv_di_0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "        (gate_s_bn_di_0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_s_relu_di_0): ReLU()\n",
      "        (gate_s_conv_di_1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "        (gate_s_bn_di_1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_s_relu_di_1): ReLU()\n",
      "        (gate_s_conv_final): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bam2): BAM(\n",
      "    (channel_att): ChannelGate(\n",
      "      (gate_activation): ReLU()\n",
      "      (gate_c): Sequential(\n",
      "        (flatten): Flatten()\n",
      "        (gate_c_fc_0): Linear(in_features=128, out_features=8, bias=True)\n",
      "        (gate_c_bn_1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_c_relu_1): ReLU()\n",
      "        (gate_c_fc_final): Linear(in_features=8, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (spatial_att): SpatialGate(\n",
      "      (gate_s): Sequential(\n",
      "        (gate_s_conv_reduce0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate_s_bn_reduce0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_s_relu_reduce0): ReLU()\n",
      "        (gate_s_conv_di_0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "        (gate_s_bn_di_0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_s_relu_di_0): ReLU()\n",
      "        (gate_s_conv_di_1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "        (gate_s_bn_di_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_s_relu_di_1): ReLU()\n",
      "        (gate_s_conv_final): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bam3): BAM(\n",
      "    (channel_att): ChannelGate(\n",
      "      (gate_activation): ReLU()\n",
      "      (gate_c): Sequential(\n",
      "        (flatten): Flatten()\n",
      "        (gate_c_fc_0): Linear(in_features=256, out_features=16, bias=True)\n",
      "        (gate_c_bn_1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_c_relu_1): ReLU()\n",
      "        (gate_c_fc_final): Linear(in_features=16, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (spatial_att): SpatialGate(\n",
      "      (gate_s): Sequential(\n",
      "        (gate_s_conv_reduce0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate_s_bn_reduce0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_s_relu_reduce0): ReLU()\n",
      "        (gate_s_conv_di_0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "        (gate_s_bn_di_0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_s_relu_di_0): ReLU()\n",
      "        (gate_s_conv_di_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
      "        (gate_s_bn_di_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (gate_s_relu_di_1): ReLU()\n",
      "        (gate_s_conv_final): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    ''' 1x1 convolution '''\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1, padding=1, dilation=1):\n",
    "    ''' 3x3 convolution '''\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding, dilation=dilation, bias=False)\n",
    "\n",
    "def conv7x7(in_channels, out_channels, stride=1, padding=3, dilation=1):\n",
    "    ''' 7x7 convolution '''\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=7, stride=stride, padding=padding, dilation=dilation, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#from Models.conv import conv1x1, conv3x3, conv7x7\n",
    "\n",
    "class BAM(nn.Module):\n",
    "    def __init__(self, in_channel, reduction_ratio, dilation):\n",
    "        super(BAM, self).__init__()\n",
    "        self.hid_channel = in_channel // reduction_ratio\n",
    "        self.dilation = dilation\n",
    "        self.globalAvgPool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=in_channel, out_features=self.hid_channel)\n",
    "        self.bn1_1d = nn.BatchNorm1d(self.hid_channel)\n",
    "        self.fc2 = nn.Linear(in_features=self.hid_channel, out_features=in_channel)\n",
    "        self.bn2_1d = nn.BatchNorm1d(in_channel)\n",
    "\n",
    "        self.conv1 = conv1x1(in_channel, self.hid_channel)\n",
    "        self.bn1_2d = nn.BatchNorm2d(self.hid_channel)\n",
    "        self.conv2 = conv3x3(self.hid_channel, self.hid_channel, stride=1, padding=self.dilation, dilation=self.dilation)\n",
    "        self.bn2_2d = nn.BatchNorm2d(self.hid_channel)\n",
    "        self.conv3 = conv3x3(self.hid_channel, self.hid_channel, stride=1, padding=self.dilation, dilation=self.dilation)\n",
    "        self.bn3_2d = nn.BatchNorm2d(self.hid_channel)\n",
    "        self.conv4 = conv1x1(self.hid_channel, 1)\n",
    "        self.bn4_2d = nn.BatchNorm2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Channel attention\n",
    "        Mc = self.globalAvgPool(x)\n",
    "        Mc = Mc.view(Mc.size(0), -1)\n",
    "\n",
    "        Mc = self.fc1(Mc)\n",
    "        Mc = self.bn1_1d(Mc)\n",
    "        Mc = self.relu(Mc)\n",
    "\n",
    "        Mc = self.fc2(Mc)\n",
    "        Mc = self.bn2_1d(Mc)\n",
    "        Mc = self.relu(Mc)\n",
    "\n",
    "        Mc = Mc.view(Mc.size(0), Mc.size(1), 1, 1)\n",
    "\n",
    "        # Spatial attention\n",
    "        Ms = self.conv1(x)\n",
    "        Ms = self.bn1_2d(Ms)\n",
    "        Ms = self.relu(Ms)\n",
    "\n",
    "        Ms = self.conv2(Ms)\n",
    "        Ms = self.bn2_2d(Ms)\n",
    "        Ms = self.relu(Ms)\n",
    "\n",
    "        Ms = self.conv3(Ms)\n",
    "        Ms = self.bn3_2d(Ms)\n",
    "        Ms = self.relu(Ms)\n",
    "\n",
    "        Ms = self.conv4(Ms)\n",
    "        Ms = self.bn4_2d(Ms)\n",
    "        Ms = self.relu(Ms)\n",
    "\n",
    "        Ms = Ms.view(x.size(0), 1, x.size(2), x.size(3))\n",
    "        Mf = 1 + self.sigmoid(Mc * Ms)\n",
    "        return x * Mf\n",
    "\n",
    "#To-do:\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channel, reduction_ratio, dilation=1):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.hid_channel = in_channel // reduction_ratio\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.globalAvgPool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.globalMaxPool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        # Shared MLP.\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=in_channel, out_features=self.hid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=self.hid_channel, out_features=in_channel)\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.conv1 = conv7x7(2, 1, stride=1, dilation=self.dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Channel attention '''\n",
    "        avgOut = self.globalAvgPool(x)\n",
    "        avgOut = avgOut.view(avgOut.size(0), -1)\n",
    "        avgOut = self.mlp(avgOut)\n",
    "\n",
    "        maxOut = self.globalMaxPool(x)\n",
    "        maxOut = maxOut.view(maxOut.size(0), -1)\n",
    "        maxOut = self.mlp(maxOut)\n",
    "        # sigmoid(MLP(AvgPool(F)) + MLP(MaxPool(F)))\n",
    "        Mc = self.sigmoid(avgOut + maxOut)\n",
    "        Mc = Mc.view(Mc.size(0), Mc.size(1), 1, 1)\n",
    "        Mf1 = Mc * x\n",
    "\n",
    "        ''' Spatial attention. '''\n",
    "        # sigmoid(conv7x7( [AvgPool(F); MaxPool(F)]))\n",
    "        maxOut = torch.max(Mf1, 1)[0].unsqueeze(1)\n",
    "        avgOut = torch.mean(Mf1, 1).unsqueeze(1)\n",
    "        Ms = torch.cat((maxOut, avgOut), dim=1)\n",
    "\n",
    "        Ms = self.conv1(Ms)\n",
    "        Ms = self.sigmoid(Ms)\n",
    "        Ms = Ms.view(Ms.size(0), 1, Ms.size(2), Ms.size(3))\n",
    "        Mf2 = Ms * Mf1\n",
    "        return Mf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#from Models.attention import BAM, CBAM\n",
    "#from Models.conv import conv1x1, conv3x3\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, hid_channels, atte='bam', ratio=16, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, hid_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(hid_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(hid_channels, hid_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(hid_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "        if atte == 'cbam':\n",
    "            self.atte = CBAM(out_channels, ratio)\n",
    "        else:\n",
    "            self.atte = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        # CBAM\n",
    "        if not self.atte is None:\n",
    "            out = self.atte(out)\n",
    "\n",
    "        #out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BottleneckBlock(nn.Module): # bottelneck-block, over the 50 layers.\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, hid_channels, atte='bam', ratio=16, stride=1, downsample=None):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        self.downsample = downsample\n",
    "        out_channels = hid_channels * self.expansion\n",
    "        self.conv1 = conv1x1(in_channels, hid_channels)\n",
    "        self.bn1 = nn.BatchNorm2d(hid_channels)\n",
    "\n",
    "        self.conv2 = conv3x3(hid_channels, hid_channels, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(hid_channels)\n",
    "\n",
    "        self.conv3 = conv1x1(hid_channels, out_channels)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if atte == 'cbam':\n",
    "            self.atte = CBAM(out_channels, ratio)\n",
    "        else:\n",
    "            self.atte = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x # indentity\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.atte is None:\n",
    "            out = self.atte(out)\n",
    "\n",
    "        #out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    '''\n",
    "    *50-layer\n",
    "        conv1 (output: 112x112)\n",
    "            7x7, 64, stride 2\n",
    "        conv2 (output: 56x56)\n",
    "            3x3 max pool, stride 2\n",
    "            [ 1x1, 64  ]\n",
    "            [ 3x3, 64  ] x 3\n",
    "            [ 1x1, 256 ]\n",
    "        cov3 (output: 28x28)\n",
    "            [ 1x1, 128 ]\n",
    "            [ 3x3, 128 ] x 4\n",
    "            [ 1x1, 512 ]\n",
    "        cov4 (output: 14x14)\n",
    "            [ 1x1, 256 ]\n",
    "            [ 3x3, 256 ] x 6\n",
    "            [ 1x1, 1024]\n",
    "        cov5 (output: 28x28)\n",
    "            [ 1x1, 512 ]\n",
    "            [ 3x3, 512 ] x 3\n",
    "            [ 1x1, 2048]\n",
    "        _ (output: 1x1)\n",
    "            average pool, 100-d fc, softmax\n",
    "        FLOPs 3.8x10^9\n",
    "    '''\n",
    "    '''\n",
    "    *101-layer\n",
    "        conv1 (output: 112x112)\n",
    "            7x7, 64, stride 2\n",
    "        conv2 (output: 56x56)\n",
    "            3x3 max pool, stride 2\n",
    "            [ 1x1, 64  ]\n",
    "            [ 3x3, 64  ] x 3\n",
    "            [ 1x1, 256 ]\n",
    "        cov3 (output: 28x28)\n",
    "            [ 1x1, 128 ]\n",
    "            [ 3x3, 128 ] x 4\n",
    "            [ 1x1, 512 ]\n",
    "        cov4 (output: 14x14)\n",
    "            [ 1x1, 256 ]\n",
    "            [ 3x3, 256 ] x 23\n",
    "            [ 1x1, 1024]\n",
    "        cov5 (output: 28x28)\n",
    "            [ 1x1, 512 ]\n",
    "            [ 3x3, 512 ] x 3\n",
    "            [ 1x1, 2048]\n",
    "        _ (output: 1x1)\n",
    "            average pool, 100-d fc, softmax\n",
    "        FLOPs 7.6x10^9\n",
    "    '''\n",
    "    def __init__(self, block, layers, num_classes=1000, atte='bam', ratio=16, dilation=4):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        self.layers = layers\n",
    "        self.in_channels = 64\n",
    "        self.atte = atte\n",
    "        self.ratio = ratio\n",
    "        self.dilation = dilation\n",
    "\n",
    "        if num_classes == 1000:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        if self.atte == 'bam':\n",
    "            self.bam1 = BAM(64*block.expansion, self.ratio, self.dilation)\n",
    "            self.bam2 = BAM(128*block.expansion, self.ratio, self.dilation)\n",
    "            self.bam3 = BAM(256*block.expansion, self.ratio, self.dilation)\n",
    "\n",
    "        self.conv2 = self.get_layers(block, 64, self.layers[0])\n",
    "        self.conv3 = self.get_layers(block, 128, self.layers[1], stride=2)\n",
    "        self.conv4 = self.get_layers(block, 256, self.layers[2], stride=2)\n",
    "        self.conv5 = self.get_layers(block, 512, self.layers[3], stride=2)\n",
    "        self.avgPool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        torch.nn.init.kaiming_normal(self.fc.weight)\n",
    "        for m in self.state_dict():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        torch.nn.init.kaiming_normal(self.fc.weight)\n",
    "        for m in self.state_dict():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def get_layers(self, block, hid_channels, n_layers, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != hid_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                    conv1x1(self.in_channels, hid_channels * block.expansion, stride),\n",
    "                    nn.BatchNorm2d(hid_channels * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, hid_channels, self.atte, self.ratio, stride, downsample))\n",
    "        self.in_channels = hid_channels * block.expansion\n",
    "\n",
    "        for _ in range(1, n_layers):\n",
    "            layers.append(block(self.in_channels, hid_channels, self.atte, self.ratio))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            Example tensor shape based on resnet101\n",
    "        '''\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        if self.atte == 'bam':\n",
    "            x = self.bam1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        if self.atte == 'bam':\n",
    "            x = self.bam2(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        if self.atte == 'bam':\n",
    "            x = self.bam3(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    return ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    return ResNet(BottleneckBlock, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    ''' ResNet-101 Model'''\n",
    "    return ResNet(BottleneckBlock, [3, 4, 23, 3], **kwargs)\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    return ResNet(BottleneckBlock, [3, 8, 36, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shoaibmerajsami/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:180: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "/home/shoaibmerajsami/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:187: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    " model2 = resnet18(num_classes=5, atte='bam', ratio=16, dilation = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adnet as autoencoder by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adnet as autoencoder by me\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Conv_BN_Relu_first(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,padding,groups,bias):\n",
    "        super(Conv_BN_Relu_first,self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 64\n",
    "        groups =1 \n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding,groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class Conv_BN_Relu_other(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,padding,groups,bias):\n",
    "        super(Conv_BN_Relu_other,self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = out_channels\n",
    "        groups =1 \n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=features, kernel_size=kernel_size, padding=padding,groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,padding,groups,bais):\n",
    "        super(Conv,self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 1\n",
    "        groups =1 \n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding,groups=groups, bias=False)\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Self_Attn(nn.Module):\n",
    "    def __init__(self,in_dim):\n",
    "        super(Self_Attn,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim//8,kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim//8,kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim,kernel_size=1)\n",
    "        self.gamma=nn.Parameter(torch.zeros(1))\n",
    "        self.softmax=nn.Softmax(dim=-1)\n",
    "    def forward(self,x):\n",
    "        m_batchsize, C, width,height = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize,-1,width*height)\n",
    "        #print proj_query.size()\n",
    "        #print proj_key.size()\n",
    "        energy = torch.bmm(proj_query,proj_key)\n",
    "        attention = self.softmax(energy)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) \n",
    "        out = torch.bmm(proj_value,attention.permute(0,2,1))\n",
    "        out = out.view(m_batchsize,C,width,height)\n",
    "        out = self.gamma*out + x\n",
    "        return out, attention\n",
    "\n",
    "class ADNet(nn.Module):\n",
    "    def __init__(self, channels, num_of_layers=15):\n",
    "        super(ADNet, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 64\n",
    "        groups =1 \n",
    "        layers = []\n",
    "        kernel_size1 = 1\n",
    "        self.conv1_1 = nn.Sequential(nn.Conv2d(in_channels=channels,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_2 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_3 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_4 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_5 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_6 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_7 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_8 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_9 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_10 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_11 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_12 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_13 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_14 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_15 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_16 = nn.Conv2d(in_channels=features,out_channels=3,kernel_size=kernel_size,padding=1,groups=groups,bias=False)\n",
    "        self.conv3 = nn.Conv2d(in_channels=6,out_channels=3,kernel_size=1,stride=1,padding=0,groups=1,bias=True)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.Tanh= nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear1 = nn.Linear(40*72*3, 128)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.linear3 = nn.Linear(128, 5)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2 / (9.0 * 64)) ** 0.5)\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(0, (2 / (9.0 * 64)) ** 0.5)\n",
    "                clip_b = 0.025\n",
    "                w = m.weight.data.shape[0]\n",
    "                for j in range(w):\n",
    "                    if m.weight.data[j] >= 0 and m.weight.data[j] < clip_b:\n",
    "                        m.weight.data[j] = clip_b\n",
    "                    elif m.weight.data[j] > -clip_b and m.weight.data[j] < 0:\n",
    "                        m.weight.data[j] = -clip_b\n",
    "                m.running_var.fill_(0.01)\n",
    "    def _make_layers(self, block,features, kernel_size, num_of_layers, padding=1, groups=1, bias=False):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layers):\n",
    "            layers.append(block(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, groups=groups, bias=bias))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        input = x \n",
    "        x1 = self.conv1_1(x)\n",
    "        x1 = self.conv1_2(x1)\n",
    "        x1 = self.conv1_3(x1)\n",
    "        x1 = self.conv1_4(x1)\n",
    "        x1 = self.conv1_5(x1)\n",
    "        x1 = self.conv1_6(x1)\n",
    "        x1 = self.conv1_7(x1)   \n",
    "        x1t = self.conv1_8(x1)\n",
    "        x1 = self.conv1_9(x1t)\n",
    "        x1 = self.conv1_10(x1)\n",
    "        x1 = self.conv1_11(x1)\n",
    "        x1 = self.conv1_12(x1)\n",
    "        x1 = self.conv1_13(x1)\n",
    "        x1 = self.conv1_14(x1)\n",
    "        x1 = self.conv1_15(x1)\n",
    "        x1 = self.conv1_16(x1)\n",
    "        #out = torch.cat([x,x1],1)\n",
    "        #out= self.Tanh(out)\n",
    "        #out = self.conv3(out)\n",
    "        #out = out*x1\n",
    "        #out2 = x - out\n",
    "        #x2 = nn.Flatten()(x1) #flatten the feature maps.\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = self.linear1(x1)\n",
    "        x2 = self.ReLU(x2)\n",
    "        x3 = self.linear2(x2)\n",
    "        x2 = self.ReLU(x3)\n",
    "        x2 = self.linear3(x2)\n",
    "\n",
    "        return x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adnet as autoencoder by me\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Conv_BN_Relu_first(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,padding,groups,bias):\n",
    "        super(Conv_BN_Relu_first,self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 64\n",
    "        groups =1 \n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding,groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class Conv_BN_Relu_other(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,padding,groups,bias):\n",
    "        super(Conv_BN_Relu_other,self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = out_channels\n",
    "        groups =1 \n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=features, kernel_size=kernel_size, padding=padding,groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,padding,groups,bais):\n",
    "        super(Conv,self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 1\n",
    "        groups =1 \n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding,groups=groups, bias=False)\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Self_Attn(nn.Module):\n",
    "    def __init__(self,in_dim):\n",
    "        super(Self_Attn,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim//8,kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim//8,kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim,kernel_size=1)\n",
    "        self.gamma=nn.Parameter(torch.zeros(1))\n",
    "        self.softmax=nn.Softmax(dim=-1)\n",
    "    def forward(self,x):\n",
    "        m_batchsize, C, width,height = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize,-1,width*height)\n",
    "        #print proj_query.size()\n",
    "        #print proj_key.size()\n",
    "        energy = torch.bmm(proj_query,proj_key)\n",
    "        attention = self.softmax(energy)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) \n",
    "        out = torch.bmm(proj_value,attention.permute(0,2,1))\n",
    "        out = out.view(m_batchsize,C,width,height)\n",
    "        out = self.gamma*out + x\n",
    "        return out, attention\n",
    "\n",
    "class ADNet(nn.Module):\n",
    "    def __init__(self, channels, num_of_layers=15):\n",
    "        super(ADNet, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 64\n",
    "        groups =1 \n",
    "        layers = []\n",
    "        kernel_size1 = 1\n",
    "        self.conv1_1 = nn.Sequential(nn.Conv2d(in_channels=channels,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_2 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_3 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_4 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_5 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_6 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_7 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_8 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_9 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_10 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_11 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_12 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=2,groups=groups,bias=False,dilation=2),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_13 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_14 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=padding,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_15 = nn.Sequential(nn.Conv2d(in_channels=features,out_channels=features,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        self.conv1_16 = nn.Conv2d(in_channels=features,out_channels=3,kernel_size=kernel_size,padding=1,groups=groups,bias=False)\n",
    "        #self.conv1_17 =  nn.Sequential(nn.Conv2d(in_channels=6,out_channels=3,kernel_size=kernel_size,padding=1,groups=groups,bias=False),nn.BatchNorm2d(features),nn.ReLU(inplace=True))\n",
    "        #self.conv3 = nn.Conv2d(in_channels=6,out_channels=3,kernel_size=1,stride=1,padding=0,groups=1,bias=True)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.Tanh= nn.Tanh()\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        #self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear1 = nn.Linear(6*40*72, 128)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.linear3 = nn.Linear(128, 5)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2 / (9.0 * 64)) ** 0.5)\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(0, (2 / (9.0 * 64)) ** 0.5)\n",
    "                clip_b = 0.025\n",
    "                w = m.weight.data.shape[0]\n",
    "                for j in range(w):\n",
    "                    if m.weight.data[j] >= 0 and m.weight.data[j] < clip_b:\n",
    "                        m.weight.data[j] = clip_b\n",
    "                    elif m.weight.data[j] > -clip_b and m.weight.data[j] < 0:\n",
    "                        m.weight.data[j] = -clip_b\n",
    "                m.running_var.fill_(0.01)\n",
    "    def _make_layers(self, block,features, kernel_size, num_of_layers, padding=1, groups=1, bias=False):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layers):\n",
    "            layers.append(block(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, groups=groups, bias=bias))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        input = x \n",
    "        x1 = self.conv1_1(x)\n",
    "        x1 = self.conv1_2(x1)\n",
    "        x1 = self.conv1_3(x1)\n",
    "        x1 = self.conv1_4(x1)\n",
    "        x1 = self.conv1_5(x1)\n",
    "        x1 = self.conv1_6(x1)\n",
    "        x1 = self.conv1_7(x1)   \n",
    "        x1t = self.conv1_8(x1)\n",
    "        x1 = self.conv1_9(x1t)\n",
    "        x1 = self.conv1_10(x1)\n",
    "        x1 = self.conv1_11(x1)\n",
    "        x1 = self.conv1_12(x1)\n",
    "        x1 = self.conv1_13(x1)\n",
    "        x1 = self.conv1_14(x1)\n",
    "        x1 = self.conv1_15(x1)\n",
    "        x1 = self.conv1_16(x1)\n",
    "        #print(x1.size())\n",
    "        out = torch.cat([x,x1],1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        #out= self.ReLU(out)\n",
    "        #out = self.conv1_17(out)\n",
    "        #print(out.size())\n",
    "        \n",
    "        #out = self.ReLU(out)\n",
    "        #out = out*x1\n",
    "        #out2 = x - out\n",
    "        #x2 = nn.Flatten()(out2) #flatten the feature maps.\n",
    "        x2 = self.ReLU(out)\n",
    "        x2 = self.linear1(x2)\n",
    "        x2 = self.ReLU(x2)\n",
    "        x3 = self.linear2(x2)\n",
    "        x2 = self.ReLU(x3)\n",
    "        x2 = self.linear3(x2)\n",
    "\n",
    "        return x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0637,  0.0844,  0.0299,  0.0225,  0.0264],\n",
       "        [-0.0606,  0.0922,  0.0262,  0.0170,  0.0236],\n",
       "        [-0.0568,  0.0869,  0.0282,  0.0175,  0.0295],\n",
       "        [-0.0620,  0.0855,  0.0193,  0.0251,  0.0237],\n",
       "        [-0.0641,  0.0842,  0.0248,  0.0262,  0.0289],\n",
       "        [-0.0581,  0.0858,  0.0238,  0.0174,  0.0311],\n",
       "        [-0.0567,  0.0836,  0.0262,  0.0226,  0.0226],\n",
       "        [-0.0587,  0.0902,  0.0233,  0.0223,  0.0295]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ADNet(channels=3,)\n",
    "x = torch.randn((8, 3, 40, 72))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.Size' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-f940dec5ccdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-9f78f2ae1a53>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_14\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_15\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;31m#x1 = self.conv1_16(x1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'torch.Size' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',\n",
    "           'resnet152_cbam']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "           \n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        #out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.ca = ChannelAttention(planes * 4)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        #out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=5):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 1, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18_cbam(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
    "    'vgg19_bn', 'vgg19',\n",
    "]\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=5, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 5 * 9, 128*10),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128*10, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64,'M',128, 128,'M', 256, 256, 256, 512, 512, 512, 512,'M',512, 512],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\")\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['A']), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11_bn(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 13-layer model (configuration \"B\")\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['B']), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13_bn(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg13_bn']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['D']), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16_bn(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg16_bn']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['E']), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg19']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19_bn(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg19_bn']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VGG:\n\tMissing key(s) in state_dict: \"features.23.weight\", \"features.23.bias\", \"features.24.running_mean\", \"features.24.running_var\", \"features.26.weight\", \"features.26.bias\", \"features.27.running_mean\", \"features.27.running_var\", \"features.29.weight\", \"features.29.bias\", \"features.30.running_mean\", \"features.30.running_var\", \"features.32.weight\", \"features.32.bias\", \"features.33.weight\", \"features.33.bias\", \"features.33.running_mean\", \"features.33.running_var\", \"features.36.weight\", \"features.36.bias\", \"features.37.running_mean\", \"features.37.running_var\", \"features.39.weight\", \"features.39.bias\", \"features.40.running_mean\", \"features.40.running_var\". \n\tUnexpected key(s) in state_dict: \"features.25.weight\", \"features.25.bias\", \"features.25.running_mean\", \"features.25.running_var\", \"features.28.weight\", \"features.28.bias\", \"features.28.running_mean\", \"features.28.running_var\", \"features.31.weight\", \"features.31.bias\", \"features.31.running_mean\", \"features.31.running_var\", \"features.34.weight\", \"features.34.bias\", \"features.35.weight\", \"features.35.bias\", \"features.35.running_mean\", \"features.35.running_var\", \"features.38.weight\", \"features.38.bias\", \"features.38.running_mean\", \"features.38.running_var\", \"features.41.weight\", \"features.41.bias\", \"features.41.running_mean\", \"features.41.running_var\". \n\tsize mismatch for features.24.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.27.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.30.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.37.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.40.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([4096, 25088]) from checkpoint, the shape in current model is torch.Size([1280, 23040]).\n\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for classifier.3.weight: copying a param with shape torch.Size([4096, 4096]) from checkpoint, the shape in current model is torch.Size([128, 1280]).\n\tsize mismatch for classifier.3.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for classifier.6.weight: copying a param with shape torch.Size([1000, 4096]) from checkpoint, the shape in current model is torch.Size([5, 128]).\n\tsize mismatch for classifier.6.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([5]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c4ac2147a86d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-f8ef2485e8ac>\u001b[0m in \u001b[0;36mvgg16_bn\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_zoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vgg16_bn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1407\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VGG:\n\tMissing key(s) in state_dict: \"features.23.weight\", \"features.23.bias\", \"features.24.running_mean\", \"features.24.running_var\", \"features.26.weight\", \"features.26.bias\", \"features.27.running_mean\", \"features.27.running_var\", \"features.29.weight\", \"features.29.bias\", \"features.30.running_mean\", \"features.30.running_var\", \"features.32.weight\", \"features.32.bias\", \"features.33.weight\", \"features.33.bias\", \"features.33.running_mean\", \"features.33.running_var\", \"features.36.weight\", \"features.36.bias\", \"features.37.running_mean\", \"features.37.running_var\", \"features.39.weight\", \"features.39.bias\", \"features.40.running_mean\", \"features.40.running_var\". \n\tUnexpected key(s) in state_dict: \"features.25.weight\", \"features.25.bias\", \"features.25.running_mean\", \"features.25.running_var\", \"features.28.weight\", \"features.28.bias\", \"features.28.running_mean\", \"features.28.running_var\", \"features.31.weight\", \"features.31.bias\", \"features.31.running_mean\", \"features.31.running_var\", \"features.34.weight\", \"features.34.bias\", \"features.35.weight\", \"features.35.bias\", \"features.35.running_mean\", \"features.35.running_var\", \"features.38.weight\", \"features.38.bias\", \"features.38.running_mean\", \"features.38.running_var\", \"features.41.weight\", \"features.41.bias\", \"features.41.running_mean\", \"features.41.running_var\". \n\tsize mismatch for features.24.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.27.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.30.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.37.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.40.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([4096, 25088]) from checkpoint, the shape in current model is torch.Size([1280, 23040]).\n\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1280]).\n\tsize mismatch for classifier.3.weight: copying a param with shape torch.Size([4096, 4096]) from checkpoint, the shape in current model is torch.Size([128, 1280]).\n\tsize mismatch for classifier.3.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for classifier.6.weight: copying a param with shape torch.Size([1000, 4096]) from checkpoint, the shape in current model is torch.Size([5, 128]).\n\tsize mismatch for classifier.6.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([5])."
     ]
    }
   ],
   "source": [
    "model = vgg16_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ReLU(inplace=True)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=92160, out_features=1280, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=1280, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
